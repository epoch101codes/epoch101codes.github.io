diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 82ecc41..65563a7 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -1616,7 +1616,7 @@ config X86_NEED_RELOCS
 config PHYSICAL_ALIGN
 	hex "Alignment value to which kernel should be aligned" if X86_32
 	default "0x1000000"
-	range 0x2000 0x1000000
+	range 0x2000 0x2000000
 	---help---
 	  This value puts the alignment restrictions on physical address
 	  where kernel is loaded and run from. Kernel is compiled for an
diff --git a/arch/x86/include/asm/apic.h b/arch/x86/include/asm/apic.h
index 1a6c09a..00a7688 100644
--- a/arch/x86/include/asm/apic.h
+++ b/arch/x86/include/asm/apic.h
@@ -220,6 +220,7 @@ extern void enable_IR_x2apic(void);
 
 extern int get_physical_broadcast(void);
 
+extern unsigned int lapic_is_bsp(void);
 extern int lapic_get_maxlvt(void);
 extern void clear_local_APIC(void);
 extern void connect_bsp_APIC(void);
diff --git a/arch/x86/include/asm/cpu.h b/arch/x86/include/asm/cpu.h
index 4564c8e..139dcd9 100644
--- a/arch/x86/include/asm/cpu.h
+++ b/arch/x86/include/asm/cpu.h
@@ -10,6 +10,7 @@
 #ifdef CONFIG_SMP
 
 extern void prefill_possible_map(void);
+extern void prefill_present_map(void);
 
 #else /* CONFIG_SMP */
 
diff --git a/arch/x86/include/asm/io_apic.h b/arch/x86/include/asm/io_apic.h
index 690d1cc..f5d9143 100644
--- a/arch/x86/include/asm/io_apic.h
+++ b/arch/x86/include/asm/io_apic.h
@@ -203,6 +203,9 @@ static inline int restore_ioapic_entries(void)
 
 static inline void mp_save_irq(struct mpc_intsrc *m) { };
 static inline void disable_ioapic_support(void) { }
-#endif
+#endif /* !CONFIG_X86_IO_APIC */
+
+void NSprint_IO_APICs(void);
+void NSprint_local_APIC(void *dummy);
 
 #endif /* _ASM_X86_IO_APIC_H */
diff --git a/arch/x86/include/asm/setup.h b/arch/x86/include/asm/setup.h
index 9756551..8559c2c4 100644
--- a/arch/x86/include/asm/setup.h
+++ b/arch/x86/include/asm/setup.h
@@ -18,6 +18,7 @@
 
 #define PARAM_SIZE 4096		/* sizeof(struct boot_params) */
 
+// CL Command Line
 #define OLD_CL_MAGIC		0xA33F
 #define OLD_CL_ADDRESS		0x020	/* Relative to real mode data */
 #define NEW_CL_POINTER		0x228	/* Relative to real mode data */
diff --git a/arch/x86/include/asm/smp.h b/arch/x86/include/asm/smp.h
index 73b11bc..ed3a52e 100644
--- a/arch/x86/include/asm/smp.h
+++ b/arch/x86/include/asm/smp.h
@@ -160,6 +160,8 @@ void play_dead_common(void);
 void wbinvd_on_cpu(int cpu);
 int wbinvd_on_all_cpus(void);
 
+int mkbsp_boot_cpu(int apicid, int cpu);
+
 void native_send_call_func_ipi(const struct cpumask *mask);
 void native_send_call_func_single_ipi(int cpu);
 
diff --git a/arch/x86/include/asm/trampoline.h b/arch/x86/include/asm/trampoline.h
index feca311..570ef91 100644
--- a/arch/x86/include/asm/trampoline.h
+++ b/arch/x86/include/asm/trampoline.h
@@ -15,25 +15,46 @@ extern const unsigned char x86_trampoline_start [];
 extern const unsigned char x86_trampoline_end   [];
 extern unsigned char *x86_trampoline_base;
 
+extern const unsigned char x86_trampoline_bsp_start [];
+extern const unsigned char x86_trampoline_bsp_end   [];
+extern unsigned char *x86_trampoline_bsp_base;
+
 extern unsigned long init_rsp;
 extern unsigned long initial_code;
 extern unsigned long initial_gs;
 
-extern void __init setup_trampolines(void);
+extern unsigned long mkbsp_load_addr;
+extern unsigned long mkbsp_boot_params;
+
+extern void __init setup_trampolines(int flags);
+extern void __init setup_trampolines_bsp(int flags);
 
 extern const unsigned char trampoline_data[];
 extern const unsigned char trampoline_status[];
 
+extern const unsigned char trampoline_data_bsp[];
+extern const unsigned char trampoline_status_bsp[];
+
 #define TRAMPOLINE_SYM(x)						\
 	((void *)(x86_trampoline_base +					\
 		  ((const unsigned char *)(x) - x86_trampoline_start)))
 
+#define TRAMPOLINE_SYM_BSP(x)						\
+	((void *)(x86_trampoline_bsp_base +					\
+		  ((const unsigned char *)(x) - x86_trampoline_bsp_start)))
+
+
 /* Address of the SMP trampoline */
 static inline unsigned long trampoline_address(void)
 {
 	return virt_to_phys(TRAMPOLINE_SYM(trampoline_data));
 }
 
+static inline unsigned long trampoline_bsp_address(void)
+{
+	return virt_to_phys(TRAMPOLINE_SYM_BSP(trampoline_data_bsp));
+}
+
 #endif /* __ASSEMBLY__ */
 
 #endif /* _ASM_X86_TRAMPOLINE_H */
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index f98d84c..dec0eff 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -282,6 +282,14 @@ int get_physical_broadcast(void)
 }
 #endif
 
+unsigned int lapic_is_bsp(void)
+{
+	unsigned int msr, msr2;
+
+	rdmsr(MSR_IA32_APICBASE, msr, msr2);
+	return (MSR_IA32_APICBASE_BSP & msr);
+}
+
 /**
  * lapic_get_maxlvt - get the maximum number of local vector table entries
  */
@@ -2365,6 +2373,14 @@ static int __init parse_nolapic_timer(char *arg)
 }
 early_param("nolapic_timer", parse_nolapic_timer);
 
+static int __init parse_lapic_timer(char *arg)
+{
+	lapic_timer_frequency = simple_strtoul(arg, NULL, 0); // set the value
+	pr_info("APIC: lapic_timer_frequency set to %d\n", lapic_timer_frequency);
+	return 0;
+}
+early_param("lapic_timer", parse_lapic_timer);
+
 static int __init apic_set_verbosity(char *arg)
 {
 	if (!arg)  {
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index a25e276..72f9ae9 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -1414,10 +1414,12 @@ static int setup_ioapic_entry(int irq, struct IO_APIC_route_entry *entry,
 	return 0;
 }
 
+int unsigned pin_maskera[16] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
+
 static void setup_ioapic_irq(unsigned int irq, struct irq_cfg *cfg,
 				struct io_apic_irq_attr *attr)
 {
-	struct IO_APIC_route_entry entry;
+	struct IO_APIC_route_entry entry, tmp_entry;
 	unsigned int dest;
 
 	if (!IO_APIC_IRQ(irq))
@@ -1435,6 +1437,9 @@ static void setup_ioapic_irq(unsigned int irq, struct irq_cfg *cfg,
 
 	dest = apic->cpu_mask_to_apicid_and(cfg->domain, apic->target_cpus());
 
+	printk("%s: domain %lx target_cpus() %lx dest %x\n",
+			__func__, cpumask_bits(cfg->domain)[0],
+			cpumask_bits(apic->target_cpus())[0], dest);
 	apic_printk(APIC_VERBOSE,KERN_DEBUG
 		    "IOAPIC[%d]: Set routing entry (%d-%d -> 0x%x -> "
 		    "IRQ %d Mode:%i Active:%i Dest:%d)\n",
@@ -1453,7 +1458,23 @@ static void setup_ioapic_irq(unsigned int irq, struct irq_cfg *cfg,
 	if (irq < legacy_pic->nr_legacy_irqs)
 		legacy_pic->mask(irq);
 
-	ioapic_write_entry(attr->ioapic, attr->ioapic_pin, entry);
+	tmp_entry = ioapic_read_entry(attr->ioapic, attr->ioapic_pin);
+/*	printk("%s: READ%d-%d destM %d dest %d vect %d mask %d trig %d pol %d bsp %d[%d]\n",
+			__func__, attr->ioapic, attr->ioapic_pin,
+			tmp_entry.dest_mode, tmp_entry.dest,
+			tmp_entry.vector, tmp_entry.mask,
+			tmp_entry.trigger, tmp_entry.polarity,
+			lapic_is_bsp(), !(!lapic_is_bsp()) );
+	if(!lapic_is_bsp()) // if we are not on the bsp (the master)
+		entry.dest |= tmp_entry.dest;
+	printk("%s: WRITE%d-%d destM %d dest %d vect %d mask %d trig %d pol %d\n",
+			__func__, attr->ioapic, attr->ioapic_pin,
+			entry.dest_mode, entry.dest,
+			entry.vector, entry.mask,
+			entry.trigger, entry.polarity );
+*/
+	if ( !(!lapic_is_bsp()) ) // write only if we are on the bsp (the master)
+		ioapic_write_entry(attr->ioapic, attr->ioapic_pin, entry);
 }
 
 static bool __init io_apic_pin_not_connected(int idx, int ioapic_idx, int pin)
@@ -1466,17 +1487,34 @@ static bool __init io_apic_pin_not_connected(int idx, int ioapic_idx, int pin)
 	return true;
 }
 
-static void __init __io_apic_setup_irqs(unsigned int ioapic_idx)
+static void __init __io_apic_setup_irqs(unsigned int ioapic_idx) // this is for every ioapic_idx (considering different ioapic can be installed in the system)
 {
-	int idx, node = cpu_to_node(0);
+	int idx, node;
 	struct io_apic_irq_attr attr;
 	unsigned int pin, irq;
+	char buffer[128];
+	node = cpu_to_node(0); // note: node is always node zero! Have sense in single kernel
+//	node = boot_cpu_physical_apicid; // actually this is always correct because is what we want (APIC)
+/*	node = cpumask_first(cpu_present_mask); // This solution does not work correctly cpu_present_mask
+	cpumask_scnprintf(buffer, 128, cpu_present_mask); // is somewhere overwritten by someone else to
+	pr_info("node %d -%s-\n", node, buffer); */ // a mask of all available cpus..
+	// final note: apparently node is referred to numa, so does not influentiate mklinux
 
 	for (pin = 0; pin < ioapics[ioapic_idx].nr_registers; pin++) {
 		idx = find_irq_entry(ioapic_idx, pin, mp_INT);
-		if (io_apic_pin_not_connected(idx, ioapic_idx, pin))
+		if (io_apic_pin_not_connected(idx, ioapic_idx, pin)) // this only checks if idx is equal to -1 and printk
 			continue;
 
+		// TODO check if it is programmed or not
+		/* the following code is copyed by some other place in this file
+		hard_smp_processor_id(), boot_cpu_physical_apicid, !(!lapic_is_bsp()));
+if(!(!lapic_is_bsp())) { // this maybe substituted with a "mklinux" kernel cmd line parameter
+	printk(KERN_WARNING "clearing the IO APIC content\n");
+	clear_IO_APIC(); // the idea is that only the first kernel will clear the IO APIC content
+	*/
+
+		// idea we can skip some thing that is programmed or set a OR variable if we are not bsp
+
 		irq = pin_2_irq(idx, ioapic_idx, pin);
 
 		if ((ioapic_idx > 0) && (irq > 16))
@@ -1733,6 +1771,9 @@ __apicdebuginit(void) print_IO_APICs(void)
 
 	printk(KERN_INFO ".................................... done.\n");
 }
+void NSprint_IO_APICs(void) {
+	NSprint_IO_APICs();
+}
 
 __apicdebuginit(void) print_APIC_field(int base)
 {
@@ -1847,6 +1888,9 @@ __apicdebuginit(void) print_local_APIC(void *dummy)
 	}
 	printk("\n");
 }
+void NSprint_local_APIC(void *dummy) {
+	NSprint_local_APIC(dummy);
+}
 
 __apicdebuginit(void) print_local_APICs(int maxcpu)
 {
@@ -1985,7 +2029,12 @@ void __init enable_IO_APIC(void)
 	/*
 	 * Do not trust the IO-APIC being empty at bootup
 	 */
-	clear_IO_APIC();
+	printk(KERN_WARNING "hard_smp_processor_id=%d boot_cpu_physical_apicid=%d lapic_is_bsp=%d\n",
+			hard_smp_processor_id(), boot_cpu_physical_apicid, !(!lapic_is_bsp()));
+	if(!(!lapic_is_bsp())) { // this maybe substituted with a "mklinux" kernel cmd line parameter
+		printk(KERN_WARNING "clearing the IO APIC content\n");
+		clear_IO_APIC(); // the idea is that only the first kernel will clear the IO APIC content
+	}
 }
 
 /*
@@ -2292,6 +2341,9 @@ static void __target_IO_APIC_irq(unsigned int irq, unsigned int dest, struct irq
 	struct irq_pin_list *entry;
 	u8 vector = cfg->vector;
 
+	if (!lapic_is_bsp()) // continue remapping only on the bsp processor (master)
+		return;
+
 	for_each_irq_pin(entry, cfg->irq_2_pin) {
 		unsigned int reg;
 
@@ -2301,12 +2353,12 @@ static void __target_IO_APIC_irq(unsigned int irq, unsigned int dest, struct irq
 		 * With interrupt-remapping, destination information comes
 		 * from interrupt-remapping table entry.
 		 */
-		if (!irq_remapped(cfg))
-			io_apic_write(apic, 0x11 + pin*2, dest);
+		if (!irq_remapped(cfg)) //original code
+			io_apic_write(apic, 0x11 + pin*2, dest); // WRITE DESTINATION!!!
 		reg = io_apic_read(apic, 0x10 + pin*2);
 		reg &= ~IO_APIC_REDIR_VECTOR_MASK;
 		reg |= vector;
-		io_apic_modify(apic, 0x10 + pin*2, reg);
+		io_apic_modify(apic, 0x10 + pin*2, reg); // WRITE NEW MASK!!!
 	}
 }
 
@@ -2990,7 +3042,7 @@ void __init setup_IO_APIC(void)
 	sync_Arb_IDs();
 	setup_IO_APIC_irqs();
 	init_IO_APIC_traps();
-	if (legacy_pic->nr_legacy_irqs)
+	if (legacy_pic->nr_legacy_irqs && !(!lapic_is_bsp()))
 		check_timer();
 }
 
diff --git a/arch/x86/kernel/apic/ipi.c b/arch/x86/kernel/apic/ipi.c
index cce91bf..c9166cf 100644
--- a/arch/x86/kernel/apic/ipi.c
+++ b/arch/x86/kernel/apic/ipi.c
@@ -109,6 +109,9 @@ void default_send_IPI_mask_logical(const struct cpumask *cpumask, int vector)
 	if (WARN_ONCE(!mask, "empty IPI mask"))
 		return;
 
+/*	printk("%s: TO mask %lx vector %d dest %lx cpu_online_mask %lx\n",
+			__func__, mask, vector, apic->dest_logical, cpumask_bits(cpu_online_mask)[0]));
+*/
 	local_irq_save(flags);
 	WARN_ON(mask & ~cpumask_bits(cpu_online_mask)[0]);
 	__default_send_IPI_dest_field(mask, vector, apic->dest_logical);
diff --git a/arch/x86/kernel/head_32.S b/arch/x86/kernel/head_32.S
index ce0be7c..e87d644f 100644
--- a/arch/x86/kernel/head_32.S
+++ b/arch/x86/kernel/head_32.S
@@ -85,11 +85,11 @@ RESERVE_BRK(pagetables, INIT_MAP_SIZE)
  */
 __HEAD
 ENTRY(startup_32)
-	movl pa(stack_start),%ecx
+	movl pa(stack_start),%ecx /* load the content at relative addr pa(stack_start) to ecx */
 	
 	/* test KEEP_SEGMENTS flag to see if the bootloader is asking
 		us to not reload segments */
-	testb $(1<<6), BP_loadflags(%esi)
+	testb $(1<<6), BP_loadflags(%esi) // boot_params->hdr.loadflags &boot_params=$esi
 	jnz 2f
 
 /*
@@ -103,7 +103,7 @@ ENTRY(startup_32)
 	movl %eax,%gs
 	movl %eax,%ss
 2:
-	leal -__PAGE_OFFSET(%ecx),%esp
+	leal -__PAGE_OFFSET(%ecx),%esp //load the stack previously loaded in ecx
 
 /*
  * Clear BSS first so that there are no surprises...
diff --git a/arch/x86/kernel/i387.c b/arch/x86/kernel/i387.c
index 739d859..41b0a73 100644
--- a/arch/x86/kernel/i387.c
+++ b/arch/x86/kernel/i387.c
@@ -107,7 +107,9 @@ void __cpuinit fpu_init(void)
 		cr0 |= X86_CR0_EM;
 	write_cr0(cr0);
 
-	if (!smp_processor_id())
+	printk("%s: processor id %d\n", smp_processor_id());
+	//if (!smp_processor_id())
+	if (smp_processor_id() == boot_cpu_physical_apicid)
 		init_thread_xstate();
 
 	mxcsr_feature_mask_init();
diff --git a/arch/x86/kernel/machine_kexec_32.c b/arch/x86/kernel/machine_kexec_32.c
index a3fa43b..20d4761 100644
--- a/arch/x86/kernel/machine_kexec_32.c
+++ b/arch/x86/kernel/machine_kexec_32.c
@@ -50,6 +50,7 @@ static void set_gdt(void *newgdt, __u16 limit)
 	load_gdt(&curgdt);
 }
 
+// copyed from head_32.S (or sister file)
 static void load_segments(void)
 {
 #define __STR(X) #X
@@ -216,6 +217,9 @@ void machine_kexec(struct kimage *image)
 #endif
 	}
 
+	// copy the code in a safe place in order that it will be executed and not
+	// overwritten by the new kernel (it will not work otherwise, during copy
+	// everything will stuck
 	control_page = page_address(image->control_code_page);
 	memcpy(control_page, relocate_kernel, KEXEC_CONTROL_CODE_MAX_SIZE);
 
@@ -238,7 +242,7 @@ void machine_kexec(struct kimage *image)
 	 * I take advantage of this here by force loading the
 	 * segments, before I zap the gdt with an invalid value.
 	 */
-	load_segments();
+	load_segments(); // line 54
 	/*
 	 * The gdt & idt are now invalid.
 	 * If you want to load them you must set up your own idt & gdt.
diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index cf0ef98..c5e1d97 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -447,7 +447,7 @@ static void __init parse_setup_data(void)
 
 		switch (data->type) {
 		case SETUP_E820_EXT:
-			parse_e820_ext(data);
+			parse_e820_ext(data); //parse the bios e820 informations
 			break;
 		case SETUP_DTB:
 			add_dtb(pa_data);
@@ -673,9 +673,22 @@ static int __init parse_reservelow(char *p)
 
 	return 0;
 }
-
 early_param("reservelow", parse_reservelow);
 
+
+static int no_trampolines = 0;
+static int __init parse_notrampolines(char *p)
+{
+	unsigned long long size;
+
+//	if (!p)
+//		return -EINVAL;
+	no_trampolines =1;
+
+	return 0;
+}
+early_param("notrampolines", parse_notrampolines);
+
 /*
  * Determine if we were loaded by an EFI loader.  If so, then we have also been
  * passed the efi memmap, systab, etc., so we should use these data structures
@@ -764,7 +777,7 @@ void __init setup_arch(char **cmdline_p)
 	x86_init.oem.arch_setup();
 
 	iomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;
-	setup_memory_map();
+	setup_memory_map(); //bios provided physical memory map
 	parse_setup_data();
 	/* update the e820_saved too */
 	e820_reserve_setup_data();
@@ -907,8 +920,8 @@ void __init setup_arch(char **cmdline_p)
 
 	cleanup_highmap();
 
-	memblock.current_limit = get_max_mapped();
-	memblock_x86_fill();
+	memblock.current_limit = get_max_mapped(); // update the current_limit
+	memblock_x86_fill();  // move all ram to memblock.memory
 
 	/*
 	 * The EFI specification says that boot service code won't be called
@@ -927,12 +940,13 @@ void __init setup_arch(char **cmdline_p)
 	printk(KERN_DEBUG "initial memory mapped : 0 - %08lx\n",
 			max_pfn_mapped<<PAGE_SHIFT);
 
-	setup_trampolines();
+	setup_trampolines(no_trampolines); // 0:0x0009b000-0x0009f000 (16384 B)
+	setup_trampolines_bsp(no_trampolines);
 
-	init_gbpages();
+	init_gbpages(); // nothing todo
 
 	/* max_pfn_mapped is updated here */
-	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT);
+	max_low_pfn_mapped = init_memory_mapping(0, max_low_pfn<<PAGE_SHIFT); // actually changes the page table
 	max_pfn_mapped = max_low_pfn_mapped;
 
 #ifdef CONFIG_X86_64
@@ -969,7 +983,7 @@ void __init setup_arch(char **cmdline_p)
 	 */
 	acpi_boot_table_init();
 
-	early_acpi_boot_init();
+	early_acpi_boot_init(); // not the same as acpi_boot_init
 
 	initmem_init();
 	memblock_find_dma_reserve();
@@ -979,7 +993,7 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	x86_init.paging.pagetable_setup_start(swapper_pg_dir);
-	paging_init();
+	paging_init(); // maps pkmap in
 	x86_init.paging.pagetable_setup_done(swapper_pg_dir);
 
 	if (boot_cpu_data.cpuid_level >= 0) {
@@ -992,6 +1006,8 @@ void __init setup_arch(char **cmdline_p)
 	clone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,
 			swapper_pg_dir     + KERNEL_PGD_BOUNDARY,
 			KERNEL_PGD_PTRS);
+	// this function copy back the new part of the virtual address space to the original
+	// page table. the page table is not changed (cr3 is still the same).
 #endif
 
 	tboot_probe();
@@ -1007,7 +1023,8 @@ void __init setup_arch(char **cmdline_p)
 	/*
 	 * Read APIC and some other early information from ACPI tables.
 	 */
-	acpi_boot_init();
+	acpi_boot_init(); // this set the cpu_possible_mask and cpu_present_mask from the ACPI tables
+	                  // read the MADT and parse out the info about the local APICs
 	sfi_init();
 	x86_dtb_init();
 
@@ -1017,7 +1034,8 @@ void __init setup_arch(char **cmdline_p)
 	if (smp_found_config)
 		get_smp_config();
 
-	prefill_possible_map();
+	prefill_possible_map(); // cpu_possible_mask fill with other cpus from setup_possible_cpus, disabled_cpus...
+	prefill_present_map(); // or reset_present_map(); TODO HERE or before prefile_possible in order to set max_cpus from the present_map
 
 	init_cpu_to_node();
 
@@ -1026,7 +1044,7 @@ void __init setup_arch(char **cmdline_p)
 
 	kvm_guest_init();
 
-	e820_reserve_resources();
+	e820_reserve_resources(); //for each e820 region add it as a resource
 	e820_mark_nosave_regions(max_low_pfn);
 
 	x86_init.resources.reserve_resources();
diff --git a/arch/x86/kernel/setup_percpu.c b/arch/x86/kernel/setup_percpu.c
index 71f4727..64583a1 100644
--- a/arch/x86/kernel/setup_percpu.c
+++ b/arch/x86/kernel/setup_percpu.c
@@ -170,8 +170,10 @@ void __init setup_per_cpu_areas(void)
 	unsigned long delta;
 	int rc;
 
-	pr_info("NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%d nr_node_ids:%d\n",
-		NR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);
+/*	pr_info("NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%d nr_node_ids:%d\n",
+			NR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);
+*/	printk("%s NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%d nr_node_ids:%d\n",
+			__func__, NR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);
 
 	/*
 	 * Allocate percpu area.  Embedding allocator is our favorite;
@@ -206,10 +208,17 @@ void __init setup_per_cpu_areas(void)
 
 	/* alrighty, percpu areas up and running */
 	delta = (unsigned long)pcpu_base_addr - (unsigned long)__per_cpu_start;
+	printk("%s delta=%lx pcpu_base_addr=%lx __per_cpu_start=%lx\n",
+			__func__, delta, (unsigned long)pcpu_base_addr, (unsigned long)__per_cpu_start);
 	for_each_possible_cpu(cpu) {
 		per_cpu_offset(cpu) = delta + pcpu_unit_offsets[cpu];
 		per_cpu(this_cpu_off, cpu) = per_cpu_offset(cpu);
 		per_cpu(cpu_number, cpu) = cpu;
+/*		pr_info("CPU%d per_cpu_offset=%x this_cpu_off=%x cpu_number=%d\n",
+				cpu, per_cpu_offset(cpu), per_cpu(this_cpu_off, cpu), per_cpu(cpu_number, cpu));
+*/		printk("%s CPU%d per_cpu_offset=%lx this_cpu_off=%lx cpu_number=%d\n",
+				__func__, cpu, per_cpu_offset(cpu), per_cpu(this_cpu_off, cpu), per_cpu(cpu_number, cpu));
+
 		setup_percpu_segment(cpu);
 		setup_stack_canary_segment(cpu);
 		/*
@@ -247,11 +256,14 @@ void __init setup_per_cpu_areas(void)
 		 */
 		set_cpu_numa_node(cpu, early_cpu_to_node(cpu));
 #endif
+
 		/*
 		 * Up to this point, the boot CPU has been using .init.data
 		 * area.  Reload any changed state for the boot CPU.
 		 */
-		if (!cpu)
+		//This will happen ONLY if the cpu is booting CPU that do not have to be the ZERO
+		//if (!cpu) // PREVIOUS CODE
+		if (cpu == boot_cpu_physical_apicid)
 			switch_to_new_gdt(cpu);
 	}
 
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index 9f548cb..3c38bae 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -321,7 +321,7 @@ void __cpuinit smp_store_cpu_info(int id)
 
 	*c = boot_cpu_data;
 	c->cpu_index = id;
-	if (id != 0)
+	if (id != boot_cpu_physical_apicid)
 		identify_secondary_cpu(c);
 }
 
@@ -829,6 +829,97 @@ do_rest:
 	return boot_error;
 }
 
+///////////////////////////////////////////////////////////////////////////////
+// Multi Kernel Linux Boot Up function
+///////////////////////////////////////////////////////////////////////////////
+/*
+ * Original code from do_boot_cpu (above)
+ * check if the apicid/cpu are not used in the current kernel configuration,
+ * if true continue with booting.
+ */
+int __cpuinit mkbsp_boot_cpu(int apicid, int cpu)
+{
+	unsigned long boot_error = 0;
+	unsigned long start_ip;
+	int timeout;
+
+	// TODO TODO TODO
+	// must be setted via kexec_load
+	mkbsp_load_addr = 0x4000000; // address of startup_32 in the kernel to load
+	// TODO TODO TODO
+	// must be setted via kexec_load
+	mkbsp_boot_params = 0x13420; // boot params physical address
+
+	/* start_ip had better be page-aligned! */
+	start_ip = trampoline_bsp_address();
+
+	/*
+	 * This grunge runs the startup process for
+	 * the targeted processor.
+	 */
+
+	printk(KERN_DEBUG "smpbootLOADER MK cpu %d: start_ip = %lx (load_addr = %lx boot_params = %lx)\n",
+			cpu, start_ip, mkbsp_load_addr, mkbsp_boot_params);
+
+	if (get_uv_system_type() != UV_NON_UNIQUE_APIC) {
+
+		pr_debug("Setting warm reset code and vector.\n");
+
+		smpboot_setup_warm_reset_vector(start_ip);
+		/*
+		 * Be paranoid about clearing APIC errors.
+		*/
+		if (APIC_INTEGRATED(apic_version[boot_cpu_physical_apicid])) {
+			apic_write(APIC_ESR, 0);
+			apic_read(APIC_ESR);
+		}
+	}
+
+	/*
+	 * Kick the secondary CPU. Use the method in the APIC driver
+	 * if it's defined - or use an INIT boot APIC message otherwise:
+	 */
+	if (apic->wakeup_secondary_cpu)
+		boot_error = apic->wakeup_secondary_cpu(apicid, start_ip);
+	else
+		boot_error = wakeup_secondary_cpu_via_init(apicid, start_ip);
+
+	if (!boot_error) {
+
+		for (timeout = 0; timeout < 500; timeout++) {
+			udelay(100);
+
+			if (*(volatile u32 *)TRAMPOLINE_SYM_BSP(trampoline_status_bsp)
+			    == 0xA5A5A5A5) {
+				/* trampoline started but...? */
+				pr_err("CPU%d: Trampoline started. Stuck??\n", cpu);
+				break; // next version of the bsp loader will be much more efficient
+			}
+			else {
+				/* trampoline code not run */
+				pr_err("CPU%d: Not responding.\n", cpu);
+				boot_error = 1;
+				if (apic->inquire_remote_apic)
+								apic->inquire_remote_apic(apicid);
+			}
+
+			/*
+			 * Allow other tasks to run while we wait for the
+			 * AP to come online. This also gives a chance
+			 * for the MTRR work(triggered by the AP coming online)
+			 * to be completed in the stop machine context.
+			 */
+			schedule();
+		}
+	}
+
+	/* mark "stuck" area as not stuck */
+	*(volatile u32 *)TRAMPOLINE_SYM_BSP(trampoline_status_bsp) = 0;
+
+	return boot_error;
+}
+
+
 int __cpuinit native_cpu_up(unsigned int cpu)
 {
 	int apicid = apic->cpu_present_to_apicid(cpu);
@@ -918,7 +1009,7 @@ static int __init smp_sanity_check(unsigned max_cpus)
 	preempt_disable();
 
 #if !defined(CONFIG_X86_BIGSMP) && defined(CONFIG_X86_32)
-	if (def_to_bigsmp && nr_cpu_ids > 8) {
+	if (def_to_bigsmp && nr_cpu_idssmp_store_cpu_info > 8) {
 		unsigned int cpu;
 		unsigned nr;
 
@@ -1031,6 +1122,7 @@ static void __init smp_cpu_index_default(void)
 void __init native_smp_prepare_cpus(unsigned int max_cpus)
 {
 	unsigned int i;
+	unsigned int cpu = boot_cpu_physical_apicid;
 
 	preempt_disable();
 	smp_cpu_index_default();
@@ -1038,17 +1130,17 @@ void __init native_smp_prepare_cpus(unsigned int max_cpus)
 	/*
 	 * Setup boot CPU information
 	 */
-	smp_store_cpu_info(0); /* Final full version of the data */
-	cpumask_copy(cpu_callin_mask, cpumask_of(0));
+	smp_store_cpu_info(cpu); /* Final full version of the data */
+	cpumask_copy(cpu_callin_mask, cpumask_of(cpu));
 	mb();
 
-	current_thread_info()->cpu = 0;  /* needed? */
+	current_thread_info()->cpu = cpu;  /* needed? */
 	for_each_possible_cpu(i) {
 		zalloc_cpumask_var(&per_cpu(cpu_sibling_map, i), GFP_KERNEL);
 		zalloc_cpumask_var(&per_cpu(cpu_core_map, i), GFP_KERNEL);
 		zalloc_cpumask_var(&per_cpu(cpu_llc_shared_map, i), GFP_KERNEL);
 	}
-	set_cpu_sibling_map(0);
+	set_cpu_sibling_map(cpu);
 
 
 	if (smp_sanity_check(max_cpus) < 0) {
@@ -1090,8 +1182,8 @@ void __init native_smp_prepare_cpus(unsigned int max_cpus)
 	 * Set up local APIC timer on boot CPU.
 	 */
 
-	printk(KERN_INFO "CPU%d: ", 0);
-	print_cpu_info(&cpu_data(0));
+	printk(KERN_INFO "CPU%d: ", cpu);
+	print_cpu_info(&cpu_data(cpu));
 	x86_init.timers.setup_percpu_clockev();
 
 	if (is_uv_system())
@@ -1157,6 +1249,61 @@ static int __init _setup_possible_cpus(char *str)
 }
 early_param("possible_cpus", _setup_possible_cpus);
 
+/* TODO
+ * in the next version, copy from tilera code, they maybe have a better
+ * way to do the same things. Because you can map in and out processor from
+ * the grid.
+ */
+static DECLARE_BITMAP(setup_present_bits, CONFIG_NR_CPUS) __read_mostly;
+const struct cpumask *const setup_present_mask = to_cpumask(setup_present_bits);
+//EXPORT_SYMBOL(setup_present_mask); //not required to be public
+
+static int __init _setup_present_mask(char *str)
+{
+	cpulist_parse(str, (struct cpumask *)setup_present_mask);
+	return 0;
+}
+early_param("present_mask", _setup_present_mask);
+
+__init void prefill_present_map(void)
+{
+	int present;
+
+	//a little of checking that the mask is included in the possible cpu must be done
+	//max_cpus or the variables connected must be modified accordingly
+
+	//check if the current CPU is included in the mask if not add it
+	//then get the weight
+
+	//check present with possible
+	present = cpumask_weight(setup_present_mask);
+	printk(KERN_INFO "%s: present_cpus %d, max_cpus %d\n",
+			__func__, present, setup_max_cpus);
+
+	//we assume that present was never settedif it is 0, prefill it with setup_max_cpus (if setted)
+	if (!present) {
+		// the following code do not let the secondary kernels boot correctly
+/*		int i;
+		for (i=0; i<setup_max_cpus; i++)
+			cpumask_set_cpu(i, (struct cpumask *) setup_present_mask);
+		present = cpumask_weight(setup_present_mask);
+*/		return; //not sure to return here
+	}
+
+	// present and setup_max_cpus must be synchronized, setup_max_cpus is imposed by the user
+	// does it affects hot plug? hopefully no
+	if (present != setup_max_cpus)
+		setup_max_cpus = present;
+
+	//figure out which is the current processor and change the present subset accordingly
+	cpumask_copy((struct cpumask *)cpu_present_mask, (struct cpumask *)setup_present_mask);
+
+	//adjust online and active cpu masks
+	cpumask_clear((struct cpumask *)cpu_online_mask);
+	cpumask_set_cpu(boot_cpu_physical_apicid, (struct cpumask *)cpu_online_mask);
+	cpumask_copy((struct cpumask *)cpu_active_mask, (struct cpumask *)cpu_online_mask);
+	// TODO basically a check about the previous setting of cpu_online_mask and cpu_active_mask must be done
+}
 
 /*
  * cpu_possible_mask should be static, it cannot change as cpu's
diff --git a/arch/x86/kernel/trampoline.c b/arch/x86/kernel/trampoline.c
index a91ae77..0ef7478 100644
--- a/arch/x86/kernel/trampoline.c
+++ b/arch/x86/kernel/trampoline.c
@@ -6,8 +6,9 @@
 #include <asm/pgtable.h>
 
 unsigned char *x86_trampoline_base;
+unsigned char *x86_trampoline_bsp_base;
 
-void __init setup_trampolines(void)
+void __init setup_trampolines(int flags)
 {
 	phys_addr_t mem;
 	size_t size = PAGE_ALIGN(x86_trampoline_end - x86_trampoline_start);
@@ -22,8 +23,31 @@ void __init setup_trampolines(void)
 
 	printk(KERN_DEBUG "Base memory trampoline at [%p] %llx size %zu\n",
 	       x86_trampoline_base, (unsigned long long)mem, size);
+	if (!flags)
+		memcpy(x86_trampoline_base, x86_trampoline_start, size);
+	else
+		printk(KERN_DEBUG "no_trampolines is set, trampoline will NOT be copied\n");
+}
+
+void __init setup_trampolines_bsp(int flags)
+{
+	phys_addr_t mem;
+	size_t size = PAGE_ALIGN(x86_trampoline_bsp_end - x86_trampoline_bsp_start);
 
-	memcpy(x86_trampoline_base, x86_trampoline_start, size);
+	/* Has to be in very low memory so we can execute real-mode AP code. */
+	mem = memblock_find_in_range(0, 1<<20, size, PAGE_SIZE);
+	if (mem == MEMBLOCK_ERROR)
+		panic("Cannot allocate trampoline\n");
+
+	x86_trampoline_bsp_base = __va(mem);
+	memblock_x86_reserve_range(mem, mem + size, "TRAMPOLINE_BSP");
+
+	printk(KERN_DEBUG "Base memory trampoline BSP at [%p] %llx size %zu\n",
+	       x86_trampoline_bsp_base, (unsigned long long)mem, size);
+	if (!flags)
+		memcpy(x86_trampoline_bsp_base, x86_trampoline_bsp_start, size);
+	else
+		printk(KERN_DEBUG "no_trampolines is set, trampoline_bsp will NOT be copied\n");
 }
 
 /*
@@ -40,3 +64,12 @@ static int __init configure_trampolines(void)
 	return 0;
 }
 arch_initcall(configure_trampolines);
+
+static int __init configure_trampolines_bsp(void)
+{
+	size_t size = PAGE_ALIGN(x86_trampoline_bsp_end - x86_trampoline_bsp_start);
+
+	set_memory_x((unsigned long)x86_trampoline_bsp_base, size >> PAGE_SHIFT);
+	return 0;
+}
+arch_initcall(configure_trampolines_bsp);
diff --git a/arch/x86/kernel/trampoline_32.S b/arch/x86/kernel/trampoline_32.S
index 451c0a7..7e8d9a7 100644
--- a/arch/x86/kernel/trampoline_32.S
+++ b/arch/x86/kernel/trampoline_32.S
@@ -81,3 +81,73 @@ ENTRY(trampoline_status)
 trampoline_end:
 
 #endif /* CONFIG_SMP */
+
+//#ifdef CONFIG_MK
+
+	.section ".x86_trampoline_bsp","a"
+	.balign PAGE_SIZE
+	#.balign 32
+	.code16
+
+ENTRY(trampoline_data_bsp)
+bsp_base = .
+	wbinvd			# Needed for NUMA-Q should be harmless for others
+	mov	%cs, %ax	# Code and data in the same place
+	mov	%ax, %ds
+
+	cli			# We should be safe anyway
+
+	movl	$0xA5A5A5A5, trampoline_status_bsp - bsp_base
+				# write marker for master knows we're running
+
+	/* GDT tables in non default location kernel can be beyond 16MB and
+	 * lgdt will not be able to load the address as in real mode default
+	 * operand size is 16bit. Use lgdtl instead to force operand size
+	 * to 32 bit.
+	 */
+
+	lidtl	boot_idt_descr_bsp - bsp_base	# load idt with 0, 0
+	lgdtl	boot_gdt_descr_bsp - bsp_base	# load gdt with whatever is appropriate
+
+	movl    mkbsp_boot_params - bsp_base, %esi
+	movl    mkbsp_load_addr - bsp_base, %ebp
+	movl	%ebp, 2f - bsp_base             # self-modifying code to be relocatable (pmjump.S)
+
+	xor	%ax, %ax
+	inc	%ax		# protected mode (PE) bit
+	lmsw	%ax		# into protected mode
+
+	# Put the following code here is maybe not the best solution
+	movw $__BOOT_DS, %ax
+	movw %ax, %ds
+
+	# Transition to 32-bit mode
+	.byte	0x66, 0xea		# ljmpl selector, offset [opcode]
+2:	.long	0x04000000		# offset
+	.word	__BOOT_CS		# selector
+
+	# These need to be in the same 64K segment as the above;
+	# hence we don't use the boot_gdt_descr defined in head.S
+boot_gdt_descr_bsp:
+	.word	__BOOT_DS + 7			# gdt limit
+	.long	boot_gdt - __PAGE_OFFSET	# gdt base
+
+boot_idt_descr_bsp:
+	.word	0				# idt limit = 0
+	.long	0				# idt base = 0L
+
+	# THIS A PROTOTYPE
+	# THE FOLLOWING VALUES MUST BE CHANGED RUNTIME
+	# THE struct boot_param MUST BE DYNAMICALLY GENERATED
+ENTRY(mkbsp_load_addr)
+	.long   0x4000000       # address of startup_32 in the kernel to load
+ENTRY(mkbsp_boot_params)
+	.long   0x13420  		# boot params physical address
+
+ENTRY(trampoline_status_bsp)
+	.long	0
+
+.globl trampoline_end_bsp
+trampoline_end_bsp:
+
+//#endif /* CONFIG_MK */
diff --git a/arch/x86/kernel/vmlinux.lds.S b/arch/x86/kernel/vmlinux.lds.S
index 0f703f1..29cbc4d 100644
--- a/arch/x86/kernel/vmlinux.lds.S
+++ b/arch/x86/kernel/vmlinux.lds.S
@@ -208,6 +208,13 @@ SECTIONS
 		*(.x86_trampoline)
 		x86_trampoline_end = .;
 	}
+/*#ifdef CONFIG_MK*/
+	.x86_trampoline_bsp : AT(ADDR(.x86_trampoline_bsp) - LOAD_OFFSET) {
+		x86_trampoline_bsp_start = .;
+		*(.x86_trampoline_bsp)
+		x86_trampoline_bsp_end = .;
+	}
+/*#endif*/
 
 	.x86_cpu_dev.init : AT(ADDR(.x86_cpu_dev.init) - LOAD_OFFSET) {
 		__x86_cpu_dev_start = .;
diff --git a/arch/x86/mm/dump_pagetables.c b/arch/x86/mm/dump_pagetables.c
index 0002a3a..74b4231 100644
--- a/arch/x86/mm/dump_pagetables.c
+++ b/arch/x86/mm/dump_pagetables.c
@@ -29,6 +29,8 @@ struct pg_state {
 	pgprot_t current_prot;
 	unsigned long start_address;
 	unsigned long current_address;
+	unsigned long start_physical;
+	unsigned long current_physical;
 	const struct addr_marker *marker;
 };
 
@@ -139,7 +141,7 @@ static void printk_prot(struct seq_file *m, pgprot_t prot, int level)
 		else
 			seq_printf(m, "x  ");
 	}
-	seq_printf(m, "%s\n", level_name[level]);
+	seq_printf(m, "%s ", level_name[level]);
 }
 
 /*
@@ -200,6 +202,10 @@ static void note_page(struct seq_file *m, struct pg_state *st,
 		seq_printf(m, "%9lu%c ", delta, *unit);
 		printk_prot(m, st->current_prot, st->level);
 
+		seq_printf(m, "0x%0*lx-0x%0*lx\n",
+			   width, st->start_physical,
+			   width, st->current_physical);
+
 		/*
 		 * We print markers for special areas of address space,
 		 * such as the start of vmalloc space etc.
@@ -210,6 +216,7 @@ static void note_page(struct seq_file *m, struct pg_state *st,
 			seq_printf(m, "---[ %s ]---\n", st->marker->name);
 		}
 
+		st->start_physical = st->current_physical;
 		st->start_address = st->current_address;
 		st->current_prot = new_prot;
 		st->level = level;
@@ -310,6 +317,7 @@ static void walk_pgd_level(struct seq_file *m)
 
 	for (i = 0; i < PTRS_PER_PGD; i++) {
 		st.current_address = normalize_addr(i * PGD_LEVEL_MULT);
+		st.current_physical = (pgd_val(*start) & (0xFFFFFFFF << PAGE_SHIFT));
 		if (!pgd_none(*start)) {
 			pgprotval_t prot = pgd_val(*start) & PTE_FLAGS_MASK;
 
@@ -326,12 +334,13 @@ static void walk_pgd_level(struct seq_file *m)
 
 	/* Flush out the last page */
 	st.current_address = normalize_addr(PTRS_PER_PGD*PGD_LEVEL_MULT);
+	st.current_physical = (pgd_val(*start) & (0xFFFFFFFF << PAGE_SHIFT));
 	note_page(m, &st, __pgprot(0), 0);
 }
 
 static int ptdump_show(struct seq_file *m, void *v)
 {
-	walk_pgd_level(m);
+	walk_pgd_level(m); //main call
 	return 0;
 }
 
diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c
index 87488b9..6e0d063 100644
--- a/arch/x86/mm/init.c
+++ b/arch/x86/mm/init.c
@@ -262,6 +262,7 @@ unsigned long __init_refok init_memory_mapping(unsigned long start,
 	if (!after_bootmem)
 		find_early_table_space(end, use_pse, use_gbpages);
 
+	//map for each range the physical pages to virtual pages
 	for (i = 0; i < nr_range; i++)
 		ret = kernel_physical_mapping_init(mr[i].start, mr[i].end,
 						   mr[i].page_size_mask);
diff --git a/arch/x86/mm/pat.c b/arch/x86/mm/pat.c
index f6ff57b..cb9d39e 100644
--- a/arch/x86/mm/pat.c
+++ b/arch/x86/mm/pat.c
@@ -492,8 +492,8 @@ static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 	while (cursor < to) {
 		if (!devmem_is_allowed(pfn)) {
 			printk(KERN_INFO
-		"Program %s tried to access /dev/mem between %Lx->%Lx.\n",
-				current->comm, from, to);
+		"pat.c:%s Program %s tried to access /dev/mem between %Lx->%Lx.\n",
+			__func__, current->comm, from, to);
 			return 0;
 		}
 		cursor += PAGE_SIZE;
diff --git a/drivers/acpi/processor_driver.c b/drivers/acpi/processor_driver.c
index 9d7bc9f..75cde1a 100644
--- a/drivers/acpi/processor_driver.c
+++ b/drivers/acpi/processor_driver.c
@@ -469,7 +469,12 @@ static int __cpuinit acpi_processor_add(struct acpi_device *device)
 	}
 
 #ifdef CONFIG_SMP
-	if (pr->id >= setup_max_cpus && pr->id != 0)
+	printk(KERN_INFO
+			"pr->id %d setup_max_cpus %d nr_cpu_ids %d cpu_present %d boot %d prev_check %d curr_check %d\n",
+			pr->id, setup_max_cpus, nr_cpu_ids, cpu_present(pr->id), boot_cpu_physical_apicid,
+			(pr->id >= setup_max_cpus && pr->id != 0), ( !cpu_present(pr->id) && pr->id != boot_cpu_physical_apicid));
+//	if (pr->id >= setup_max_cpus && pr->id != 0)
+	if ( !cpu_present(pr->id) && pr->id != boot_cpu_physical_apicid)
 		return 0;
 #endif
 
diff --git a/drivers/ata/libata-sff.c b/drivers/ata/libata-sff.c
index 4cadfa2..d55638f 100644
--- a/drivers/ata/libata-sff.c
+++ b/drivers/ata/libata-sff.c
@@ -1715,6 +1715,10 @@ void ata_sff_lost_interrupt(struct ata_port *ap)
 	   no interrupt. */
 	ata_port_warn(ap, "lost interrupt (Status 0x%x)\n",
 								status);
+
+	//NSprint_local_APIC(0);
+	//NSprint_IO_APICs();
+
 	/* Run the host interrupt logic as if the interrupt had not been
 	   lost */
 	ata_sff_port_intr(ap, qc);
diff --git a/drivers/char/mem.c b/drivers/char/mem.c
index 1451790..b6cef31 100644
--- a/drivers/char/mem.c
+++ b/drivers/char/mem.c
@@ -67,7 +67,7 @@ static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 	while (cursor < to) {
 		if (!devmem_is_allowed(pfn)) {
 			printk(KERN_INFO
-		"Program %s tried to access /dev/mem between %Lx->%Lx.\n",
+		"mem.c:%s Program %s tried to access /dev/mem between %Lx->%Lx.\n", __func__,
 				current->comm, from, to);
 			return 0;
 		}
@@ -331,6 +331,56 @@ static int mmap_mem(struct file *file, struct vm_area_struct *vma)
 	return 0;
 }
 
+/* note
+ * crashkernel=size@addr require the following function to be accessed from user space
+ * (i.e. ioremap is required). reserving with mem=end memmap=size$end does not
+ * require this function. it is actually not very clear to me the difference between
+ * the two kernel arguments.
+ */
+static int mmap_unmap(struct file *file, struct vm_area_struct *vma)
+{
+	size_t size = vma->vm_end - vma->vm_start;
+
+	//supported on the following arch: sh, ia64, arm  (otherwise always succed)
+	if (!valid_mmap_phys_addr_range(vma->vm_pgoff, size))
+		return -EINVAL;
+	//mostly returns 1 (success)
+	if (!private_mapping_ok(vma))
+		return -ENOSYS;
+	//the following filter the access based on devmem_is_allowed (arch/x86/mm/init.c) requires CONFIG_STRICT_DEVMEM (otherwise always succed)
+	if (!range_is_allowed(vma->vm_pgoff, size))
+		return -EPERM;
+	//from arch/x86/mm/pat.c internally calls range_is_allowed (arch/x86/mm/pat.c, same function as declared here)
+	if (!phys_mem_access_prot_allowed(file, vma->vm_pgoff, size,
+						&vma->vm_page_prot)) {
+		void * unmap = ioremap_cache(vma->vm_pgoff, size);
+		printk(KERN_INFO
+				"mem.c:%s ioremap_cache returns %p\n",
+				__func__, unmap);
+		if (!unmap)
+			return -EINVAL;
+	}
+
+	// returns vma->vm_page_prot; (also declared here)
+	vma->vm_page_prot = phys_mem_access_prot(file, vma->vm_pgoff,
+						 size,
+						 vma->vm_page_prot);
+
+	vma->vm_ops = &mmap_mem_ops;
+
+	// NOTE THE FOLLOWING (remap_pfn_range does not care about )
+	/* Remap-pfn-range will mark the range VM_IO and VM_RESERVED */
+	if (remap_pfn_range(vma,
+			    vma->vm_start,
+			    vma->vm_pgoff,
+			    size,
+			    vma->vm_page_prot)) {
+		return -EAGAIN;
+	}
+	return 0;
+}
+
+
 #ifdef CONFIG_DEVKMEM
 static int mmap_kmem(struct file *file, struct vm_area_struct *vma)
 {
@@ -749,6 +799,15 @@ static const struct file_operations mem_fops = {
 	.get_unmapped_area = get_unmapped_area_mem,
 };
 
+static const struct file_operations unmap_fops = {
+//	.llseek		= memory_lseek,
+//	.read		= read_mem,
+//	.write		= write_mem,
+	.mmap		= mmap_unmap,
+	.open		= open_mem,
+//	.get_unmapped_area = get_unmapped_area_mem,
+};
+
 #ifdef CONFIG_DEVKMEM
 static const struct file_operations kmem_fops = {
 	.llseek		= memory_lseek,
@@ -867,6 +926,7 @@ static const struct memdev {
 #ifdef CONFIG_CRASH_DUMP
 	[12] = { "oldmem", 0, &oldmem_fops, NULL },
 #endif
+	[13] = { "unmap", 0, &unmap_fops, NULL},
 };
 
 static int memory_open(struct inode *inode, struct file *filp)
diff --git a/drivers/char/tools/dev_mem_test.c b/drivers/char/tools/dev_mem_test.c
new file mode 100644
index 0000000..a094612
--- /dev/null
+++ b/drivers/char/tools/dev_mem_test.c
@@ -0,0 +1,66 @@
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdarg.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/sysmacros.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <asm/boot.h>
+#include <errno.h>
+
+
+int main(int argc, char ** argv)
+{
+	//char * fp = "/dev/mem";
+	char * fp = "/dev/unmap";
+	off_t offset = 0x4000000;
+	//off_t offset = 0xa0000;
+	int fd;
+	struct stat sb;
+	void *kernel;
+	int sz;
+	int size;
+
+	//command line mmap_test device address [size]
+
+	if ((argc < 3) || (argc > 4)) {
+		printf("usage: %s device address [size]\n", argv[0]);
+		return 0;
+	}
+	//argv[1] device path
+	//argv[2] address
+	//argv[3] size
+	sscanf(argv[2], "%p", &offset); // check for failure
+
+	if (argc == 4)
+		sscanf(argv[3], "%d", &size);
+	else
+		size = 1024;
+
+	fp = argv[1];
+
+	printf("opening: %s at %p size %d\n",
+			argv[1], offset, size);
+	fd = open(fp, O_RDONLY);
+	if (fd < 0)
+		printf("Unable to open `%s': %m\n", fp, fd);
+
+	if (fstat(fd, &sb))
+		printf("Unable to stat `%s': %m", fp, fd);
+
+	sz = sb.st_size;
+	printf ("System is %d kB (%d B)\n", (sz+1023)/1024, sz);
+
+	kernel = mmap(NULL, 1024, PROT_READ, MAP_SHARED, fd, offset);
+	printf("void * kernel is %p @ phys %p\n", kernel, offset);
+	if (((unsigned long) kernel) == -1)
+	  perror("mmap error");
+
+	close(fd);
+
+	/* Everything is OK */
+	return 0;
+}
diff --git a/drivers/pci/probe.c b/drivers/pci/probe.c
index dfee1b3..39cf9c3 100644
--- a/drivers/pci/probe.c
+++ b/drivers/pci/probe.c
@@ -1227,6 +1227,101 @@ void pci_device_add(struct pci_dev *dev, struct pci_bus *bus)
 	up_write(&pci_bus_sem);
 }
 
+struct pci_dev_blacklist_item {
+	unsigned short vendor;
+	unsigned short device;
+	unsigned int flags;
+};
+#define BL 16
+static struct pci_dev_blacklist_item
+pci_dev_blacklist[BL] = { {0,0,0},{0,0,0},{0,0,0},{0,0,0},
+						{0,0,0},{0,0,0},{0,0,0},{0,0,0},
+						{0,0,0},{0,0,0},{0,0,0},{0,0,0},
+						{0,0,0},{0,0,0},{0,0,0},{0,0,0} };
+static int pci_dev_blacklist_elements = 0;
+
+int pci_dev_list_add(int compatible, char *vendor, char *model,
+		char *strflags, int flags)
+{
+	int i;
+
+	// we statically allocated the blacklist array in order to avoid
+	// an early call to kmalloc that maybe cannot serve the request
+	if (!((i = pci_dev_blacklist_elements) < BL))
+		return -ENOMEM;
+
+	pci_dev_blacklist[i].vendor = (unsigned short)simple_strtoul(vendor, NULL, 0);
+	pci_dev_blacklist[i].device = (unsigned short)simple_strtoul(model, NULL, 0);
+	pci_dev_blacklist[i].flags = (unsigned int)simple_strtoul(strflags, NULL, 0);
+
+	printk(KERN_INFO "%s: [%x,%x] blacklisted with flags 0x%08x\n", __func__,
+			pci_dev_blacklist[i].vendor, pci_dev_blacklist[i].device, pci_dev_blacklist[i].flags);
+	pci_dev_blacklist_elements++;
+	return i;
+}
+
+/*
+ * The list must be in the format
+ * pci_dev_flags=vendor:device:flags,[v,d,f]
+ * a simple example that blacklist the IDE device is
+ * pci_dev_flags=8086:7010:b
+ */
+static int pci_dev_add_str(char *dev_list)
+{
+	char *vendor, *device, *strflags;
+	char *next, *next_check;
+	int res = 0;
+
+	next = dev_list;
+	if (next && next[0] == '"') {
+		// Ignore both the leading and trailing quote.
+		next++;
+		next_check = ",\"";
+	} else {
+		next_check = ",";
+	}
+
+	/*
+	 * For the leading and trailing '"' case, the for loop comes
+	 * through the last time with vendor[0] == '\0'.
+	 */
+	for (vendor = strsep(&next, ":");
+			vendor && (vendor[0] != '\0') && (res == 0);
+			vendor = strsep(&next, ":")) {
+		strflags = NULL;
+		device = strsep(&next, ":");
+		if (device)
+			strflags = strsep(&next, next_check);
+			if (!device || !strflags) {
+				printk(KERN_ERR "%s: bad dev info string '%s' '%s'"
+						" '%s'\n", __func__, vendor, device,
+						strflags);
+				res = -EINVAL;
+			} else
+				res = pci_dev_list_add(0 /* compatible */, vendor,
+						device, strflags, 0);
+	}
+	return res;
+}
+
+static int __init parse_pci_dev_flags(char *argv)
+{
+	return pci_dev_add_str(argv);
+}
+early_param("pci_dev_flags", parse_pci_dev_flags);
+//__setup("pci_dev_flags", parse_pci_dev_flags);
+
+static int pci_device_blacklisted(struct pci_dev *dev)
+{
+	int i;
+
+	for (i=0; i<pci_dev_blacklist_elements; i++)
+		if (dev->vendor == pci_dev_blacklist[i].vendor &&
+			dev->device == pci_dev_blacklist[i].device)
+				return (i +1);
+	return 0;
+}
+
 struct pci_dev *__ref pci_scan_single_device(struct pci_bus *bus, int devfn)
 {
 	struct pci_dev *dev;
@@ -1241,6 +1336,12 @@ struct pci_dev *__ref pci_scan_single_device(struct pci_bus *bus, int devfn)
 	if (!dev)
 		return NULL;
 
+	if (pci_device_blacklisted(dev)) {
+		printk(KERN_INFO "%s: [%x,%x] device blacklisted\n", __func__,
+				dev->vendor, dev->device);
+		return NULL;
+	}
+
 	pci_device_add(dev, bus);
 
 	return dev;
diff --git a/drivers/tty/serial/8250.c b/drivers/tty/serial/8250.c
index eeadf1b..b6295b1 100644
--- a/drivers/tty/serial/8250.c
+++ b/drivers/tty/serial/8250.c
@@ -3319,6 +3319,9 @@ static int __init serial8250_init(void)
 	if (ret)
 		goto put_dev;
 
+	if (!lapic_is_bsp())
+		return ret;
+
 	serial8250_register_ports(&serial8250_reg, &serial8250_isa_devs->dev);
 
 	ret = platform_driver_register(&serial8250_isa_driver);
diff --git a/drivers/tty/vty.c b/drivers/tty/vty.c
new file mode 100644
index 0000000..02f6010a
--- /dev/null
+++ b/drivers/tty/vty.c
@@ -0,0 +1,277 @@
+Peng prototype
+
+#include<linux/module.h>
+#include<linux/init.h>
+#include<linux/kernel.h>
+#include<linux/slab.h>
+#include<linux/string.h>
+#include<linux/spinlock.h>
+#include<linux/highmem.h>
+#include<linux/mm.h>
+#include<linux/rmap.h>
+#include<asm/io.h>
+
+#include "vty.h"
+
+MODULE_LICENSE("GPL");
+
+#define SUCCESS 0
+#define FAILURE -1
+#define BUF_SIZE 10
+
+rwlock_t spin;
+
+struct shared_mem
+{
+	struct packet *packets[BUF_SIZE];
+	int current_pos;
+};
+
+struct shared_mem *shrm;
+EXPORT_SYMBOL(shrm);
+
+static int push_packet_into_buffer(struct packet *pckt)
+{
+	write_lock(&spin);
+	if(shrm->current_pos < 0 || shrm->current_pos >= 100)
+	{
+		shrm->current_pos = 0;
+	}
+	shrm->packets[shrm->current_pos] = pckt;
+	printk(KERN_ALERT "Writing packet in %d  from %s\n",shrm->current_pos,__func__);
+	shrm->current_pos += 1;
+	write_unlock(&spin);
+	return SUCCESS;
+}
+EXPORT_SYMBOL(push_packet_into_buffer);
+
+static int pop_packet_from_buffer(int position,struct packet **dest_pckt)
+{
+	read_lock(&spin);
+	memcpy(*dest_pckt, shrm->packets[position],sizeof(struct packet));
+	shrm->packets[position] = NULL;
+	read_unlock(&spin);
+	return SUCCESS;
+}
+EXPORT_SYMBOL(pop_packet_from_buffer);
+
+static int get_data_location(int order,int *arr)
+{
+	if(shrm->current_pos <= 0)
+		return 0;
+	struct packet *pckt;
+	int counter;
+	int p = 0 ;
+	read_lock(&spin);
+	for(counter = 0 ; counter < shrm->current_pos; ++counter)
+	{
+		pckt = shrm->packets[counter];
+		if(pckt->destination == order)
+		{
+			*(arr+p) = counter;
+			++p;
+		}
+	}
+	read_unlock(&spin);
+	return p;
+}
+EXPORT_SYMBOL(get_data_location);
+
+static int __init vty_init(void)
+{
+	printk(KERN_ALERT "Loading shared memory %s",__func__);
+
+	void * poff= (void *)0xc0000000; // 3GGB
+	size_t size = 0x00200000; // 2MB
+	void * virtual_address;
+
+	unsigned long pfn = (long)poff >> PAGE_SHIFT;
+	unsigned long node= -1, nid= -1;
+	// check local? (global is better) limits
+	for_each_online_node(nid) {
+		unsigned long start_pfn, end_pfn;
+		start_pfn = node_start_pfn(nid);
+		end_pfn = node_end_pfn(nid);
+		if ((start_pfn <= pfn) && (pfn < end_pfn)) {
+			node = nid;
+			break; // node found continue
+		}
+		printk(KERN_ALERT"node %ld pfn start %ld end %ld\n", nid, start_pfn, end_pfn);
+	}
+
+	//NOTA: this code does not create a new page table entry for the frame
+	//REFLECTION: I do not think we really need a new ioremap_cache for the RAM right now
+	//TODO: the physical address must be customizable
+
+	if (node == -1) { // page never mapped (why?)
+		printk("%s: the page is not mapped on any node/page table\n", __func__);
+
+		//ioremap cache is used for pci devices TODO reimplement it to support memory that is not mapped in the page table
+		//ioremap_cache is in arch/x86/mm/ioremap.c and calls __ioremap_caller
+		virtual_address = ioremap_cache((resource_size_t)poff, size);
+
+		// TODO must be iounmap at the end of the usage
+
+		printk(KERN_ALERT"%s: ioremap_cache returns %p\n", __func__, virtual_address);
+	}
+	else { // the page is in the page table i.e. has a struct page
+
+		// pfn_to_page does not check for the page existence check it
+		// pfn_to_page is in include/asm-generic/memory_model.h
+		struct page *shared_page  =  pfn_to_page(pfn);
+
+		printk(KERN_ALERT "phys %p pfn %lx shift %d page %p\n", poff, (long)poff >> PAGE_SHIFT, PAGE_SHIFT, shared_page);
+
+		virtual_address = page_address(shared_page);
+		void * kmap_addr = kmap(shared_page); //kmap calls page_address
+
+		if (kmap_addr != virtual_address) {
+			printk(KERN_ALERT "Virtual address %p %p are not the same ERROR\n",virtual_address,kmap_addr);
+			return -1;
+		}
+
+		//TODO do we have to check if the page is really mapped?!?!
+		//page_mapcount(page ) ?!?! OR page_mapped(page) FROM include/linu/mm.h
+
+		// following code from mm/memory-failure.c (collect_procs_anon or collect_procs_file )
+
+		if (PageAnon(page)) {
+			// Page is ANON
+			struct anon_vma * av = page_lock_anon_vma(page);
+			if (av == NULL)	/* Not actually mapped anymore */
+				return;
+
+			// THIS PART IS CRITICAL .. we do not want to scan all the task
+			// this will be plan B
+
+//			read_lock(&tasklist_lock);
+//			for_each_process (tsk) {
+
+			// NOTE FOR PENG:
+			// we can do heuristics on each level: vma, vm_mm and tsk
+
+			struct anon_vma_chain *vmac;
+			struct vm_area_struct *vma;
+			struct mm_struct *vm_mm;
+			struct task_struct *tsk;
+//				if (!task_early_kill(tsk))
+//					continue;
+			list_for_each_entry(vmac, &av->head, same_anon_vma) {
+					vma = vmac->vma;
+
+					if (!page_mapped_in_vma(page, vma))
+						continue; // error page is not really mapped
+
+					vm_mm =vma->vm_mm;
+
+					// can I perform some testing on vm_mm? TODO
+
+					tsk = vm_mm->owner;
+
+					// can I perform some testing on tsk? Is still alive? TODO
+
+					printk("tsk is %p vm_mm is %p vma is %p\n");
+
+//					if (vma->vm_mm == tsk->mm)
+//						add_to_kill(tsk, page, vma, to_kill, tkc);
+				}
+//			}
+//			read_unlock(&tasklist_lock);
+
+			page_unlock_anon_vma(av);
+
+		} else
+		{
+			// Page is FILE
+			struct vm_area_struct *vma;
+			struct task_struct *tsk;
+			struct prio_tree_iter iter;
+			struct address_space *mapping = page->mapping;
+
+			mutex_lock(&mapping->i_mmap_mutex);
+//			read_lock(&tasklist_lock);
+//			for_each_process(tsk) {
+				pgoff_t pgoff = page->index << (PAGE_CACHE_SHIFT - PAGE_SHIFT);
+
+//				if (!task_early_kill(tsk))
+//					continue;
+
+				vma_prio_tree_foreach(vma, &iter, &mapping->i_mmap, pgoff,
+						      pgoff) {
+					/*
+					 * Send early kill signal to tasks where a vma covers
+					 * the page but the corrupted page is not necessarily
+					 * mapped it in its pte.
+					 * Assume applications who requested early kill want
+					 * to be informed of all such data corruptions.
+					 */
+
+					vm_mm = vma->vm_mm;
+					tsk = vm_mm->owner;
+//					if (vma->vm_mm == tsk->mm)
+//						add_to_kill(tsk, page, vma, to_kill, tkc);
+				}
+//			}
+//			read_unlock(&tasklist_lock);
+			mutex_unlock(&mapping->i_mmap_mutex);
+		}
+
+// following code is superseeded by the above code! :-P
+//		struct anon_vma *gigio = page_get_anon_vma(shared_page); //
+//		printk(KERN_ALERT "Virtual address %p %p %p\n",virtual_address,kmap_addr, gigio);
+
+
+		// IDEAs
+		// 1. migrate an entire vma_struct  (that is a contiguous virtual area of memory) see /proc/pid/maps
+		// that contains the physical address threashold in size
+		// 2. migrate that vma_sruct and the contiguous one only if are both of the same type anon or file
+		// 3. if there are different task holding the same page what to do?!?!
+		// 4. before listing for copy we must check that the page MUST be checked (imagine if was copied before or not dirty)
+		// 5. if one physical is contained in different task we can copy some pages (threshold) for each task (priorities?) hor81palo
+
+
+		// TODO
+		//how to revert back the addresses from vm_area_struct to physical address (depends on the current process mapped in)
+		vm_normal_page // an alternative to go back to the struct page requires remapping from mm/memory.c
+		follow_page
+
+		//interesting example in __access_remote_vm IN mm/memoery.c
+
+
+	}
+
+	int * mimmo1 = (int *)virtual_address;
+
+	*mimmo1 = 1234;
+
+	printk(KERN_ALERT "The value is %d \n", *mimmo1);
+
+	/*
+	//supported on the following arch: sh, ia64, arm  (otherwise always succed)
+	if (!valid_mmap_phys_addr_range(poff, size))
+		return -EINVAL;
+	//the following filter the access based on devmem_is_allowed (arch/x86/mm/init.c) requires CONFIG_STRICT_DEVMEM (otherwise always succed)
+	if (!range_is_allowed(poff, size))
+		return -EPERM;
+*/
+	rwlock_init(&spin);
+	shrm = (struct shared_mem *)kmalloc(sizeof(struct shared_mem), GFP_KERNEL);
+	if(shrm == NULL)
+	{
+		printk(KERN_ALERT "Memory allocation is failed %s\n", __func__);
+		return -ENOMEM;
+	}
+
+	printk(KERN_ALERT "Memory Allocation is successful\n");
+	shrm->current_pos = 0;
+	return SUCCESS;
+}
+
+static void __exit vty_exit(void)
+{
+	kfree(shrm);
+	printk(KERN_ALERT "Unloading shared memory\n");
+}
+
+module_init(vty_init);
+module_exit(vty_exit);
diff --git a/include/linux/kexec.h b/include/linux/kexec.h
index 2fa0901..239b4bb 100644
--- a/include/linux/kexec.h
+++ b/include/linux/kexec.h
@@ -175,6 +175,9 @@ extern struct kimage *kexec_crash_image;
 
 #define KEXEC_ON_CRASH		0x00000001
 #define KEXEC_PRESERVE_CONTEXT	0x00000002
+#define KEXEC_FORCE_CRASH	0x00000004
+// force the kernel to be loaded to the crashkernel hole
+
 #define KEXEC_ARCH_MASK		0xffff0000
 
 /* These values match the ELF architecture values.
@@ -194,9 +197,9 @@ extern struct kimage *kexec_crash_image;
 
 /* List of defined/legal kexec flags */
 #ifndef CONFIG_KEXEC_JUMP
-#define KEXEC_FLAGS    KEXEC_ON_CRASH
+#define KEXEC_FLAGS    (KEXEC_ON_CRASH | KEXEC_FORCE_CRASH )
 #else
-#define KEXEC_FLAGS    (KEXEC_ON_CRASH | KEXEC_PRESERVE_CONTEXT)
+ -0=#define KEXEC_FLAGS    (KEXEC_ON_CRASH | KEXEC_PRESERVE_CONTEXT)
 #endif
 
 #define VMCOREINFO_BYTES           (4096)
diff --git a/include/linux/reboot.h b/include/linux/reboot.h
index e0879a7..9a1cb90 100644
--- a/include/linux/reboot.h
+++ b/include/linux/reboot.h
@@ -33,6 +33,7 @@
 #define	LINUX_REBOOT_CMD_RESTART2	0xA1B2C3D4
 #define	LINUX_REBOOT_CMD_SW_SUSPEND	0xD000FCE2
 #define	LINUX_REBOOT_CMD_KEXEC		0x45584543
+#define	LINUX_REBOOT_CMD_MKBSP		0xDEAD5E55
 
 
 #ifdef __KERNEL__
diff --git a/init/main.c b/init/main.c
index 217ed23..c8dd32e 100644
--- a/init/main.c
+++ b/init/main.c
@@ -500,7 +500,7 @@ asmlinkage void __init start_kernel(void)
 	mm_init_owner(&init_mm, &init_task);
 	mm_init_cpumask(&init_mm);
 	setup_command_line(command_line);
-	setup_nr_cpu_ids();
+	setup_nr_cpu_ids(); //requires cpu_possible_mask setted up (in setup_arch, acpi_boot_init)
 	setup_per_cpu_areas();
 	smp_prepare_boot_cpu();	/* arch-specific boot-cpu hooks */
 
diff --git a/ipc/Makefile b/ipc/Makefile
index 9075e17..ce9dcc0 100644
--- a/ipc/Makefile
+++ b/ipc/Makefile
@@ -6,7 +6,6 @@ obj-$(CONFIG_SYSVIPC_COMPAT) += compat.o
 obj-$(CONFIG_SYSVIPC) += util.o msgutil.o msg.o sem.o shm.o ipcns_notifier.o syscall.o
 obj-$(CONFIG_SYSVIPC_SYSCTL) += ipc_sysctl.o
 obj_mq-$(CONFIG_COMPAT) += compat_mq.o
-obj-$(CONFIG_POSIX_MQUEUE) += mqueue.o msgutil.o $(obj_mq-y)
+obj-$(CONFIG_POSIX_MQUEUE) += mqueue.o msgutil.o $(obj_mq-y) mcomm.o
 obj-$(CONFIG_IPC_NS) += namespace.o
 obj-$(CONFIG_POSIX_MQUEUE_SYSCTL) += mq_sysctl.o
-
diff --git a/ipc/mcomm.c b/ipc/mcomm.c
new file mode 100644
index 0000000..1dc327a
--- /dev/null
+++ b/ipc/mcomm.c
@@ -0,0 +1,433 @@
+
+#ifndef CACHE_ALIGNED
+ #define CACHE_ALIGNED
+#endif
+
+#include "buffer.h"
+#ifdef USE_MBUFFER
+ #include "mbuffer.h"
+#endif /* USE_MBUFFER */
+
+#include "mcomm.h"
+
+static unsigned long mcomm_address = 0x0000;
+
+/// allocator
+
+#define get_node_from_cpu(id) 0
+
+#define alloc_private(size, node) __alloc_private(size, node)
+#define alloc_global(size) __alloc_on_node(size, -1)
+#define alloc_on_node(size, node) __alloc_on_node(size, node)
+#define free_on_node(addr) __free_on_node(addr)
+
+// KRN SHM
+#define INIT_SIZE 0x100000
+unsigned long alloc_size = INIT_SIZE;
+unsigned long alloc_addr = 0xbadabada;
+
+// KRN SHM
+static int alloc_init(void* poff, int size)
+{
+	void * virtual_address;
+
+    printk(KERN_ALERT "Poff %llx and %ld\n",poff,size);
+
+    unsigned long pfn = (long) poff >> PAGE_SHIFT;
+    unsigned long psize = (size) ? size : alloc_size;
+    unsigned long node = -1, nid = -1; // TODO
+
+    if (alloc_size != psize)
+    	alloc_size = psize;
+
+/* check if the memory is mapped in any zone of the current
+ * kernel instance. In such a case the memory will not be mapped
+ * because mapped in the memory page table array.
+ */
+    for_each_online_node(nid) {
+            unsigned long start_pfn, end_pfn;
+            start_pfn = node_start_pfn(nid);
+            end_pfn = node_end_pfn(nid);
+            if ((start_pfn <= pfn) && (pfn < end_pfn)) {
+                    node = nid;
+                    break; // node found continue
+            }
+    }
+
+    if (node == -1) { // page never mapped (why?)
+    	 virtual_address = ioremap_cache(
+    			 (resource_size_t)((void *) poff + (i * size)), size);
+    } else {
+    	struct page *shared_page;
+    	shared_page = pfn_to_page(pfn);
+    	virtual_address = page_address(shared_page);
+    	void * kmap_addr = kmap(shared_page);
+    }
+
+    alloc_addr = virtual_addr;
+	return 0;
+}
+
+void* __alloc_on_node(size_t size, int node)
+{
+	int asize = 0x20000; // TODO check
+	int anode = node +1;
+	void* shmaddr = alloc_addr + (anode * asize);
+
+	if (size > asize)
+		printk(KERN_ERR"%s: size %d asize %d ERROR\n", __func__);
+
+	return shmaddr;
+}
+
+
+
+/// matrix memory
+
+static int matrix_init_matrix (matrix_comm ** pmatrix, int elements)
+{
+	char matrix_magic[]= MAGIC_CHARS_MATR;
+	int need_init =0;
+
+	// actual matrix that takes care about the mapping
+	//matrix_comm * matrix = (matrix_comm *)alloc_global(sizeof(matrix_comm));
+	matrix_comm * matrix = (matrix_comm *)alloc_global(sizeof(matrix_comm));
+	if (!matrix) {
+		printk(KERN_ERR "%s: error allocating matrix_comm\n",
+				__func__);
+ 		return -1;
+	}
+
+	// check if the area was allocated before
+	if ( memcmp(matrix, matrix_magic, 4) == 0) {
+		// it was initialized before, sanity checks
+		if (matrix->elements != elements) {
+			printk(KERN_ERR "%s: matrix elements not correspond %d %d\n",
+					__func__, matrix->elements, elements);
+			return -1;
+		}
+	}
+	else {
+		// it was never initialized before,
+		need_init =1;
+
+		//Initialize the main matrix descriptor
+		memcpy(matrix, matrix_magic, 4);
+		matrix->elements = elements;
+		matrix->lock = 0;
+		memset (&(matrix->present), 0, sizeof(bitmask_t));
+		memset (&(matrix->desc[0]), 0, sizeof(void*) * elements);
+	}
+
+	if (pmatrix)
+		*pmatrix = matrix;
+
+	return need_init;
+}
+
+static int matrix_init_row (row_comm ** prow, matrix_comm * matrix,
+		int size, int need_init, int id, int elements)
+{
+	char row_magic[]= MAGIC_CHARS_ROW;
+	int l;
+	int need_init_cell =0;
+
+	/* this code will not use bbuffer_init */
+	int bbuf_pad_size = size;
+#ifdef CACHE_ALIGNED
+	bbuf_pad_size = BBUFFER_SPACE(size);
+#endif /* CACHE_ALIGNED */
+	BBUFFER_CHECK(bbuf_pad_size);
+
+	/* for each cpu there is a vector of recveirs buffers */
+	int bbuf_size = BBUFFER_SIZEOF(bbuf_pad_size);
+	int row_memory =
+			sizeof(row_comm) + (bbuf_size * elements);
+
+
+	// we need to pass the cpuid in order to get the right shm area
+	// is the alloc function that has to figure out the correct mem zone
+	row_comm * row = (row_comm * ) alloc_on_node(row_memory, id);
+	if ( !(row) ) {
+		printk(KERN_ERR"%s: error allocating row_comm\n",
+				__func__);
+		return 0;
+	}
+	CHECK_CACHE_ALIGNED(row);
+	matrix->desc[id] = row; // TODO
+
+	// if init is not required check if the area was allocated before
+	if ( !need_init && (memcmp(row, row_magic, 4) == 0)) {
+		need_init_cell=0;
+
+		// it was initialized before, sanity checks
+		if (row->elements != elements) {
+			printk(KERN_ERR "%s: row elements not correspond %d %d\n",
+					__func__, row->elements, elements);
+			return 0;
+		}
+		if (row->csize != bbuf_size) {
+			printk(KERN_ERR "%s: size not correspond %d %d\n",
+					__func__, row->csize, bbuf_size);
+			return 0;
+		}
+	}
+	else {
+		// it was never initialized before
+		need_init_cell =1;
+
+		memcpy(row, row_magic, 4);
+		row->elements = elements;
+		row->id = id;
+		row->lock = 0;
+
+		memset(&(row->status), 0, sizeof(bitmask_t) * MAX_BITMAP);
+		memset(&(row->active), 0, sizeof(bitmask_t) * MAX_BITMAP);
+		memset(&(row->offset), 0, sizeof(unsigned long) * MAX_ELEMENTS);
+
+		row->csize = bbuf_size;
+		row->cnumber = 0;
+	}
+
+	// check the alignment
+	CHECK_CACHE_ALIGNED( (&(row->status)) );
+
+	bbuffer_t * pbbuf = (bbuffer_t*)&(row[1]);
+	CHECK_CACHE_ALIGNED( pbbuf );
+
+	// init local data structures if required
+	if (need_init_cell)
+		for (l=0; l<elements; l++) {
+			BBUFFER_INIT(pbbuf, bbuf_pad_size);
+
+			row->offset[l] =
+					(unsigned long)pbbuf - (unsigned long)((bbuffer_t*)&(row[1]));
+			pbbuf = (bbuffer_t*)((void*)pbbuf + bbuf_size);
+
+			set_bit_bitmap(&(row->active[0]), l);
+		}
+
+	if (prow)
+		*prow = row;
+
+	return need_init_cell;
+}
+
+/*
+ * size is the size of a single message cell buffer
+ * elements is the maximum number of rows or columns
+ *
+ * The returned value refer to a private local comm_mapping struct
+ * such data structure saves the mappings of the different memory areas
+ */
+comm_mapping * matrix_init_mapping (int size, int elements )
+{
+	int i, l;
+	int need_init =0, need_init_cell =0;
+
+	char matrix_magic[]= MAGIC_CHARS_MATR;
+	char row_magic[]= MAGIC_CHARS_ROW;
+
+	matrix_comm * matrix;
+
+	/* arguments checks */
+	if ((elements < 1) || (elements > MAX_CPUS) || !(size))
+		return 0;
+
+	need_init = matrix_init_matrix( &matrix, elements);
+	if (need_init == -1)
+		return 0;
+
+	// create a comm_mapping descriptor
+	comm_mapping * map = (comm_mapping*)
+			alloc_private(sizeof(comm_mapping), -1);
+	if (!map) {
+		printk(KERN_ERR "%s: error allocating comm_mapping id %d\n",
+				__func__, -1);
+		return 0;
+	}
+	memset (map, 0, sizeof(comm_mapping));
+	map->matrix = matrix;
+
+
+	// allocate and init local data structures
+	for (i=0; i<elements; i++) {
+
+		row_comm * row;
+		int need_init_cell = matrix_init_row (&row, matrix,
+						size, need_init, i, elements);
+		if ( need_init_cell == -1 )
+			return 0;
+
+		// save the private mapping
+		map->row[i] = row;
+		map->bmp[i] = &(row->status[0]);
+		map->buf[i] = (bbuffer_t *) &(row[1]);
+
+		// set the global descriptor
+		set_bit_bitmap(&(matrix->present[0]), i); // TODO move this to next function?
+	}
+
+	return map;
+}
+
+/*
+ * This function assumes that a previous call to matrix_init_mapping was issued
+ * and the shared data areas are mapped to memory (shared data areas corrensponds to
+ * MPICH segments
+ */
+comm_buffers * matrix_init_buffers(comm_mapping * map, int id)
+{
+	int i;
+	int elements =0, bbuf_size =0;
+
+
+	/* arguments checks */
+	if ( !(map) || (id < 0) || (id >= MAX_CPUS) )
+		return 0;
+	if ( !(map->matrix) || !(map->row[id]) )
+		return 0;
+
+
+	/* reload the arguments */
+	elements = map->matrix->elements;
+	bbuf_size = map->row[id]->csize;
+
+	/* create a comm_buffers descriptor */
+	comm_buffers * buffs = (comm_buffers*)
+			alloc_private(sizeof(comm_buffers), id);
+	if (!buffs) {
+		printk(KERN_ERR "%s: error allocating comm_buffers id %d\n",
+				__func__, id);
+		return 0;
+	}
+	memset(buffs, 0, sizeof(comm_buffers));
+
+	/* init the private data structure */
+	buffs->id = id;
+	buffs->elements = elements;
+	buffs->recv_bmp = map->bmp[id];
+
+	/* cells of this row */
+	for (i=0; i<elements; i++)
+		buffs->recv_buf[i] = (void*) map->buf[id] + (bbuf_size * i);
+
+	/* cross references */
+	for (i=0; i<elements; i++) {
+		buffs->send[i].bmp = map->bmp[i];
+		buffs->send[i].buf = (void*) map->buf[i] + (bbuf_size * id);
+	}
+
+	return buffs;
+}
+
+// point to point send
+int matrix_send_to(comm_buffers * buffs, int dest, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!buffs)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(dest < buffs->elements))
+		return 0;
+	/* check if the destination recv buffer is registered */
+	if (!(bb = buffs->send[dest].buf))
+		return 0;
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_put(bb, buff, count);
+#else
+	a = bbuffer_put(bb, buff, count);
+#endif
+
+	if (a > 0)
+		set_bit_bitmap(buffs->send[dest].bmp, buffs->id);
+	return a;
+}
+
+int matrix_send_self(comm_buffers * buffs, char* buff, int count)
+{
+	if ( !buffs )
+		return 0;
+
+	return matrix_send_to(buffs, buffs->id, buff, count);
+}
+
+// point to point recv functions
+
+int matrix_recv_from(comm_buffers* buffs, int src, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!buffs)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(src < buffs->elements))
+		return 0;
+	/* check if our recv buffer is registered */
+	if (!(bb = buffs->recv_buf[src]))
+		return 0;
+
+	// we choose to do not use the bitmap here but only as a best
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_get(bb, buff, count);
+#else
+	a = bbuffer_get(bb, buff, count);
+#endif
+
+	if (a > 0)
+		if (!bbuffer_count(bb))
+			clear_bit_bitmap(buffs->recv_bmp, src);
+	return a;
+}
+
+int matrix_recv_self(comm_buffers* buffs, char* buff, int count)
+{
+	return matrix_recv_from(buffs, buffs->id, buff, count);
+}
+
+static comm_mapping* cmap;
+static comm_buffers* cbuf;
+
+#define COMM_BUFFS_SIZE 0x2000
+#define COMM_CPU_NUM 64
+
+void __init mcomm_init(void)
+{
+	if ( !ncomm_address ) {
+		printk(KERN_ERR"MATRIX Communicator @ %p. Cannot Initialize\n",
+				mcomm_address);
+		return;
+	}
+
+	printk("MATRIX Communicator @ %p. Initialization\n",
+			mcomm_address);
+
+	init_alloc(mcomm_address, 0);
+
+	cmap = matrix_init_mapping(COMM_BUFFS_SIZE, COMM_CPU_NUM);
+	cbuf = matrix_init_buffers(cmap, smp_processor_id());
+
+	printk("MATRIX Communicator cmap %p cbuf %p\n", cmap, cbuf);
+}
+__initcall(mcomm_init);
+
+
+static int __init _mcomm_param(char *str)
+{
+	if (!str)
+		return -EINVAL;
+
+	mcomm_address = simple_strtoull(str, 0, 16);
+	//mcomm_address = simple_strtoull(str, 0, 0); //automatically discover the base
+
+    return 0;
+}
+
+early_param("mcomm", _mcomm_param);
diff --git a/ipc/mcomm.h b/ipc/mcomm.h
new file mode 100644
index 0000000..91eb577
--- /dev/null
+++ b/ipc/mcomm.h
@@ -0,0 +1,118 @@
+#define MAX_ELEMENTS MAX_ARRAY
+#define USE_CACHE_ALIGN
+
+#define MAGIC_CHARS_ROW {'R','O','W',' '}
+
+typedef struct _row_comm {
+	char magic[4];		// magic
+	int elements;		// number of cpus
+	int id;				// cpu identifier
+	unsigned long lock;	// lock
+
+#ifdef USE_CACHE_ALIGN
+	char pad0[(CACHE_LINE -
+			( (sizeof(char) *4) +
+			(sizeof(int) *2) +
+			(sizeof(unsigned long) *1) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+
+	bitmask_t 	  status[MAX_BITMAP];   // receivers (cells) status
+	bitmask_t 	  active[MAX_BITMAP];	// currently allocated buffers or initialized
+	unsigned long offset[MAX_ARRAY];	// offset of the buffer from the beginning of the map
+	int 	 	  csize;				// allocated space per buffer
+	int 		  cnumber;				// number of buffers currently present
+
+#ifdef USE_CACHE_ALIGN
+	char pad1[(CACHE_LINE -
+			( (sizeof(bitmask_t) *2 *MAX_BITMAP) +
+			(sizeof(int) *2) +
+			(sizeof(unsigned long) *MAX_ARRAY) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+} row_comm;
+
+//NOTA ricordati la differenza tra massimo numero di elementi e quelli correntemente allocati
+
+// this is dependent by the type of memory allocator we are using
+// see what we learn from the MPICH/Nemesis guys so define it
+// simply void*
+typedef struct _shm_desc {
+	size_t	size;
+	key_t	key;
+	row_comm * addr; // used by the setup process
+} shm_desc;
+// TODO move in the allocator
+
+
+#define MAGIC_CHARS_MATR {'M','A','T','R'}
+//general communicator header
+typedef struct _matrix_comm {
+	char			magic[4];
+	unsigned long	lock; // we have to spinlock so must maybe be cache aligned (the problem is this does not to be critical)
+
+	int				elements; // the maximum number of elements, or the currently allocated elements
+	bitmask_t 		present[MAX_BITMAP]; // which elements are currently really allocated
+	void*			desc[MAX_ELEMENTS]; // available descriptors per element
+
+} matrix_comm;
+
+
+// NOTA the following two can be merged in one!!!
+// they are both allocated locally/privately
+// so no one cares
+// what will be readed concurrently and is in the same cache line?
+// does something like this exists? and if yes what?
+
+//structure CACHE_ALIGNED !!!
+typedef struct _comm_buffers {
+
+	// THIS IS MY BITMAP: the copy is inshared memory
+	bitmask_t * recv_bmp; //this first because must be cache aligned
+	// THIS ARE THE ptr to MY BUFFERS hopefully they will fit the same cache line of the pointer before
+	bbuffer_t * recv_buf[MAX_ARRAY];
+
+#ifdef USE_CACHE_ALIGN
+	char pad0[(CACHE_LINE -
+			( (sizeof(bitmask_t *) *1) +
+			(sizeof(bbuffer_t *) *MAX_ARRAY) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+
+	// the following data is packed per item  because it will be accessed together
+	struct {
+		// remote bitmap pointer
+		bitmask_t * bmp;
+		// remote recv buffer pointer
+		bbuffer_t * buf;
+	} send[MAX_ARRAY];
+
+	// the following is not aligned
+	int elements, id; //information must be replicated on each local copy
+
+} comm_buffers;
+
+// this is the private/local summary of each area
+typedef struct _comm_mapping {
+	matrix_comm * matrix;
+	row_comm    * row[MAX_ARRAY];
+
+	// remove the followings?!?!
+	// the following can be reconstructed from base
+	bitmask_t* bmp[MAX_ARRAY];
+	bbuffer_t* buf[MAX_ARRAY];
+} comm_mapping;
+
+// PROTOTYPES DECLARATION
+
+comm_mapping * matrix_init_mapping (int size, int elements);
+comm_buffers * matrix_init_buffers (comm_mapping * map, int id);
+
+void matrix_finalize_buffers(comm_mapping * map);
+void matrix_finalize_mapping(comm_mapping * map);
+
+int matrix_send_to(comm_buffers * buffs, int dest, char* buff, int count);
+int matrix_send_self(comm_buffers * buffs, char *buff, int count);
+
+int matrix_recv_from(comm_buffers* buffs, int src, char* buff, int count);
+int matrix_recv_self(comm_buffers* buffs, char* buff, int count);
diff --git a/ipc/test/Makefile b/ipc/test/Makefile
new file mode 100644
index 0000000..8261c99
--- /dev/null
+++ b/ipc/test/Makefile
@@ -0,0 +1,23 @@
+
+CFLAGS += -g
+
+bbuffer:
+	$(CC) -o bbuffer -DUNIT_TEST_BBUFFER buffer.c
+
+mbuffer: buffer.o
+	$(CC) -o mbuffer buffer.o -DUNIT_TEST_MBUFFER mbuffer.c
+	
+macommb: buffer.o
+	$(CC) -o macommb buffer.o -pthread -DUNIT_TEST_MACOMM matrix_comm.c
+
+macommm: buffer.o mbuffer.o
+	$(CC) -o macommm buffer.o mbuffer.o -pthread -DUNIT_TEST_MACOMM -DUSE_MBUFFER matrix_comm.c
+
+mashmm: buffer.o mbuffer.o alloc.o
+	$(CC) $(CFLAGS) -o mashmm buffer.o mbuffer.o alloc.o -pthread -DUNIT_TEST_MACOMM -DUSE_MBUFFER -DUSE_SHMV matrix_shm_comm.c
+
+all: bbuffer mbuffer macommb macommm mashmm
+
+clean:
+	rm *.o bbuffer mbuffer macommb macommm mashmm
+	
\ No newline at end of file
diff --git a/ipc/test/README b/ipc/test/README
new file mode 100644
index 0000000..be9d686
--- /dev/null
+++ b/ipc/test/README
@@ -0,0 +1,34 @@
+
+TODO TODO TODO CLEAN UP
+
+clean up is required to divide the shared memory test
+developed before and the shared memory message passing infrastructure
+
+
+TESTS
+
+SPINLOCKs
+ -DDO_WORK -DUSE_NOP -DUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -UDO_WORK -DUSE_NOP -DUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -DDO_WORK -UUSE_NOP -DUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -UDO_WORK -UUSE_NOP -DUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -DDO_WORK -DUSE_NOP -UUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -UDO_WORK -DUSE_NOP -UUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -DDO_WORK -UUSE_NOP -UUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -UDO_WORK -UUSE_NOP -UUSE_CACHE_ALIGN -DUSE_BARRIERS
+ -DDO_WORK -DUSE_NOP -DUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -UDO_WORK -DUSE_NOP -DUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -DDO_WORK -UUSE_NOP -DUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -UDO_WORK -UUSE_NOP -DUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -DDO_WORK -DUSE_NOP -UUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -UDO_WORK -DUSE_NOP -UUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -DDO_WORK -UUSE_NOP -UUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ -UDO_WORK -UUSE_NOP -UUSE_CACHE_ALIGN -DCIRCULAR_MAP -DUSE_BARRIERS
+ 
+ TODO
+  first implement nop or fence
+  then implement something elso to be tested 
+   - arraylock
+   - mcs
+ 
+ 
\ No newline at end of file
diff --git a/ipc/test/alloc.c b/ipc/test/alloc.c
new file mode 100644
index 0000000..a7b1a3d
--- /dev/null
+++ b/ipc/test/alloc.c
@@ -0,0 +1,112 @@
+
+// Copyright Antonio Barbalace Virginia Tech 2012
+// Project Popcorn
+
+#define USE_SHMV
+#ifdef USE_SHMV
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/shm.h>
+
+#include "alloc.h"
+
+
+
+// TODO NUMA placement, i.e. each thread must be affine
+// TODO cache efficiency
+// TODO how to handle resizing ?!?! STATIC ALLOCATION for now
+
+
+
+// SHM
+#define INIT_SIZE 0x1000000
+#define INIT_KEY 0x1234
+static key_t current_key= 0xbadabada;
+// SHM
+#define init_alloc alloc_init
+int alloc_init(void) {
+	current_key = INIT_KEY;
+
+	return 0;
+}
+// NOTE redefined in the .h as a call to __alloc_on_node
+/* void* __alloc_global(size_t size)
+{
+  key_t key = current_key++;		// key to be passed to shmget()
+  int shmflg = IPC_CREAT | 0666; 	// shmflg to be passed to shmget()
+  int size = INIT_SIZE;				// size to be passed to shmget()
+  int shmid;						// return value from shmget()
+  void* shmaddr;					// return value from shmat()
+
+  // init shared memory
+  if ((shmid = shmget (key, size, shmflg)) == -1) {
+    perror("shmget: shmget failed");
+    return 0;
+  }
+  printf("shmget: shmget (%lx, %lx, %lx) returned %d\n", key, size, shmflag, shmid);
+
+  // map shared memory
+  if ((shmaddr = shmat(shmid, 0, shmflag)) == -1) {
+	  perror("shmat: shmat failed");
+	  return 0;
+  }
+  printf("shmat: shmat (%lx, %lx, %lx) returned %p\n", shmid, 0, shmflag, shmaddr);
+
+  return shmaddr;
+} */
+// SHM
+void* __alloc_on_node(size_t size, int node) {
+
+// TODO try to merge different process (on different cores but same node) on the same memory area
+
+	  key_t key = current_key + (node+1);	/* key to be passed to shmget() */
+	  int shmflg = IPC_CREAT | 0666; 		/* shmflg to be passed to shmget() */
+//	  int size = INIT_SIZE;					/* size to be passed to shmget() */
+	  int shmid;							/* return value from shmget() */
+	  void* shmaddr;						/* return value from shmat() */
+
+	  // init shared memory
+	  if ((shmid = shmget (key, size, shmflg)) == -1) {
+	    perror("shmget: shmget failed");
+	    return 0;
+	  }
+//	  printf("shmget: shmget (0x%lx, %ld, 0x%lx) NODE %d returned %d\n",
+//			  (long int)key, (long int)size, (long int)shmflg, node, (int)shmid);
+
+	  // map shared memory
+	  if ((shmaddr = shmat(shmid, 0, shmflg)) == -1) {
+		  perror("shmat: shmat failed");
+		  return 0;
+	  }
+//	  printf("shmat: shmat (0x%x, 0x%lx, 0x%lx) returned %p\n",
+//			  (int)shmid, (long int)0, (long int)shmflg, shmaddr);
+
+	  return shmaddr;
+}
+
+#else /* !USE_SHMV */
+int init_alloc() {
+ #error "not implemented"
+}
+void* __alloc_global(size_t size) {
+ #error "not implemented"
+	return 0;
+}
+void* __alloc_on_node(size_t size, int node) {
+ #error "not implemented"
+	return 0;
+}
+#endif /* !USE_SHMV */
+
+// do not use shared memory (local copy on private memory
+void* __alloc_private(size_t size, int node) {
+	return malloc(size);
+}
+
+
+//
+void __free_on_node(void* addr) {
+	free (addr);
+}
diff --git a/ipc/test/alloc.h b/ipc/test/alloc.h
new file mode 100644
index 0000000..2fd8632
--- /dev/null
+++ b/ipc/test/alloc.h
@@ -0,0 +1,48 @@
+
+// alloc.h
+// Copyright Antonio Barbalace Virginia Tech 2012
+
+/*
+ * Memory allocation infrastructure
+ * - shared memory multi thread
+ * - shared memory multi thread ccNUMA/NUMA aware
+ * - shared memory multi processor
+ * - shared memory multi processor multi shm entry (ccNUMA/NUMA aware)
+ * - shared memory multi kernel
+ * - shared memory multi kernel ccNUMA/NUMA aware (multi area and time mutable areas)
+ */
+
+/*
+ * TODO
+ * check the real functions name in libnuma
+ * check the real macro name (NUMA?)
+ */
+
+#ifndef NUMA
+#ifdef USE_SHMV
+ #define get_node_from_cpu(id) 0
+
+ #define alloc_private(size, node) __alloc_private(size, node)
+ #define alloc_global(size) __alloc_on_node(size, -1)
+ #define alloc_on_node(size, node) __alloc_on_node(size, node)
+ #define free_on_node(addr) __free_on_node(addr)
+
+#else /* !USE_SHMV */
+ #define get_node_from_cpu(id) 0
+
+ #define alloc_private(size, node) malloc(size)
+ #define alloc_global(size) malloc(size)
+ // alloc must be cache aligned otherwise no point to do this work
+ #define alloc_on_node(size, node) malloc(size)
+ #define free_on_node(addr) free(addr)
+
+#endif /* USE_SHMV */
+#endif /* NUMA */
+
+// implemented in alloc.c
+//void* __alloc_global(size_t size);				// global alloc without caring at locality
+void* __alloc_on_node(size_t size, int node); 	// global alloc caring at locality (node)
+void* __alloc_private(size_t size, int node);	// private alloc caring at locality (node)
+void __free_on_node(void* addr);
+
+
diff --git a/ipc/test/atomic.h b/ipc/test/atomic.h
new file mode 100644
index 0000000..adb1acc
--- /dev/null
+++ b/ipc/test/atomic.h
@@ -0,0 +1,154 @@
+
+typedef unsigned char u8;
+typedef unsigned short u16;
+typedef unsigned int u32;
+
+struct __xchg_dummy {
+	unsigned int a[64];
+};
+#define __xg(x) ((struct __xchg_dummy *)(x))
+
+#define __xchg(x, ptr, size)						\
+({									\
+	__typeof(*(ptr)) __x = (x);					\
+	switch (size) {							\
+	case 1:								\
+		asm volatile("xchgb %b0,%1"				\
+			     : "=q" (__x)				\
+			     : "m" (*__xg(ptr)), "0" (__x)		\
+			     : "memory");				\
+		break;							\
+	case 2:								\
+		asm volatile("xchgw %w0,%1"				\
+			     : "=r" (__x)				\
+			     : "m" (*__xg(ptr)), "0" (__x)		\
+			     : "memory");				\
+		break;							\
+	case 4:								\
+		asm volatile("xchgl %0,%1"				\
+			     : "=r" (__x)				\
+			     : "m" (*__xg(ptr)), "0" (__x)		\
+			     : "memory");				\
+		break;							\
+	case 8:								\
+		asm volatile("xchgq %0,%1"				\
+			     : "=r" (__x)				\
+			     : "m" (*__xg(ptr)), "0" (__x)		\
+			     : "memory");				\
+		break;							\
+	default:							\
+		assert(!size);					\
+	}								\
+	__x;								\
+})
+
+#define xchg(ptr, v)							\
+	__xchg((v), (ptr), sizeof(*ptr))
+
+
+
+#define __raw_cmpxchg(ptr, old, new, size, lock)			\
+({									\
+	__typeof__(*(ptr)) __ret;					\
+	__typeof__(*(ptr)) __old = (old);				\
+	__typeof__(*(ptr)) __new = (new);				\
+	switch (size) {							\
+	case 1:								\
+		asm volatile(lock "cmpxchgb %b1,%2"			\
+			     : "=a"(__ret)				\
+			     : "q"(__new), "m"(*__xg(ptr)), "0"(__old)	\
+			     : "memory");				\
+		break;							\
+	case 2:								\
+		asm volatile(lock "cmpxchgw %w1,%2"			\
+			     : "=a"(__ret)				\
+			     : "r"(__new), "m"(*__xg(ptr)), "0"(__old)	\
+			     : "memory");				\
+		break;							\
+	case 4:								\
+		asm volatile(lock "cmpxchgl %1,%2"			\
+			     : "=a"(__ret)				\
+			     : "r"(__new), "m"(*__xg(ptr)), "0"(__old)	\
+			     : "memory");				\
+		break;							\
+	case 8:								\
+		asm volatile(lock "cmpxchgl %1,%2"			\
+			     : "=a"(__ret)				\
+			     : "r"(__new), "m"(*__xg(ptr)), "0"(__old)	\
+			     : "memory");				\
+		break;							\
+	default:							\
+		assert(!size);					\
+	}								\
+	__ret;								\
+})
+
+#define __sync_cmpxchg(ptr, old, new, size)				\
+	__raw_cmpxchg((ptr), (old), (new), (size), "lock; ")
+
+#define sync_cmpxchg(ptr, old, new)					\
+	__sync_cmpxchg((ptr), (old), (new), sizeof(*ptr))
+
+
+/*
+
+IMPLEMENT THE NOP INSTRUCTIONS
+
+{
+  // Note: "mfence" (SSE2) is supported on all x86_64/amd64 chips.
+  __asm__ __volatile__("mfence" : : : "memory");
+}
+
+*/
+
+/* FROM LINUX KERNEL (thanks)
+ * An exchange-type operation, which takes a value and a pointer, and
+ * returns a the old value.
+ */
+#define __X86_CASE_B 1
+#define __X86_CASE_W 2
+#define __X86_CASE_L 4
+#define __X86_CASE_Q 8
+
+#define __xchg_op(ptr, arg, op, lock)                                   \
+        ({                                                              \
+                __typeof__ (*(ptr)) __ret = (arg);                      \
+                switch (sizeof(*(ptr))) {                               \
+                case __X86_CASE_B:                                      \
+                        asm volatile (lock #op "b %b0, %1\n"            \
+                                      : "+q" (__ret), "+m" (*(ptr))     \
+                                      : : "memory", "cc");              \
+                        break;                                          \
+                case __X86_CASE_W:                                      \
+                        asm volatile (lock #op "w %w0, %1\n"            \
+                                      : "+r" (__ret), "+m" (*(ptr))     \
+                                      : : "memory", "cc");              \
+                        break;                                          \
+                case __X86_CASE_L:                                      \
+                        asm volatile (lock #op "l %0, %1\n"             \
+                                      : "+r" (__ret), "+m" (*(ptr))     \
+                                      : : "memory", "cc");              \
+                        break;                                          \
+                case __X86_CASE_Q:                                      \
+                        asm volatile (lock #op "q %q0, %1\n"            \
+                                      : "+r" (__ret), "+m" (*(ptr))     \
+                                      : : "memory", "cc");              \
+                        break;                                          \
+                default:                                                \
+                        __ ## op ## _wrong_size();                      \
+                }                                                       \
+                __ret;                                                  \
+        })
+
+/*
+ * xadd() adds "inc" to "*ptr" and atomically returns the previous
+ * value of "*ptr".
+ *
+ * xadd() is locked when multiple CPUs are online
+ * xadd_sync() is always locked
+ * xadd_local() is never locked
+ */
+#define __xadd(ptr, inc, lock)  __xchg_op((ptr), (inc), xadd, lock)
+#define xadd(ptr, inc)          __xadd((ptr), (inc), LOCK_PREFIX)
+#define xadd_sync(ptr, inc)     __xadd((ptr), (inc), "lock; ")
+#define xadd_local(ptr, inc)    __xadd((ptr), (inc), "")
diff --git a/ipc/test/bitmask.h b/ipc/test/bitmask.h
new file mode 100644
index 0000000..be7ad58
--- /dev/null
+++ b/ipc/test/bitmask.h
@@ -0,0 +1,24 @@
+typedef unsigned int bitmask_t;
+
+static inline void clear_bit_bitmap(bitmask_t* pbitmap, int id)
+{
+	pbitmap[(id / BIT_PER_BITMASK)] &= ~(1 << (id % BIT_PER_BITMASK));
+}
+
+static inline void set_bit_bitmap(bitmask_t* pbitmap, int id)
+{
+	pbitmap[(id / BIT_PER_BITMASK)] |= (1 << (id % BIT_PER_BITMASK));
+}
+
+static inline int ffs_bit_bitmap(bitmask_t* pbitmap)
+{
+	register int i, pos;
+	for (i=0; i<MAX_BITMAP; i++)
+		if ((pos = ffs(pbitmap[i])) > 0)
+			return ((i*BIT_PER_BITMASK) + (pos -1));
+	return -1;
+}
+
+//bit hacks
+//http://graphics.stanford.edu/~seander/bithacks.html
+//http://realtimecollisiondetection.net/blog/?p=78
diff --git a/ipc/test/buffer.c b/ipc/test/buffer.c
new file mode 100644
index 0000000..f83055e
--- /dev/null
+++ b/ipc/test/buffer.c
@@ -0,0 +1,265 @@
+// bbuffer.c
+// Author: Antonio Barbalace, VirginiaTech 2012
+
+// maybe this file must be all contained in a h file...
+// basically is a cicular buffer BYTE ORIENTED
+// FUTURE support two usages: typed oriented and byte (memcpy style oriented)
+// NUMA AWARE - allocating memory on the right node (libnuma)
+// *numa_alloc_onnode(size_t size, int node);
+// in MKLINUX the mklinux_alloc_onnode will be used
+// for multiple writer 2 phase commit can be a solution
+// for zero copy memory get/dispose of buffers is fantastic solution
+
+#include <stdint.h>
+
+//#include "types.h"
+typedef unsigned short u16;
+typedef unsigned int u32;
+
+#ifndef CACHE_ALIGNED
+ #define CACHE_ALIGNED
+#endif
+//#define UNIT_TEST_BBUFFER
+
+
+#include "buffer.h"
+
+
+//and maybe one cache line before and after the buffer must be a watermark
+// header and buffer must be allocate together in the same private/local area
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <assert.h>
+
+#include "alloc.h"
+
+///////////////////////////////////////////////////////////////////////////////
+// bbuffer_init
+
+bbuffer_t * bbuffer_init (int size, int node)
+{
+	int padded_size = size;
+
+#ifdef CACHE_ALIGNED
+	padded_size = BBUFFER_SPACE(size);
+#endif /* CACHE_ALIGNED */
+	BBUFFER_CHECK(padded_size);
+
+	bbuffer_t* bb = (bbuffer_t*) alloc_on_node(
+			BBUFFER_SIZEOF(padded_size), node);
+	/* returns zero if malloc fails */
+	if (!bb)
+		return bb;
+
+	BBUFFER_INIT(bb, padded_size);
+	return bb;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// bbuffer_finalize
+
+void bbuffer_finalize (bbuffer_t* bb)
+{
+	free_on_node(bb);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// bbuffer_put
+
+/* further improvements
+ * 1. each entry must be cache aligned (avoid false sharing)
+ * 2. waiting put (on buffer overrun)
+ */
+int bbuffer_put (bbuffer_t* buf, char* src, int count)
+{
+	register struct _raw_indexes ht;
+	register int size, avail_elements; // used_elements,
+
+	ht = buf->indexes;
+	size = buf->size;
+	//used_elements = ((size + ht.head) - ht.tail) % size;
+    avail_elements = size - ((size + ht.head) - ht.tail) % size; //used_elements;
+
+    /* if the elements does not fit in the buffer return error */
+    if (count > (avail_elements -1))
+    	return -1;
+
+    /* when tail is greater then head content is written across the end */
+    if ((ht.head + count) >= size) {
+    	memcpy(&(buf->buffer[ht.head]),
+    			src, (size - ht.head));
+    	memcpy(&(buf->buffer[0]),
+    			(src + (size - ht.head)), (ht.head + count) % size);
+    	ht.head = (ht.head + count) % size;
+	}
+	else {
+		memcpy(&(buf->buffer[ht.head]), src, count);
+		ht.head = (ht.head + count);
+	}
+
+    buf->indexes.head = ht.head;
+    return count;
+}
+
+// TODO
+//int bbuffer_puttofit (arch_header_t *buf, char *src, int count) {
+//	return 0;
+//}
+
+///////////////////////////////////////////////////////////////////////////////
+// bbuffer_get
+
+
+// considering that a message can be written on the bound and finish on the other side, this is maybe not the best for performance but..
+// an external buffer where to copy the data is not a bad idea we can study a message passing with linear address of the contents i
+//order to do not require further copies (like lists of buckets each bucket can contain a different message
+// RETURNS the number of characters copied
+
+// how many bytes? right now we have no clue on how many bytes -> we need a micro header in the buffer
+// otherwise we can create a circular buffer of fixed elements (every time you insert o pick up one or more elements)
+
+/* THINK ABOUT...
+CODE IS NOT RELIABLE RIGHT NOW, microheaders or object oriented buffer ?! I mean if the buffer is byte oriented is fantastic!
+		i.e. the object granularity is char the code is ready to go (it is ok for many apps, like the multi cache test)
+*/
+
+/* TODO
+two alternatives:
+
+the idea to avoid the count variable is to store a bit somewhere in the
+tail or head that indicate that head and tail are full but
+
+this is the alternative to lost one element when head and tail cannot be the same
+*/
+int bbuffer_get (bbuffer_t * buf, char * dst, int count)
+{
+	register struct _raw_indexes ht;
+	register int size;
+	register int used_elements; // avail_elements;
+
+	ht = buf->indexes;
+	size = buf->size;
+
+	used_elements = (((size + ht.head) - ht.tail) % size);
+ 	//avail_elements = size - used_elements;
+
+ 	/* nothing present in the buffer */
+	if (used_elements == 0 ) // tail == head
+		return -1;
+
+	/* amount to copy */
+	if (count > used_elements )
+		count = used_elements;
+
+	/* when tail is greater then head content is written across the end */
+	if (ht.tail + count >= size) {
+		memcpy(dst, &(buf->buffer[ht.tail]),
+				(size - ht.tail));
+		memcpy((dst + (size - ht.tail)), &(buf->buffer[0]),
+				(ht.tail + count) % size);
+		ht.tail = (ht.tail + count) % size;
+	}
+	else {
+		memcpy(dst, &(buf->buffer[ht.tail]), count);
+		ht.tail= (ht.tail + count);
+	}
+
+	buf->indexes.tail = ht.tail;
+	return count;
+}
+
+int bbuffer_count (bbuffer_t * buf)
+{
+	register struct _raw_indexes ht;
+	register int size;
+
+	ht = buf->indexes;
+	size = buf->size;
+
+	return (((size + ht.head) - ht.tail) % size);
+}
+
+static void bbuffer_dump(bbuffer_t * bb)
+{
+  printf("bbuffer_dump: head %d tail %d size %d count %d\n",
+		  bb->indexes.head, bb->indexes.tail, bb->size,
+		  (((bb->size + bb->indexes.head) - bb->indexes.tail) % bb->size));
+}
+
+
+//#define UNIT_TEST_BBUFFER
+#ifdef UNIT_TEST_BBUFFER
+int main (int argc, char * argv[])
+{
+  bbuffer_t* bbuf;
+  int _ret;
+  char src[196] = "Il viaggio ultraterreno di Dante richiede l'appoggio di "
+		  "una guida, in quanto il protagonista rappresenta l'uomo smarrito in "
+		  "conseguenza del peccato e pertanto incapace di recuperare da solo "
+		  "la retta via. Per l'intero cammino che si svolge attraverso il "
+		  "baratro dell'Inferno e su per la montagna del Purgatorio la guida "
+		  "prescelta  Virgilio, l'antico poeta latino autore dell'Eneide.";
+  char dest[196];
+
+  bbuf = bbuffer_init (15, 0);
+
+  _ret = bbuffer_put(bbuf, &(src[0]), 5);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[5]), 5);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[10]), 28);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[38]), 33);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = bbuffer_get(bbuf, dest, 15);
+  printf("get ret %d %s\n", _ret, dest);
+  bbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = bbuffer_get(bbuf, dest, 64);
+  printf("get ret %d %s\n", _ret, dest);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[71]), 33);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[104]), 31);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[104]), 30);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  _ret = bbuffer_put(bbuf, &(src[134]), 3);
+  printf("put ret %d\n", _ret);
+  bbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = bbuffer_get(bbuf, dest, 32);
+  printf("get ret %d %s\n", _ret, dest);
+  bbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = bbuffer_get(bbuf, dest, 64);
+  printf("get ret %d %s\n", _ret, dest);
+  bbuffer_dump(bbuf);
+
+  return 0;
+}
+#endif /* UNIT_TEST_BBUFFER */
diff --git a/ipc/test/buffer.h b/ipc/test/buffer.h
new file mode 100644
index 0000000..e72f03b
--- /dev/null
+++ b/ipc/test/buffer.h
@@ -0,0 +1,74 @@
+// bbuffer.h
+// Author: Antonio Barbalace, Virginia Tech 2012
+
+//
+//#define WORLD_BYTES (sizeof(long))
+#ifndef WORLD_BYTES
+ #define WORLD_BYTES 4
+#endif
+
+#if (WORLD_BYTES == 4)
+typedef u16 __index_t;
+typedef u32 __indexes_t;
+#else
+typedef u32 __index_t;
+typedef u64 __indexes_t;
+#endif
+
+#ifndef CACHE_LINE
+ #define CACHE_LINE 64
+#endif
+
+typedef struct bbuffer {
+	union {
+		__indexes_t head_tail;
+		struct _raw_indexes {
+			__index_t head, tail;
+		} indexes;
+	};
+	int size; //buffer size (must be padded)
+	char pad[(CACHE_LINE - sizeof(struct _raw_indexes) - sizeof(int))];
+	char buffer[]; //actual buffer (cache aligned)
+} bbuffer_t;
+
+
+#ifdef CACHE_ALIGNED
+ /* the returned memory must be cache aligned */
+ #define CHECK_CACHE_ALIGNED(addr) assert(!((unsigned long)((void*)addr) & (CACHE_LINE -1)));
+//#define CHECK_CACHE_ALIGNED(addr) assert(((unsigned long)((void*)addr) & (CACHE_LINE -1)));
+#else /* !CACHE_ALIGNED */
+ #define CHECK_CACHE_ALIGNED(addr)
+#endif /* !CACHE_ALIGNED */
+
+/* every byte must be accessed using an __index_t index */
+#define BBUFFER_LIMIT ((0x01 << sizeof(__index_t)) -1)
+#define BBUFFER_CHECK(pad_size) assert((pad_size > BBUFFER_LIMIT))
+
+#define BBUFFER_SPACE(pad_size) ((!(pad_size%CACHE_LINE)) ? \
+		(pad_size) : (pad_size + (CACHE_LINE - (pad_size%CACHE_LINE))))
+
+#define BBUFFER_SIZEOF(pad_size) (sizeof(bbuffer_t) + pad_size)
+
+#define BBUFFER_INIT(bbuf, pad_size) ({ \
+	CHECK_CACHE_ALIGNED(bbuf); \
+	memset(bbuf, 0, sizeof(bbuffer_t)); \
+	bbuf->size = pad_size; })
+
+/*
+ *
+ */
+bbuffer_t* bbuffer_init (int size, int node);
+/*
+ *
+ */
+void bbuffer_finalize (bbuffer_t* bb);
+/*
+ *
+ */
+int bbuffer_put (bbuffer_t* bb, char* src, int count);
+/*
+ *
+ */
+int bbuffer_get (bbuffer_t* bb, char* dst, int count);
+
+int bbuffer_count (bbuffer_t * buf);
diff --git a/ipc/test/count.c b/ipc/test/count.c
new file mode 100755
index 0000000..a1f18b5
--- /dev/null
+++ b/ipc/test/count.c
@@ -0,0 +1,815 @@
+/*
+ * count.c
+ * User Space scalability test for x86
+ * increments a counter (x86 locked mode)
+ */
+/*
+ * APP DESC
+ * 1. based on cmd line arguments spawn n thread
+ * 2a. each one affine to a different processor
+ * 2b. (use the idea module the number of avaiable processors)
+ * maybe mlock (to try in a future version)
+ * maybe SCHED_FIFO (to try in a future version)
+ * versions:
+ * - spinlock
+ * - cache aligned spinlock
+ * - MCS (private locks)
+ * - cache aligned MCS
+ * - Hierarchical Locks,
+ * - RCLs
+ * - messages
+ */
+
+//compile
+//gcc -DLEVEL1_DCACHE_LINESIZE=`getconf LEVEL1_DCACHE_LINESIZE`
+
+//the test must also consider how many interrupt are generating in the system while the tests are running
+
+#define _GNU_SOURCE
+// generic/standard define
+#include <time.h>
+#include <stdio.h>
+#include <sched.h>
+#include <unistd.h>
+#include <getopt.h>
+#include <sys/time.h>
+#include <pthread.h>
+#include <assert.h>
+// linux dependent define
+#ifdef GET_CPU
+ #include <linux/getcpu.h>
+#endif
+// application level define
+#include "atomic.h"
+#include "rdtsc.h"
+
+#undef USE_MEMORY_PROTECT
+#undef USE_SCHED_POLI
+#define USE_BARRIERS
+/*
+#undef USE_CACHE_ALIGN
+#undef USE_NOP
+#define DO_WORK
+*/
+
+#ifdef USE_CACHE_ALIGN
+ #define CACHE_ALIGN_OPT __attribute__((aligned (64)))
+// #define CACHE_ALIGN_OPT __attribute__((aligned (LEVEL1_DCACHE_LINESIZE)))
+#else
+ #define CACHE_ALIGN_OPT
+#endif
+
+#ifndef LEVEL1_DCACHE_LINESIZE
+ #define LEVEL1_DCACHE_LINESIZE 64
+#endif
+
+#ifdef USE_NOP
+ #define NOP
+#else
+ #define NOP
+#endif
+
+// process mapping algorithm on processors
+#undef SKIP_CURRENT
+//#define SKIP_CURRENT
+
+// duration is in milli seconds
+#define DEFAULT_DURATION 10000
+// suggested number of iterations
+#define DEFAULT_ITERATIONS 8192
+// local data to be modified (cpunum)
+#define MAX_VARIABLES 64
+
+/* ################################################################### *
+ * BARRIER
+ * ################################################################### */
+#ifdef USE_BARRIERS
+typedef struct barrier {
+	pthread_cond_t complete;
+	pthread_mutex_t mutex;
+	int count;
+	int crossing;
+} barrier_t;
+
+barrier_t barrier;
+
+void barrier_init(barrier_t *b, int n) {
+	pthread_cond_init(&b->complete, NULL);
+	pthread_mutex_init(&b->mutex, NULL);
+	b->count = n;
+	b->crossing = 0;
+}
+
+void barrier_cross(barrier_t *b) {
+	pthread_mutex_lock(&b->mutex);
+	/* One more thread through */
+	b->crossing++;
+	/* If not all here, wait */
+	if (b->crossing < b->count) {
+		pthread_cond_wait(&b->complete, &b->mutex);
+	} else {
+		pthread_cond_broadcast(&b->complete);
+		/* Reset for next time */
+		b->crossing = 0;
+	}
+	pthread_mutex_unlock(&b->mutex);
+}
+#endif
+
+/* ################################################################### *
+ * UTIL
+ * ################################################################### */
+
+static inline int get_cpu() {
+	int cpu;
+#ifdef GET_CPU
+  int c, s;
+  s = getcpu(&c, NULL, NULL);
+  cpu = (s == -1) ? s : c;
+  fprintf(stderr,"c %d s %d", c, s);
+#else
+  cpu = sched_getcpu();
+#endif
+  return cpu;
+}
+
+/* ################################################################### *
+ * LOCKING CODEs
+ * ################################################################### */
+
+typedef struct _data_variables{
+	int data;
+#ifdef USE_CACHE_ALIGN
+	char padding[(LEVEL1_DCACHE_LINESIZE - sizeof(int))];
+#endif
+} data_variables_t;
+
+//is private look at the document does not have much sense
+CACHE_ALIGN_OPT static data_variables_t data_variables[MAX_VARIABLES];
+// is global
+CACHE_ALIGN_OPT static data_variables_t data_variable;
+
+///////////////////////////////////////////////////////////////////////////////
+// TAS spinlock (bit oriented)
+
+typedef struct _spinlock {
+	int lock;
+} spinlock_t;
+
+//CACHE_ALIGN_OPT static spinlock_t spinlock_variable; //what to do for numa architecture? what about one variable per zone?
+//how to cross zone synchronize? where this variable is allocated?!?!
+CACHE_ALIGN_OPT static int spinlock_variable;
+
+static inline void init_spinlock(long arg) {
+	//spinlock_variable.lock = 0;
+	spinlock_variable = 0;
+}
+
+static inline void test_spinlock(long arg) {
+	//while ( xchg(&(spinlock_variable.lock), 1) )
+	while ( xchg((&(spinlock_variable)), 1) )
+		NOP ;
+#ifdef DO_WORK
+	//operation (do work) where? zone or privately or globally?
+	data_variable = arg;
+#endif
+	spinlock_variable = 0;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// CAS spinlock (value oriented)
+
+CACHE_ALIGN_OPT static int vspinlock_variable; //what to do for numa architecture? what about one variable per zone?
+//how to cross zone synchronize? where this variable is allocated?!?!
+
+static inline void init_vspinlock(long arg) {
+	spinlock_variable = 0;
+}
+
+static inline void test_vspinlock(long arg) {
+	while (cmpxchg(&spinlock_variable, 1) != 1234) // TODO TODO TODO
+		NOP ;
+#ifdef DO_WORK
+	//operation (do work) where? zone or privately or globally?
+	data_variable = arg;
+#endif
+	spinlock_variable = 1234;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// ticket spinlock
+
+#define CONFIG_NR_CPUS 128
+// only used in intra cpu communication (Linux code)
+#if (CONFIG_NR_CPUS < 256)
+typedef u8  __ticket_t;
+typedef u16 __ticketpair_t;
+#else
+typedef u16 __ticket_t;
+typedef u32 __ticketpair_t;
+#endif
+
+typedef struct arch_spinlock {
+	union {
+		__ticketpair_t head_tail;
+		struct __raw_tickets {
+			__ticket_t head, tail;
+		} tickets;
+	};
+} arch_spinlock_t;
+
+#define LOCK_PREFIX "\n\tlock; "
+#define UNLOCK_LOCK_PREFIX LOCK_PREFIX
+
+#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
+/* they say "Note the tail must be in the high part, because a wide xadd increment of the low part would carry up and contamine the high part" */
+/* but does not seems what it is really happening.. maybe is due to the endianity ?! */
+static __always_inline void __ticket_spin_lock(arch_spinlock_t *lock)
+{
+	register struct __raw_tickets inc = { .tail = 1 };
+
+	inc = xadd(&lock->tickets, inc);
+
+	for (;;) {
+		if (inc.head == inc.tail)
+			break;
+//		cpu_relax(); fence?
+		inc.head = ACCESS_ONCE(lock->tickets.head);
+	}
+//	barrier();		/* make sure nothing creeps before the lock is taken */
+}
+
+// Linux defines a lock section in which to put locks
+
+#if (NR_CPUS < 256)
+static __always_inline void __ticket_spin_unlock(arch_spinlock_t *lock)
+{
+	asm volatile(UNLOCK_LOCK_PREFIX "incb %0"
+		     : "+m" (lock->head_tail)
+		     :
+		     : "memory", "cc");
+}
+#else
+static __always_inline void __ticket_spin_unlock(arch_spinlock_t *lock)
+{
+	asm volatile(UNLOCK_LOCK_PREFIX "incw %0"
+		     : "+m" (lock->head_tail)
+		     :
+		     : "memory", "cc");
+}
+#endif
+
+//CACHE_ALIGN_OPT static int ticket_variable;
+CACHE_ALIGN_OPT static arch_spinlock_t ticket;
+
+static inline void init_ticket(long arg) {
+  memset(&ticket, 0, sizeof(ticket));
+}
+
+static inline void test_ticket(long arg) {
+  __ticket_spin_lock(&ticket);
+#ifdef DO_WORK
+	//operation (do work) where? zone or privately or globally?
+	data_variable = arg;
+#endif
+  __ticket_spin_unlock(&ticket);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// array lock (entries are not cache aligned)
+
+// NOTE about array lock: like spinlock they cannot be performant in ccNUMA
+// NOTE because the lock array (like in the spinlock) is on a single node (can we do better?)
+// NOTE We can do better if we store the pointer in the circular buffer allocating the
+// NOTE actually value to spin on privately (remotely -> rrarraylock)
+
+#define MAX_THREADS 128
+CACHE_ALIGN_OPT static int array_lock[MAX_THREADS];
+CACHE_ALIGN_OPT static int tail_lock;
+CACHE_ALIGN_OPT static int size_lock; // TODO must be thread local in ccNUMA
+
+static inline void init_arraylock(long arg) {
+	int i;
+	for (i=0; i<MAX_THREADS; i++)
+		array_lock[i] = 0;
+	tail_lock = 0;
+	array_lock[tail_lock] = 1;
+	size_lock = arg;
+}
+
+static inline void test_arraylock(long arg) {
+// lock
+	// slot is on the stack so thread local (can be further optimized by the compiler)
+	int slot = xadd(&(tail_lock), 1) % size_lock;
+	while ( !array_lock[slot]  )
+		NOP ;
+#ifdef DO_WORK
+	// the fact of doing or not doing work tells how much the fact that the
+	// memory on which we are working (remote) influence the performance
+	data_variable = arg; // THIS IS NOT LOCAL! IS SHARED!
+#endif
+//unlock
+	array_lock[slot] = 0;
+	array_lock[(slot + 1) % size_lock] = 1;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// array lock (entries are cache aligned)
+
+//this version avoids cache coherence traffic (due to false sharing?)
+typedef struct array_locks{
+	int lock;
+#ifdef USE_CACHE_ALIGN
+	char padding[(LEVEL1_DCACHE_LINESIZE - sizeof(int))];
+#endif
+} array_locks_t;
+
+CACHE_ALIGN_OPT static array_locks_t ccarray_lock[MAX_THREADS];
+
+static inline void init_ccarraylock(long arg) {
+	int i;
+	for (i=0; i<MAX_THREADS; i++)
+		ccarray_lock[i].lock = 0;
+	tail_lock = 0;
+	ccarray_lock[tail_lock].lock = 1;
+	size_lock = arg;
+}
+
+static inline void test_ccarraylock(long arg) {
+// lock
+	// like in the TAMP book slot is on the stack so thread local
+	int slot = xadd(&(tail_lock), 1) % size_lock;
+	while ( !(ccarray_lock[slot].lock)  )
+		NOP ;
+#ifdef DO_WORK
+	// the fact of doing or not doing work tells how much the fact that the
+	// memory on which we are working (remote) influence the performance
+	data_variable = arg; // THIS IS NOT LOCAL! IS SHARED!
+#endif
+//unlock
+	ccarray_lock[slot].lock = 0;
+	ccarray_lock[(slot + 1) % size_lock].lock = 1;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// array lock (entries are cache aligned remote)
+
+// TODO TODO TODO Is MCS similar to rrarraylock?!?!
+
+static inline void init_rearraylock() {
+
+}
+
+static inline void test_rearraylock(long arg) {
+	//cache or not cached
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// MCS
+
+int test_mcs() {
+
+}
+
+int test_cachemcs( data) {
+
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// write on shared memory
+
+typedef struct __cache_line{
+	char data[(LEVEL1_DCACHE_LINESIZE)];
+} cache_line_t;
+
+//this is in any case shared (global common) data
+#define MAX_CACHE_LINES 8
+CACHE_ALIGN_OPT static cache_line_t cl_sharedwrite[MAX_CACHE_LINES];
+int num_cache_lines = 1;
+static inline int init_shmwrite (long arg) {
+	printf("check the num of cache lines in /sys/devices/system/cpu/cpu*/cache/index*\n");
+	printf("private data generation\n");
+
+	//TODO use numa_malloc
+	//cache_line_t * data_ptr = malloc( arg * sizeof(cache_line_t));
+	cache_line_t * data_ptr = malloc( num_cache_lines * sizeof(cache_line_t));
+	if (!data_ptr)
+		exit(-1);
+
+	return 0;
+}
+// TODO first prototype we do not care about allocation local memory
+// return the local pointer
+// arg is number of cache lines
+static inline void* local_init_shmwrite(long arg, long id) {
+	int i = 0;
+	/* malloc
+	 */
+	void *prv = malloc(num_cache_lines *sizeof(cache_line_t));
+	/*	memset (i.e. initialization)
+		or for loop to set the content
+	*/
+	//memset(prv, id, (arg *sizeof(cache_line_t)))
+	memset(prv, id, (num_cache_lines *sizeof(cache_line_t)));
+	return prv;
+}
+
+
+//end_sharedwrite TODO on everyone - we do not mind about the deacollization
+//because is deallocated by the OS - has maybe to be solved in the future
+
+// the argument is how many bytes to write first byte cache aligned
+// the number of bytes reflect the number of cache lines
+// competing write
+static inline int test_shmwrite (long arg, void * private_data) {
+  // in which way to update all the nodes if the information will be shared?!?! memcpy (optimized by the compiler)
+  // no locks -- Barrelfish
+	// destination source
+	return (int) memcpy ((void *)cl_sharedwrite, private_data, (num_cache_lines *sizeof(cache_line_t)));
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// rpc
+
+
+//init param arguments are the numeber of processors and maybe
+//also the number of cache lines to test each time
+static inline int init_message (long arg) {
+
+	// using matrix_comm
+	//2d communication buffer
+
+}
+
+
+
+int test_message (long arg) {
+ //	in which way to update all the nodes if the information will be shared?!?!
+
+	/*IN this test we have to allocate private buffer (cache aligned) for each
+			thread...
+	plus
+	*/
+}
+
+/*
+further question: what to measuere the entire critical section or only the getting in and getting out?
+there are some more interesting points about it expecially for numa.. not clear actually: this will be super interesting for a comparison with RCL
+but otherwise is not.
+what about the cache alignments? does the topology will increase the bandwidth?!?!
+cache alignement and areas must be on cache boundaries taking care of what is written in the thesis from toronto
+*/
+
+/* ################################################################### *
+ * THREAD TEST MAIN LOOP
+ * ################################################################### */
+
+typedef unsigned long sample_t;
+
+typedef struct private {
+	int index; // thread id
+	int cpu; // assigned cpu id
+	int count; // count is sample num
+	int pad; //in order to the ull to be aligned to the right boundaries
+	sample_t samples[];
+} private_t;
+
+int stop = 0; //global variable
+
+//#define TEST_SPINLOCK
+//#define TEST_TICKET
+//#define TEST_ARRAYLOCK
+//#define TEST_SHMWRITE
+// NOTA test_* can only run local
+#ifdef TEST_SPINLOCK
+ #define INIT_TEST_GLOBAL(a) init_spinlock(a)
+ #define FINALIZE_TEST_GLOBAL(a)
+ #define INIT_TEST_LOCAL(a, b) 0
+ #define FINALIZE_TEST_LOCAL(a)
+ #define RUN_TEST(a,b) test_spinlock(a)
+#elif defined(TEST_TICKET)
+ #define INIT_TEST_GLOBAL(a) init_ticket(a)
+ #define FINALIZE_TEST_GLOBAL(a)
+ #define INIT_TEST_LOCAL(a, b) 0
+ #define FINALIZE_TEST_LOCAL(a)
+ #define RUN_TEST(a,b) test_ticket(a)
+#elif defined(TEST_ARRAYLOCK)
+ #define INIT_TEST_GLOBAL(a) init_arraylock(a)
+ #define FINALIZE_TEST_GLOBAL(a)
+ #define INIT_TEST_LOCAL(a, b) 0
+ #define FINALIZE_TEST_LOCAL(a)
+ #define RUN_TEST(a,b) test_arraylock(a)
+#elif defined(TEST_CCARRAYLOCK)
+ #define INIT_TEST_GLOBAL(a) init_ccarraylock(a)
+ #define FINALIZE_TEST_GLOBAL(a)
+ #define INIT_TEST_LOCAL(a, b) 0
+ #define FINALIZE_TEST_LOCAL(a)
+ #define RUN_TEST(a,b) test_ccarraylock(a)
+#elif defined(TEST_SHMWRITE)
+ #define INIT_TEST_GLOBAL(a) init_shmwrite(a)
+ #define FINALIZE_TEST_GLOBAL(a)
+ #define INIT_TEST_LOCAL(a, b) local_init_shmwrite(a, b)
+ #define FINALIZE_TEST_LOCAL(a)
+ #define RUN_TEST(a,b) test_shmwrite(a, b)
+#endif
+
+void *test(void *arg)
+{
+	private_t * data = (private_t *) arg;
+	cpu_set_t cpuset;
+  	int src, dst, id;
+  	int iter, max_iter;
+  	unsigned long long timestamp1, timestamp2;
+  	struct timespec tm;
+
+  	// core/processor affinity mapping
+  	src = get_cpu(); dst = data->cpu; id = data->index;
+	CPU_ZERO(&cpuset);
+	CPU_SET(dst, &cpuset);
+    if (sched_setaffinity(0, sizeof (cpu_set_t), &cpuset)) {
+		perror("sched_getaffinity MAJOR ERROR");
+		exit( EXIT_FAILURE );
+	}
+
+    dst = get_cpu();
+    fprintf(stderr,"thread id %d src %d dst %d (requested %d)\n",
+    		data->index, src, dst, data->cpu);
+
+    iter=0; max_iter=data->count;
+
+    // memory affinity (NUMA)
+    void* larg = INIT_TEST_LOCAL(0, id);
+
+#ifdef USE_BARRIERS
+  /* Wait on barrier */
+  barrier_cross(&barrier);
+#endif
+  while ((iter < max_iter) && (!stop)) {
+		//start_measure(timestamp1);
+	    timestamp1 = RDTSC();
+
+		RUN_TEST(id, larg);
+
+		//timestamp2 = end_measure(timestamp1);
+		timestamp2 = RDTSC();
+		//save timestamp2 in the correct area
+		data->samples[iter] = (sample_t) (unsigned long long )(timestamp2 -timestamp1);
+
+	/*	printf("id:%d iter:%d t1:%lld t2:%lld diff:%ld\n",
+				id, iter, timestamp1, timestamp2, data->samples[iter]);
+*/
+		iter++;
+  }
+
+  clock_gettime(CLOCK_THREAD_CPUTIME_ID, &tm);
+
+  FINALIZE_TEST_LOCAL(0);
+
+  fprintf(stderr,"thread id: %d iterations %d time %lds %ldns\n", id, iter, (long)tm.tv_sec, (long) tm.tv_nsec);
+  data->count = iter;
+
+  // NOTE deallocation is done in the main threa after data is outputted to file (I think is the best solution)
+  return 0;
+}
+
+/* ################################################################### *
+ * MAIN THREAD
+ * ################################################################### */
+
+int main(int argc, char* argv[]) {
+	pthread_attr_t attr;
+	pthread_t * threads;
+	private_t * data, * pdata;
+	struct timeval real_start, start, end;
+	struct timespec timeout;
+	unsigned long offset;
+	int threads_num, cpus_num, main_cpu;
+	int duration = DEFAULT_DURATION, iterations = DEFAULT_ITERATIONS;
+	int _ret, i, l, c;
+	int end_aligned = 0;
+	struct option long_options[] = {
+	    // These options don't set a flag
+	    {"duration", required_argument, NULL, 'd'},
+	    {"iterations", required_argument, NULL, 'i'},
+	    {"threads", required_argument, NULL, 'n'},
+	    {"test", required_argument, NULL, 't'},
+	    {"reverse", no_argument, NULL, 'r'},
+	    {NULL, 0, NULL, 0}
+	};
+// reading the arguments
+   while(1) {
+	    i = 0;
+	    c = getopt_long(argc, argv, "d:n:t:i:r", long_options, &i);
+
+	    if(c == -1)
+	      break;
+
+	    if(c == 0 && long_options[i].flag == 0)
+	      c = long_options[i].val;
+
+	    switch(c) {
+	     case 0:
+	       /* Flag is automatically set */
+	       break;
+	     case 'd':
+	       duration = atoi(optarg);
+	       break;
+	     case 'i':
+	       iterations = atoi(optarg);
+	       break;
+	     case 'n':
+	       threads_num = atoi(optarg);
+	       break;
+	     case 'r':
+	       end_aligned = 1;
+	       break;
+	     case 't':
+	    	 fprintf(stderr,"case t is not implemented right now %s \n", optarg); // TODO
+
+//	    	 test = test_spinlock; // TODO configure which test to use
+
+	    	break;
+	     default:
+	       exit(1);
+	    }
+	  }
+
+   assert (threads_num >=1);
+   assert (iterations >0);
+   assert (duration >0);
+//   assert (test != 0);
+
+//allocating the memory and private data structures
+   offset = sizeof(private_t) + (sizeof(sample_t)* iterations);
+    if ((data = (private_t *) malloc(threads_num * offset)) == NULL) {
+    	 fprintf(stderr,"ERROR situation data %p threads_num %d offset %ld\n",
+    			data, threads_num, offset);
+		perror("malloc ");
+		exit(1);
+	}
+	if ((threads = (pthread_t *) malloc(threads_num * sizeof(pthread_t)))
+			== NULL) {
+		perror("malloc");
+		exit(1);
+	}
+
+	cpus_num = sysconf(_SC_NPROCESSORS_ONLN);
+	main_cpu = get_cpu();
+	 fprintf(stderr,"creating %d threads on %d cpus from cpu %d\n",
+			threads_num, cpus_num, main_cpu);
+
+#ifdef USE_MEMORY_PROTECT
+	// TODO additional creation parameters ( memory lock scheduling)
+#endif
+
+
+#ifdef USE_BARRIERS
+	barrier_init(&barrier, threads_num + 1);
+#endif
+
+//init the lock (before was in each thread, look at the code above)
+    INIT_TEST_GLOBAL(threads_num);
+
+// creating the threads
+	pthread_attr_init(&attr);
+	pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+#ifdef USE_SCHED_POLICY
+
+	struct sched_param param;
+
+	prio = getpriority(PRIO_PROCESS, 0);
+
+	param.sched_priority = MAIN_PRIO;
+	sched_setscheduler(0, SCHED_FIFO, &param);
+
+#endif
+	pdata = data;
+	l = 0;
+	for (i = 0; i < threads_num; i++) {
+		pdata->count = iterations; //nota itereations is the same as sample num
+		pdata->index = i;
+#ifdef SKIP_CURRENT
+		//filling policy skipping current
+		pdata->cpu = (i != main_cpu) ? l++ : (l +1)++ ;// skip the current policy
+#else
+		//where is the data (on which node? how far is the node?)
+#ifdef CIRCULAR_MAP
+		//assign always a new node (circular assignment)
+		// 4 is the number of zones
+		nodes = 4;
+		pdata->cpu = (i % nodes) * (cpus_num / nodes) + (i / nodes);
+#elif defined(RANDOM_MAP)
+
+__gen:
+		ran_num = random() * cpu_num; //TODO
+		if (is_assigned (assign_mask,ran_num) )
+			mask (assign_maks, ran_num)
+			pdata->cpu = ran_num();
+		else
+			goto __gen;
+
+		// TODO before the main for loop that creates each thread clear the assign_mask
+
+#else
+		// filling policy
+		pdata->cpu = i;
+#endif
+
+#endif
+		pdata->cpu %= cpus_num;
+		//memset(pdata->samples, 0, sizeof(sample_t) * iterations);
+
+		 fprintf(stderr,"Creating thread %d cpu %d\n", i, pdata->cpu);
+		if (pthread_create(&threads[i], &attr, test, (void *) (pdata))
+				!= 0) {
+			fprintf(stderr, "Error creating thread\n");
+			exit(1);
+		}
+		pdata = (private_t *)((void* )pdata + offset);
+	}
+	pthread_attr_destroy(&attr);
+
+	// TODO Catch some signals
+/*	if (signal(SIGHUP, catcher) == SIG_ERR || signal(SIGINT, catcher) == SIG_ERR
+			|| signal(SIGTERM, catcher) == SIG_ERR) {
+		perror("signal");
+		exit(1);
+	}
+	*/
+
+// Start threads
+	gettimeofday(&real_start, NULL);
+#ifdef USE_BARRIERS
+	barrier_cross(&barrier);
+#endif
+	gettimeofday(&start, NULL);
+	 fprintf(stderr,"STARTING...\n");
+	if (duration > 0) {
+		timeout.tv_nsec = duration;
+		timeout.tv_sec = 0;
+		nanosleep(&timeout, NULL);
+	} else {
+		/* TODO
+		sigemptyset(&block_set);
+		sigsuspend(&block_set);
+		*/
+	}
+
+// Stopping the threads
+	stop = 1;
+	gettimeofday(&end, NULL);
+	 fprintf(stderr,"STOPPING...\n");
+
+	for (i = 0; i < threads_num; i++) {
+		if (pthread_join(threads[i], NULL) != 0) {
+			fprintf(stderr, "Error waiting for thread completion\n");
+			exit(1);
+		}
+	}
+
+	iterations = 0;
+	pdata = data;
+	for (l = 0; l< threads_num; l++) {
+		if (pdata->count > iterations)
+			iterations = pdata->count;
+		pdata = (private_t*)((void*)pdata  + offset);
+	}
+	register int ii = (iterations - pdata->count);
+//print the data in human/gnuplot readable format one column is a data set
+	for (i = 0; i< iterations; i++ ) {
+		c = 0; // do not print results when no one collected data --- replaced by the for loop on num threads before this loop
+		pdata = data;
+		printf("%d ", i);
+		for (l = 0; l< threads_num; l++) {
+			register int ii = (iterations - pdata->count);
+			if (end_aligned) {
+			  if (pdata->count <= i)
+				  c++;
+			  if (i >= ii)
+		 		 printf("%ld ", pdata->samples[i - ii]);
+			  else {
+				printf("%ld ", 0);
+			  }
+			}
+			else {
+			  if (pdata->count > i)
+ 				printf("%ld ", pdata->samples[i]);
+  			  else {
+				printf("%ld ", 0);
+				c++;
+			  }
+			}
+			pdata = (private_t*)((void*)pdata  + offset);
+		}
+		printf("\n");
+		if (c >= threads_num)
+			break;
+	}
+	fprintf(stderr, "printed %d iterations\n", i);
+	// TODO some statistics
+
+	FINALIZE_TEST_GLOBAL(a);
+
+	free (data);
+	return 0;
+}
diff --git a/ipc/test/count.cpp b/ipc/test/count.cpp
new file mode 100644
index 0000000..bac9bbd
--- /dev/null
+++ b/ipc/test/count.cpp
@@ -0,0 +1,4927 @@
+# 1 "count.c"
+# 1 "<built-in>"
+# 1 "<command-line>"
+# 1 "count.c"
+# 27 "count.c"
+# 1 "/usr/include/stdio.h" 1 3 4
+# 28 "/usr/include/stdio.h" 3 4
+# 1 "/usr/include/features.h" 1 3 4
+# 357 "/usr/include/features.h" 3 4
+# 1 "/usr/include/sys/cdefs.h" 1 3 4
+# 353 "/usr/include/sys/cdefs.h" 3 4
+# 1 "/usr/include/bits/wordsize.h" 1 3 4
+# 354 "/usr/include/sys/cdefs.h" 2 3 4
+# 358 "/usr/include/features.h" 2 3 4
+# 381 "/usr/include/features.h" 3 4
+# 1 "/usr/include/gnu/stubs.h" 1 3 4
+
+
+
+# 1 "/usr/include/bits/wordsize.h" 1 3 4
+# 5 "/usr/include/gnu/stubs.h" 2 3 4
+
+
+# 1 "/usr/include/gnu/stubs-32.h" 1 3 4
+# 8 "/usr/include/gnu/stubs.h" 2 3 4
+# 382 "/usr/include/features.h" 2 3 4
+# 29 "/usr/include/stdio.h" 2 3 4
+
+
+
+
+
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 211 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 3 4
+typedef unsigned int size_t;
+# 35 "/usr/include/stdio.h" 2 3 4
+
+# 1 "/usr/include/bits/types.h" 1 3 4
+# 28 "/usr/include/bits/types.h" 3 4
+# 1 "/usr/include/bits/wordsize.h" 1 3 4
+# 29 "/usr/include/bits/types.h" 2 3 4
+
+
+typedef unsigned char __u_char;
+typedef unsigned short int __u_short;
+typedef unsigned int __u_int;
+typedef unsigned long int __u_long;
+
+
+typedef signed char __int8_t;
+typedef unsigned char __uint8_t;
+typedef signed short int __int16_t;
+typedef unsigned short int __uint16_t;
+typedef signed int __int32_t;
+typedef unsigned int __uint32_t;
+
+
+
+
+__extension__ typedef signed long long int __int64_t;
+__extension__ typedef unsigned long long int __uint64_t;
+
+
+
+
+
+
+
+__extension__ typedef long long int __quad_t;
+__extension__ typedef unsigned long long int __u_quad_t;
+# 131 "/usr/include/bits/types.h" 3 4
+# 1 "/usr/include/bits/typesizes.h" 1 3 4
+# 132 "/usr/include/bits/types.h" 2 3 4
+
+
+__extension__ typedef __u_quad_t __dev_t;
+__extension__ typedef unsigned int __uid_t;
+__extension__ typedef unsigned int __gid_t;
+__extension__ typedef unsigned long int __ino_t;
+__extension__ typedef __u_quad_t __ino64_t;
+__extension__ typedef unsigned int __mode_t;
+__extension__ typedef unsigned int __nlink_t;
+__extension__ typedef long int __off_t;
+__extension__ typedef __quad_t __off64_t;
+__extension__ typedef int __pid_t;
+__extension__ typedef struct { int __val[2]; } __fsid_t;
+__extension__ typedef long int __clock_t;
+__extension__ typedef unsigned long int __rlim_t;
+__extension__ typedef __u_quad_t __rlim64_t;
+__extension__ typedef unsigned int __id_t;
+__extension__ typedef long int __time_t;
+__extension__ typedef unsigned int __useconds_t;
+__extension__ typedef long int __suseconds_t;
+
+__extension__ typedef int __daddr_t;
+__extension__ typedef long int __swblk_t;
+__extension__ typedef int __key_t;
+
+
+__extension__ typedef int __clockid_t;
+
+
+__extension__ typedef void * __timer_t;
+
+
+__extension__ typedef long int __blksize_t;
+
+
+
+
+__extension__ typedef long int __blkcnt_t;
+__extension__ typedef __quad_t __blkcnt64_t;
+
+
+__extension__ typedef unsigned long int __fsblkcnt_t;
+__extension__ typedef __u_quad_t __fsblkcnt64_t;
+
+
+__extension__ typedef unsigned long int __fsfilcnt_t;
+__extension__ typedef __u_quad_t __fsfilcnt64_t;
+
+__extension__ typedef int __ssize_t;
+
+
+
+typedef __off64_t __loff_t;
+typedef __quad_t *__qaddr_t;
+typedef char *__caddr_t;
+
+
+__extension__ typedef int __intptr_t;
+
+
+__extension__ typedef unsigned int __socklen_t;
+# 37 "/usr/include/stdio.h" 2 3 4
+# 45 "/usr/include/stdio.h" 3 4
+struct _IO_FILE;
+
+
+
+typedef struct _IO_FILE FILE;
+
+
+
+
+
+# 65 "/usr/include/stdio.h" 3 4
+typedef struct _IO_FILE __FILE;
+# 75 "/usr/include/stdio.h" 3 4
+# 1 "/usr/include/libio.h" 1 3 4
+# 32 "/usr/include/libio.h" 3 4
+# 1 "/usr/include/_G_config.h" 1 3 4
+# 15 "/usr/include/_G_config.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 16 "/usr/include/_G_config.h" 2 3 4
+
+
+
+
+# 1 "/usr/include/wchar.h" 1 3 4
+# 83 "/usr/include/wchar.h" 3 4
+typedef struct
+{
+  int __count;
+  union
+  {
+
+    unsigned int __wch;
+
+
+
+    char __wchb[4];
+  } __value;
+} __mbstate_t;
+# 21 "/usr/include/_G_config.h" 2 3 4
+
+typedef struct
+{
+  __off_t __pos;
+  __mbstate_t __state;
+} _G_fpos_t;
+typedef struct
+{
+  __off64_t __pos;
+  __mbstate_t __state;
+} _G_fpos64_t;
+# 53 "/usr/include/_G_config.h" 3 4
+typedef int _G_int16_t __attribute__ ((__mode__ (__HI__)));
+typedef int _G_int32_t __attribute__ ((__mode__ (__SI__)));
+typedef unsigned int _G_uint16_t __attribute__ ((__mode__ (__HI__)));
+typedef unsigned int _G_uint32_t __attribute__ ((__mode__ (__SI__)));
+# 33 "/usr/include/libio.h" 2 3 4
+# 53 "/usr/include/libio.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stdarg.h" 1 3 4
+# 40 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stdarg.h" 3 4
+typedef __builtin_va_list __gnuc_va_list;
+# 54 "/usr/include/libio.h" 2 3 4
+# 170 "/usr/include/libio.h" 3 4
+struct _IO_jump_t; struct _IO_FILE;
+# 180 "/usr/include/libio.h" 3 4
+typedef void _IO_lock_t;
+
+
+
+
+
+struct _IO_marker {
+  struct _IO_marker *_next;
+  struct _IO_FILE *_sbuf;
+
+
+
+  int _pos;
+# 203 "/usr/include/libio.h" 3 4
+};
+
+
+enum __codecvt_result
+{
+  __codecvt_ok,
+  __codecvt_partial,
+  __codecvt_error,
+  __codecvt_noconv
+};
+# 271 "/usr/include/libio.h" 3 4
+struct _IO_FILE {
+  int _flags;
+
+
+
+
+  char* _IO_read_ptr;
+  char* _IO_read_end;
+  char* _IO_read_base;
+  char* _IO_write_base;
+  char* _IO_write_ptr;
+  char* _IO_write_end;
+  char* _IO_buf_base;
+  char* _IO_buf_end;
+
+  char *_IO_save_base;
+  char *_IO_backup_base;
+  char *_IO_save_end;
+
+  struct _IO_marker *_markers;
+
+  struct _IO_FILE *_chain;
+
+  int _fileno;
+
+
+
+  int _flags2;
+
+  __off_t _old_offset;
+
+
+
+  unsigned short _cur_column;
+  signed char _vtable_offset;
+  char _shortbuf[1];
+
+
+
+  _IO_lock_t *_lock;
+# 319 "/usr/include/libio.h" 3 4
+  __off64_t _offset;
+# 328 "/usr/include/libio.h" 3 4
+  void *__pad1;
+  void *__pad2;
+  void *__pad3;
+  void *__pad4;
+  size_t __pad5;
+
+  int _mode;
+
+  char _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)];
+
+};
+
+
+typedef struct _IO_FILE _IO_FILE;
+
+
+struct _IO_FILE_plus;
+
+extern struct _IO_FILE_plus _IO_2_1_stdin_;
+extern struct _IO_FILE_plus _IO_2_1_stdout_;
+extern struct _IO_FILE_plus _IO_2_1_stderr_;
+# 364 "/usr/include/libio.h" 3 4
+typedef __ssize_t __io_read_fn (void *__cookie, char *__buf, size_t __nbytes);
+
+
+
+
+
+
+
+typedef __ssize_t __io_write_fn (void *__cookie, __const char *__buf,
+     size_t __n);
+
+
+
+
+
+
+
+typedef int __io_seek_fn (void *__cookie, __off64_t *__pos, int __w);
+
+
+typedef int __io_close_fn (void *__cookie);
+# 416 "/usr/include/libio.h" 3 4
+extern int __underflow (_IO_FILE *);
+extern int __uflow (_IO_FILE *);
+extern int __overflow (_IO_FILE *, int);
+# 460 "/usr/include/libio.h" 3 4
+extern int _IO_getc (_IO_FILE *__fp);
+extern int _IO_putc (int __c, _IO_FILE *__fp);
+extern int _IO_feof (_IO_FILE *__fp) __attribute__ ((__nothrow__));
+extern int _IO_ferror (_IO_FILE *__fp) __attribute__ ((__nothrow__));
+
+extern int _IO_peekc_locked (_IO_FILE *__fp);
+
+
+
+
+
+extern void _IO_flockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+extern void _IO_funlockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+extern int _IO_ftrylockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+# 490 "/usr/include/libio.h" 3 4
+extern int _IO_vfscanf (_IO_FILE * __restrict, const char * __restrict,
+   __gnuc_va_list, int *__restrict);
+extern int _IO_vfprintf (_IO_FILE *__restrict, const char *__restrict,
+    __gnuc_va_list);
+extern __ssize_t _IO_padn (_IO_FILE *, int, __ssize_t);
+extern size_t _IO_sgetn (_IO_FILE *, void *, size_t);
+
+extern __off64_t _IO_seekoff (_IO_FILE *, __off64_t, int, int);
+extern __off64_t _IO_seekpos (_IO_FILE *, __off64_t, int);
+
+extern void _IO_free_backup_area (_IO_FILE *) __attribute__ ((__nothrow__));
+# 76 "/usr/include/stdio.h" 2 3 4
+
+
+
+
+typedef __gnuc_va_list va_list;
+# 91 "/usr/include/stdio.h" 3 4
+typedef __off_t off_t;
+# 103 "/usr/include/stdio.h" 3 4
+typedef __ssize_t ssize_t;
+
+
+
+
+
+
+
+typedef _G_fpos_t fpos_t;
+
+
+
+
+# 161 "/usr/include/stdio.h" 3 4
+# 1 "/usr/include/bits/stdio_lim.h" 1 3 4
+# 162 "/usr/include/stdio.h" 2 3 4
+
+
+
+extern struct _IO_FILE *stdin;
+extern struct _IO_FILE *stdout;
+extern struct _IO_FILE *stderr;
+
+
+
+
+
+
+
+extern int remove (__const char *__filename) __attribute__ ((__nothrow__));
+
+extern int rename (__const char *__old, __const char *__new) __attribute__ ((__nothrow__));
+
+
+
+
+extern int renameat (int __oldfd, __const char *__old, int __newfd,
+       __const char *__new) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+
+extern FILE *tmpfile (void) ;
+# 206 "/usr/include/stdio.h" 3 4
+extern char *tmpnam (char *__s) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+extern char *tmpnam_r (char *__s) __attribute__ ((__nothrow__)) ;
+# 224 "/usr/include/stdio.h" 3 4
+extern char *tempnam (__const char *__dir, __const char *__pfx)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) ;
+
+
+
+
+
+
+
+
+extern int fclose (FILE *__stream);
+
+
+
+
+extern int fflush (FILE *__stream);
+
+# 249 "/usr/include/stdio.h" 3 4
+extern int fflush_unlocked (FILE *__stream);
+# 263 "/usr/include/stdio.h" 3 4
+
+
+
+
+
+
+extern FILE *fopen (__const char *__restrict __filename,
+      __const char *__restrict __modes) ;
+
+
+
+
+extern FILE *freopen (__const char *__restrict __filename,
+        __const char *__restrict __modes,
+        FILE *__restrict __stream) ;
+# 292 "/usr/include/stdio.h" 3 4
+
+# 303 "/usr/include/stdio.h" 3 4
+extern FILE *fdopen (int __fd, __const char *__modes) __attribute__ ((__nothrow__)) ;
+# 316 "/usr/include/stdio.h" 3 4
+extern FILE *fmemopen (void *__s, size_t __len, __const char *__modes)
+  __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern FILE *open_memstream (char **__bufloc, size_t *__sizeloc) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+
+extern void setbuf (FILE *__restrict __stream, char *__restrict __buf) __attribute__ ((__nothrow__));
+
+
+
+extern int setvbuf (FILE *__restrict __stream, char *__restrict __buf,
+      int __modes, size_t __n) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern void setbuffer (FILE *__restrict __stream, char *__restrict __buf,
+         size_t __size) __attribute__ ((__nothrow__));
+
+
+extern void setlinebuf (FILE *__stream) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+
+extern int fprintf (FILE *__restrict __stream,
+      __const char *__restrict __format, ...);
+
+
+
+
+extern int printf (__const char *__restrict __format, ...);
+
+extern int sprintf (char *__restrict __s,
+      __const char *__restrict __format, ...) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern int vfprintf (FILE *__restrict __s, __const char *__restrict __format,
+       __gnuc_va_list __arg);
+
+
+
+
+extern int vprintf (__const char *__restrict __format, __gnuc_va_list __arg);
+
+extern int vsprintf (char *__restrict __s, __const char *__restrict __format,
+       __gnuc_va_list __arg) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern int snprintf (char *__restrict __s, size_t __maxlen,
+       __const char *__restrict __format, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
+
+extern int vsnprintf (char *__restrict __s, size_t __maxlen,
+        __const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));
+
+# 414 "/usr/include/stdio.h" 3 4
+extern int vdprintf (int __fd, __const char *__restrict __fmt,
+       __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__printf__, 2, 0)));
+extern int dprintf (int __fd, __const char *__restrict __fmt, ...)
+     __attribute__ ((__format__ (__printf__, 2, 3)));
+
+
+
+
+
+
+
+
+extern int fscanf (FILE *__restrict __stream,
+     __const char *__restrict __format, ...) ;
+
+
+
+
+extern int scanf (__const char *__restrict __format, ...) ;
+
+extern int sscanf (__const char *__restrict __s,
+     __const char *__restrict __format, ...) __attribute__ ((__nothrow__));
+# 445 "/usr/include/stdio.h" 3 4
+extern int fscanf (FILE *__restrict __stream, __const char *__restrict __format, ...) __asm__ ("" "__isoc99_fscanf")
+
+                               ;
+extern int scanf (__const char *__restrict __format, ...) __asm__ ("" "__isoc99_scanf")
+                              ;
+extern int sscanf (__const char *__restrict __s, __const char *__restrict __format, ...) __asm__ ("" "__isoc99_sscanf") __attribute__ ((__nothrow__))
+
+                      ;
+# 465 "/usr/include/stdio.h" 3 4
+
+
+
+
+
+
+
+
+extern int vfscanf (FILE *__restrict __s, __const char *__restrict __format,
+      __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
+
+
+
+
+
+extern int vscanf (__const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
+
+
+extern int vsscanf (__const char *__restrict __s,
+      __const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__scanf__, 2, 0)));
+# 496 "/usr/include/stdio.h" 3 4
+extern int vfscanf (FILE *__restrict __s, __const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vfscanf")
+
+
+
+     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
+extern int vscanf (__const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vscanf")
+
+     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
+extern int vsscanf (__const char *__restrict __s, __const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vsscanf") __attribute__ ((__nothrow__))
+
+
+
+     __attribute__ ((__format__ (__scanf__, 2, 0)));
+# 524 "/usr/include/stdio.h" 3 4
+
+
+
+
+
+
+
+
+
+extern int fgetc (FILE *__stream);
+extern int getc (FILE *__stream);
+
+
+
+
+
+extern int getchar (void);
+
+# 552 "/usr/include/stdio.h" 3 4
+extern int getc_unlocked (FILE *__stream);
+extern int getchar_unlocked (void);
+# 563 "/usr/include/stdio.h" 3 4
+extern int fgetc_unlocked (FILE *__stream);
+
+
+
+
+
+
+
+
+
+
+
+extern int fputc (int __c, FILE *__stream);
+extern int putc (int __c, FILE *__stream);
+
+
+
+
+
+extern int putchar (int __c);
+
+# 596 "/usr/include/stdio.h" 3 4
+extern int fputc_unlocked (int __c, FILE *__stream);
+
+
+
+
+
+
+
+extern int putc_unlocked (int __c, FILE *__stream);
+extern int putchar_unlocked (int __c);
+
+
+
+
+
+
+extern int getw (FILE *__stream);
+
+
+extern int putw (int __w, FILE *__stream);
+
+
+
+
+
+
+
+
+extern char *fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
+     ;
+
+
+
+
+
+
+extern char *gets (char *__s) ;
+
+# 658 "/usr/include/stdio.h" 3 4
+extern __ssize_t __getdelim (char **__restrict __lineptr,
+          size_t *__restrict __n, int __delimiter,
+          FILE *__restrict __stream) ;
+extern __ssize_t getdelim (char **__restrict __lineptr,
+        size_t *__restrict __n, int __delimiter,
+        FILE *__restrict __stream) ;
+
+
+
+
+
+
+
+extern __ssize_t getline (char **__restrict __lineptr,
+       size_t *__restrict __n,
+       FILE *__restrict __stream) ;
+
+
+
+
+
+
+
+
+extern int fputs (__const char *__restrict __s, FILE *__restrict __stream);
+
+
+
+
+
+extern int puts (__const char *__s);
+
+
+
+
+
+
+extern int ungetc (int __c, FILE *__stream);
+
+
+
+
+
+
+extern size_t fread (void *__restrict __ptr, size_t __size,
+       size_t __n, FILE *__restrict __stream) ;
+
+
+
+
+extern size_t fwrite (__const void *__restrict __ptr, size_t __size,
+        size_t __n, FILE *__restrict __s) ;
+
+# 730 "/usr/include/stdio.h" 3 4
+extern size_t fread_unlocked (void *__restrict __ptr, size_t __size,
+         size_t __n, FILE *__restrict __stream) ;
+extern size_t fwrite_unlocked (__const void *__restrict __ptr, size_t __size,
+          size_t __n, FILE *__restrict __stream) ;
+
+
+
+
+
+
+
+
+extern int fseek (FILE *__stream, long int __off, int __whence);
+
+
+
+
+extern long int ftell (FILE *__stream) ;
+
+
+
+
+extern void rewind (FILE *__stream);
+
+# 766 "/usr/include/stdio.h" 3 4
+extern int fseeko (FILE *__stream, __off_t __off, int __whence);
+
+
+
+
+extern __off_t ftello (FILE *__stream) ;
+# 785 "/usr/include/stdio.h" 3 4
+
+
+
+
+
+
+extern int fgetpos (FILE *__restrict __stream, fpos_t *__restrict __pos);
+
+
+
+
+extern int fsetpos (FILE *__stream, __const fpos_t *__pos);
+# 808 "/usr/include/stdio.h" 3 4
+
+# 817 "/usr/include/stdio.h" 3 4
+
+
+extern void clearerr (FILE *__stream) __attribute__ ((__nothrow__));
+
+extern int feof (FILE *__stream) __attribute__ ((__nothrow__)) ;
+
+extern int ferror (FILE *__stream) __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern void clearerr_unlocked (FILE *__stream) __attribute__ ((__nothrow__));
+extern int feof_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) ;
+extern int ferror_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+
+
+
+extern void perror (__const char *__s);
+
+
+
+
+
+
+# 1 "/usr/include/bits/sys_errlist.h" 1 3 4
+# 27 "/usr/include/bits/sys_errlist.h" 3 4
+extern int sys_nerr;
+extern __const char *__const sys_errlist[];
+# 847 "/usr/include/stdio.h" 2 3 4
+
+
+
+
+extern int fileno (FILE *__stream) __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern int fileno_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) ;
+# 866 "/usr/include/stdio.h" 3 4
+extern FILE *popen (__const char *__command, __const char *__modes) ;
+
+
+
+
+
+extern int pclose (FILE *__stream);
+
+
+
+
+
+extern char *ctermid (char *__s) __attribute__ ((__nothrow__));
+# 906 "/usr/include/stdio.h" 3 4
+extern void flockfile (FILE *__stream) __attribute__ ((__nothrow__));
+
+
+
+extern int ftrylockfile (FILE *__stream) __attribute__ ((__nothrow__)) ;
+
+
+extern void funlockfile (FILE *__stream) __attribute__ ((__nothrow__));
+# 936 "/usr/include/stdio.h" 3 4
+
+# 28 "count.c" 2
+# 1 "/usr/include/sys/time.h" 1 3 4
+# 27 "/usr/include/sys/time.h" 3 4
+# 1 "/usr/include/time.h" 1 3 4
+# 74 "/usr/include/time.h" 3 4
+
+
+typedef __time_t time_t;
+
+
+
+# 28 "/usr/include/sys/time.h" 2 3 4
+
+# 1 "/usr/include/bits/time.h" 1 3 4
+# 75 "/usr/include/bits/time.h" 3 4
+struct timeval
+  {
+    __time_t tv_sec;
+    __suseconds_t tv_usec;
+  };
+# 30 "/usr/include/sys/time.h" 2 3 4
+
+# 1 "/usr/include/sys/select.h" 1 3 4
+# 31 "/usr/include/sys/select.h" 3 4
+# 1 "/usr/include/bits/select.h" 1 3 4
+# 32 "/usr/include/sys/select.h" 2 3 4
+
+
+# 1 "/usr/include/bits/sigset.h" 1 3 4
+# 24 "/usr/include/bits/sigset.h" 3 4
+typedef int __sig_atomic_t;
+
+
+
+
+typedef struct
+  {
+    unsigned long int __val[(1024 / (8 * sizeof (unsigned long int)))];
+  } __sigset_t;
+# 35 "/usr/include/sys/select.h" 2 3 4
+
+
+
+typedef __sigset_t sigset_t;
+
+
+
+
+
+# 1 "/usr/include/time.h" 1 3 4
+# 120 "/usr/include/time.h" 3 4
+struct timespec
+  {
+    __time_t tv_sec;
+    long int tv_nsec;
+  };
+# 45 "/usr/include/sys/select.h" 2 3 4
+
+# 1 "/usr/include/bits/time.h" 1 3 4
+# 47 "/usr/include/sys/select.h" 2 3 4
+
+
+typedef __suseconds_t suseconds_t;
+
+
+
+
+
+typedef long int __fd_mask;
+# 67 "/usr/include/sys/select.h" 3 4
+typedef struct
+  {
+
+
+
+
+
+
+    __fd_mask __fds_bits[1024 / (8 * (int) sizeof (__fd_mask))];
+
+
+  } fd_set;
+
+
+
+
+
+
+typedef __fd_mask fd_mask;
+# 99 "/usr/include/sys/select.h" 3 4
+
+# 109 "/usr/include/sys/select.h" 3 4
+extern int select (int __nfds, fd_set *__restrict __readfds,
+     fd_set *__restrict __writefds,
+     fd_set *__restrict __exceptfds,
+     struct timeval *__restrict __timeout);
+# 121 "/usr/include/sys/select.h" 3 4
+extern int pselect (int __nfds, fd_set *__restrict __readfds,
+      fd_set *__restrict __writefds,
+      fd_set *__restrict __exceptfds,
+      const struct timespec *__restrict __timeout,
+      const __sigset_t *__restrict __sigmask);
+
+
+
+# 32 "/usr/include/sys/time.h" 2 3 4
+
+
+
+
+
+
+
+
+# 57 "/usr/include/sys/time.h" 3 4
+struct timezone
+  {
+    int tz_minuteswest;
+    int tz_dsttime;
+  };
+
+typedef struct timezone *__restrict __timezone_ptr_t;
+# 73 "/usr/include/sys/time.h" 3 4
+extern int gettimeofday (struct timeval *__restrict __tv,
+    __timezone_ptr_t __tz) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+extern int settimeofday (__const struct timeval *__tv,
+    __const struct timezone *__tz)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+extern int adjtime (__const struct timeval *__delta,
+      struct timeval *__olddelta) __attribute__ ((__nothrow__));
+
+
+
+
+enum __itimer_which
+  {
+
+    ITIMER_REAL = 0,
+
+
+    ITIMER_VIRTUAL = 1,
+
+
+
+    ITIMER_PROF = 2
+
+  };
+
+
+
+struct itimerval
+  {
+
+    struct timeval it_interval;
+
+    struct timeval it_value;
+  };
+
+
+
+
+
+
+typedef int __itimer_which_t;
+
+
+
+
+extern int getitimer (__itimer_which_t __which,
+        struct itimerval *__value) __attribute__ ((__nothrow__));
+
+
+
+
+extern int setitimer (__itimer_which_t __which,
+        __const struct itimerval *__restrict __new,
+        struct itimerval *__restrict __old) __attribute__ ((__nothrow__));
+
+
+
+
+extern int utimes (__const char *__file, __const struct timeval __tvp[2])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+extern int lutimes (__const char *__file, __const struct timeval __tvp[2])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int futimes (int __fd, __const struct timeval __tvp[2]) __attribute__ ((__nothrow__));
+# 191 "/usr/include/sys/time.h" 3 4
+
+# 29 "count.c" 2
+
+
+
+
+
+# 1 "atomic.h" 1
+# 35 "count.c" 2
+# 1 "rdtsc.h" 1
+
+
+
+
+# 1 "/usr/include/string.h" 1 3 4
+# 29 "/usr/include/string.h" 3 4
+
+
+
+
+
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 35 "/usr/include/string.h" 2 3 4
+
+
+
+
+
+
+
+
+
+extern void *memcpy (void *__restrict __dest,
+       __const void *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern void *memmove (void *__dest, __const void *__src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+
+
+extern void *memccpy (void *__restrict __dest, __const void *__restrict __src,
+        int __c, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+
+extern void *memset (void *__s, int __c, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int memcmp (__const void *__s1, __const void *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+# 95 "/usr/include/string.h" 3 4
+extern void *memchr (__const void *__s, int __c, size_t __n)
+      __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+
+
+# 126 "/usr/include/string.h" 3 4
+
+
+extern char *strcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern char *strncpy (char *__restrict __dest,
+        __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern char *strcat (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern char *strncat (char *__restrict __dest, __const char *__restrict __src,
+        size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int strcmp (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern int strncmp (__const char *__s1, __const char *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int strcoll (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern size_t strxfrm (char *__restrict __dest,
+         __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+
+
+
+
+# 1 "/usr/include/xlocale.h" 1 3 4
+# 28 "/usr/include/xlocale.h" 3 4
+typedef struct __locale_struct
+{
+
+  struct __locale_data *__locales[13];
+
+
+  const unsigned short int *__ctype_b;
+  const int *__ctype_tolower;
+  const int *__ctype_toupper;
+
+
+  const char *__names[13];
+} *__locale_t;
+
+
+typedef __locale_t locale_t;
+# 163 "/usr/include/string.h" 2 3 4
+
+
+extern int strcoll_l (__const char *__s1, __const char *__s2, __locale_t __l)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 3)));
+
+extern size_t strxfrm_l (char *__dest, __const char *__src, size_t __n,
+    __locale_t __l) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 4)));
+
+
+
+
+
+extern char *strdup (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern char *strndup (__const char *__string, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
+# 210 "/usr/include/string.h" 3 4
+
+# 235 "/usr/include/string.h" 3 4
+extern char *strchr (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+# 262 "/usr/include/string.h" 3 4
+extern char *strrchr (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+
+
+# 281 "/usr/include/string.h" 3 4
+
+
+
+extern size_t strcspn (__const char *__s, __const char *__reject)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern size_t strspn (__const char *__s, __const char *__accept)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+# 314 "/usr/include/string.h" 3 4
+extern char *strpbrk (__const char *__s, __const char *__accept)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+# 342 "/usr/include/string.h" 3 4
+extern char *strstr (__const char *__haystack, __const char *__needle)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+extern char *strtok (char *__restrict __s, __const char *__restrict __delim)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+
+
+extern char *__strtok_r (char *__restrict __s,
+    __const char *__restrict __delim,
+    char **__restrict __save_ptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3)));
+
+extern char *strtok_r (char *__restrict __s, __const char *__restrict __delim,
+         char **__restrict __save_ptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3)));
+# 397 "/usr/include/string.h" 3 4
+
+
+extern size_t strlen (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+extern size_t strnlen (__const char *__string, size_t __maxlen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+extern char *strerror (int __errnum) __attribute__ ((__nothrow__));
+
+# 427 "/usr/include/string.h" 3 4
+extern int strerror_r (int __errnum, char *__buf, size_t __buflen) __asm__ ("" "__xpg_strerror_r") __attribute__ ((__nothrow__))
+
+                        __attribute__ ((__nonnull__ (2)));
+# 445 "/usr/include/string.h" 3 4
+extern char *strerror_l (int __errnum, __locale_t __l) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern void __bzero (void *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+extern void bcopy (__const void *__src, void *__dest, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern void bzero (void *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int bcmp (__const void *__s1, __const void *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+# 489 "/usr/include/string.h" 3 4
+extern char *index (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+# 517 "/usr/include/string.h" 3 4
+extern char *rindex (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+extern int ffs (int __i) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+# 536 "/usr/include/string.h" 3 4
+extern int strcasecmp (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int strncasecmp (__const char *__s1, __const char *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+# 559 "/usr/include/string.h" 3 4
+extern char *strsep (char **__restrict __stringp,
+       __const char *__restrict __delim)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+extern char *strsignal (int __sig) __attribute__ ((__nothrow__));
+
+
+extern char *__stpcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *stpcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+extern char *__stpncpy (char *__restrict __dest,
+   __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *stpncpy (char *__restrict __dest,
+        __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+# 646 "/usr/include/string.h" 3 4
+
+# 6 "rdtsc.h" 2
+# 1 "/usr/include/signal.h" 1 3 4
+# 31 "/usr/include/signal.h" 3 4
+
+
+# 1 "/usr/include/bits/sigset.h" 1 3 4
+# 104 "/usr/include/bits/sigset.h" 3 4
+extern int __sigismember (__const __sigset_t *, int);
+extern int __sigaddset (__sigset_t *, int);
+extern int __sigdelset (__sigset_t *, int);
+# 34 "/usr/include/signal.h" 2 3 4
+
+
+
+
+
+
+
+typedef __sig_atomic_t sig_atomic_t;
+
+# 58 "/usr/include/signal.h" 3 4
+# 1 "/usr/include/bits/signum.h" 1 3 4
+# 59 "/usr/include/signal.h" 2 3 4
+
+
+
+typedef __pid_t pid_t;
+
+
+
+
+
+typedef __uid_t uid_t;
+
+
+
+
+
+
+
+# 1 "/usr/include/time.h" 1 3 4
+# 77 "/usr/include/signal.h" 2 3 4
+
+
+# 1 "/usr/include/bits/siginfo.h" 1 3 4
+# 25 "/usr/include/bits/siginfo.h" 3 4
+# 1 "/usr/include/bits/wordsize.h" 1 3 4
+# 26 "/usr/include/bits/siginfo.h" 2 3 4
+
+
+
+
+
+
+
+typedef union sigval
+  {
+    int sival_int;
+    void *sival_ptr;
+  } sigval_t;
+# 51 "/usr/include/bits/siginfo.h" 3 4
+typedef struct siginfo
+  {
+    int si_signo;
+    int si_errno;
+
+    int si_code;
+
+    union
+      {
+ int _pad[((128 / sizeof (int)) - 3)];
+
+
+ struct
+   {
+     __pid_t si_pid;
+     __uid_t si_uid;
+   } _kill;
+
+
+ struct
+   {
+     int si_tid;
+     int si_overrun;
+     sigval_t si_sigval;
+   } _timer;
+
+
+ struct
+   {
+     __pid_t si_pid;
+     __uid_t si_uid;
+     sigval_t si_sigval;
+   } _rt;
+
+
+ struct
+   {
+     __pid_t si_pid;
+     __uid_t si_uid;
+     int si_status;
+     __clock_t si_utime;
+     __clock_t si_stime;
+   } _sigchld;
+
+
+ struct
+   {
+     void *si_addr;
+   } _sigfault;
+
+
+ struct
+   {
+     long int si_band;
+     int si_fd;
+   } _sigpoll;
+      } _sifields;
+  } siginfo_t;
+# 129 "/usr/include/bits/siginfo.h" 3 4
+enum
+{
+  SI_ASYNCNL = -60,
+
+  SI_TKILL = -6,
+
+  SI_SIGIO,
+
+  SI_ASYNCIO,
+
+  SI_MESGQ,
+
+  SI_TIMER,
+
+  SI_QUEUE,
+
+  SI_USER,
+
+  SI_KERNEL = 0x80
+
+};
+
+
+
+enum
+{
+  ILL_ILLOPC = 1,
+
+  ILL_ILLOPN,
+
+  ILL_ILLADR,
+
+  ILL_ILLTRP,
+
+  ILL_PRVOPC,
+
+  ILL_PRVREG,
+
+  ILL_COPROC,
+
+  ILL_BADSTK
+
+};
+
+
+enum
+{
+  FPE_INTDIV = 1,
+
+  FPE_INTOVF,
+
+  FPE_FLTDIV,
+
+  FPE_FLTOVF,
+
+  FPE_FLTUND,
+
+  FPE_FLTRES,
+
+  FPE_FLTINV,
+
+  FPE_FLTSUB
+
+};
+
+
+enum
+{
+  SEGV_MAPERR = 1,
+
+  SEGV_ACCERR
+
+};
+
+
+enum
+{
+  BUS_ADRALN = 1,
+
+  BUS_ADRERR,
+
+  BUS_OBJERR
+
+};
+
+
+enum
+{
+  TRAP_BRKPT = 1,
+
+  TRAP_TRACE
+
+};
+
+
+enum
+{
+  CLD_EXITED = 1,
+
+  CLD_KILLED,
+
+  CLD_DUMPED,
+
+  CLD_TRAPPED,
+
+  CLD_STOPPED,
+
+  CLD_CONTINUED
+
+};
+
+
+enum
+{
+  POLL_IN = 1,
+
+  POLL_OUT,
+
+  POLL_MSG,
+
+  POLL_ERR,
+
+  POLL_PRI,
+
+  POLL_HUP
+
+};
+# 273 "/usr/include/bits/siginfo.h" 3 4
+typedef struct sigevent
+  {
+    sigval_t sigev_value;
+    int sigev_signo;
+    int sigev_notify;
+
+    union
+      {
+ int _pad[((64 / sizeof (int)) - 3)];
+
+
+
+ __pid_t _tid;
+
+ struct
+   {
+     void (*_function) (sigval_t);
+     void *_attribute;
+   } _sigev_thread;
+      } _sigev_un;
+  } sigevent_t;
+
+
+
+
+
+
+enum
+{
+  SIGEV_SIGNAL = 0,
+
+  SIGEV_NONE,
+
+  SIGEV_THREAD,
+
+
+  SIGEV_THREAD_ID = 4
+
+};
+# 80 "/usr/include/signal.h" 2 3 4
+
+
+
+
+typedef void (*__sighandler_t) (int);
+
+
+
+
+extern __sighandler_t __sysv_signal (int __sig, __sighandler_t __handler)
+     __attribute__ ((__nothrow__));
+# 99 "/usr/include/signal.h" 3 4
+
+
+extern __sighandler_t signal (int __sig, __sighandler_t __handler)
+     __attribute__ ((__nothrow__));
+# 113 "/usr/include/signal.h" 3 4
+
+# 126 "/usr/include/signal.h" 3 4
+extern int kill (__pid_t __pid, int __sig) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int killpg (__pid_t __pgrp, int __sig) __attribute__ ((__nothrow__));
+
+
+
+
+extern int raise (int __sig) __attribute__ ((__nothrow__));
+
+
+
+
+extern __sighandler_t ssignal (int __sig, __sighandler_t __handler)
+     __attribute__ ((__nothrow__));
+extern int gsignal (int __sig) __attribute__ ((__nothrow__));
+
+
+
+
+extern void psignal (int __sig, __const char *__s);
+
+
+
+
+extern void psiginfo (__const siginfo_t *__pinfo, __const char *__s);
+# 168 "/usr/include/signal.h" 3 4
+extern int __sigpause (int __sig_or_mask, int __is_sig);
+# 196 "/usr/include/signal.h" 3 4
+extern int sigblock (int __mask) __attribute__ ((__nothrow__)) __attribute__ ((__deprecated__));
+
+
+extern int sigsetmask (int __mask) __attribute__ ((__nothrow__)) __attribute__ ((__deprecated__));
+
+
+extern int siggetmask (void) __attribute__ ((__nothrow__)) __attribute__ ((__deprecated__));
+# 216 "/usr/include/signal.h" 3 4
+typedef __sighandler_t sig_t;
+
+
+
+
+
+extern int sigemptyset (sigset_t *__set) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int sigfillset (sigset_t *__set) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int sigaddset (sigset_t *__set, int __signo) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int sigdelset (sigset_t *__set, int __signo) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern int sigismember (__const sigset_t *__set, int __signo)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+# 252 "/usr/include/signal.h" 3 4
+# 1 "/usr/include/bits/sigaction.h" 1 3 4
+# 25 "/usr/include/bits/sigaction.h" 3 4
+struct sigaction
+  {
+
+
+    union
+      {
+
+ __sighandler_t sa_handler;
+
+ void (*sa_sigaction) (int, siginfo_t *, void *);
+      }
+    __sigaction_handler;
+
+
+
+
+
+
+
+    __sigset_t sa_mask;
+
+
+    int sa_flags;
+
+
+    void (*sa_restorer) (void);
+  };
+# 253 "/usr/include/signal.h" 2 3 4
+
+
+extern int sigprocmask (int __how, __const sigset_t *__restrict __set,
+   sigset_t *__restrict __oset) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int sigsuspend (__const sigset_t *__set) __attribute__ ((__nonnull__ (1)));
+
+
+extern int sigaction (int __sig, __const struct sigaction *__restrict __act,
+        struct sigaction *__restrict __oact) __attribute__ ((__nothrow__));
+
+
+extern int sigpending (sigset_t *__set) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern int sigwait (__const sigset_t *__restrict __set, int *__restrict __sig)
+     __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+
+
+extern int sigwaitinfo (__const sigset_t *__restrict __set,
+   siginfo_t *__restrict __info) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern int sigtimedwait (__const sigset_t *__restrict __set,
+    siginfo_t *__restrict __info,
+    __const struct timespec *__restrict __timeout)
+     __attribute__ ((__nonnull__ (1)));
+
+
+
+extern int sigqueue (__pid_t __pid, int __sig, __const union sigval __val)
+     __attribute__ ((__nothrow__));
+# 310 "/usr/include/signal.h" 3 4
+extern __const char *__const _sys_siglist[65];
+extern __const char *__const sys_siglist[65];
+
+
+struct sigvec
+  {
+    __sighandler_t sv_handler;
+    int sv_mask;
+
+    int sv_flags;
+
+  };
+# 334 "/usr/include/signal.h" 3 4
+extern int sigvec (int __sig, __const struct sigvec *__vec,
+     struct sigvec *__ovec) __attribute__ ((__nothrow__));
+
+
+
+# 1 "/usr/include/bits/sigcontext.h" 1 3 4
+# 28 "/usr/include/bits/sigcontext.h" 3 4
+# 1 "/usr/include/asm/sigcontext.h" 1 3 4
+
+
+
+
+# 1 "/usr/include/linux/types.h" 1 3 4
+
+
+
+# 1 "/usr/include/asm/types.h" 1 3 4
+
+
+
+
+
+# 1 "/usr/include/asm-generic/types.h" 1 3 4
+
+
+
+
+
+
+# 1 "/usr/include/asm-generic/int-ll64.h" 1 3 4
+# 11 "/usr/include/asm-generic/int-ll64.h" 3 4
+# 1 "/usr/include/asm/bitsperlong.h" 1 3 4
+# 10 "/usr/include/asm/bitsperlong.h" 3 4
+# 1 "/usr/include/asm-generic/bitsperlong.h" 1 3 4
+# 11 "/usr/include/asm/bitsperlong.h" 2 3 4
+# 12 "/usr/include/asm-generic/int-ll64.h" 2 3 4
+
+
+
+
+
+
+
+typedef __signed__ char __s8;
+typedef unsigned char __u8;
+
+typedef __signed__ short __s16;
+typedef unsigned short __u16;
+
+typedef __signed__ int __s32;
+typedef unsigned int __u32;
+
+
+__extension__ typedef __signed__ long long __s64;
+__extension__ typedef unsigned long long __u64;
+# 8 "/usr/include/asm-generic/types.h" 2 3 4
+
+
+
+typedef unsigned short umode_t;
+# 7 "/usr/include/asm/types.h" 2 3 4
+# 5 "/usr/include/linux/types.h" 2 3 4
+
+
+
+# 1 "/usr/include/linux/posix_types.h" 1 3 4
+
+
+
+# 1 "/usr/include/linux/stddef.h" 1 3 4
+# 5 "/usr/include/linux/posix_types.h" 2 3 4
+# 36 "/usr/include/linux/posix_types.h" 3 4
+typedef struct {
+ unsigned long fds_bits [(1024/(8 * sizeof(unsigned long)))];
+} __kernel_fd_set;
+
+
+typedef void (*__kernel_sighandler_t)(int);
+
+
+typedef int __kernel_key_t;
+typedef int __kernel_mqd_t;
+
+# 1 "/usr/include/asm/posix_types.h" 1 3 4
+
+# 1 "/usr/include/asm/posix_types_32.h" 1 3 4
+# 10 "/usr/include/asm/posix_types_32.h" 3 4
+typedef unsigned long __kernel_ino_t;
+typedef unsigned short __kernel_mode_t;
+typedef unsigned short __kernel_nlink_t;
+typedef long __kernel_off_t;
+typedef int __kernel_pid_t;
+typedef unsigned short __kernel_ipc_pid_t;
+typedef unsigned short __kernel_uid_t;
+typedef unsigned short __kernel_gid_t;
+typedef unsigned int __kernel_size_t;
+typedef int __kernel_ssize_t;
+typedef int __kernel_ptrdiff_t;
+typedef long __kernel_time_t;
+typedef long __kernel_suseconds_t;
+typedef long __kernel_clock_t;
+typedef int __kernel_timer_t;
+typedef int __kernel_clockid_t;
+typedef int __kernel_daddr_t;
+typedef char * __kernel_caddr_t;
+typedef unsigned short __kernel_uid16_t;
+typedef unsigned short __kernel_gid16_t;
+typedef unsigned int __kernel_uid32_t;
+typedef unsigned int __kernel_gid32_t;
+
+typedef unsigned short __kernel_old_uid_t;
+typedef unsigned short __kernel_old_gid_t;
+typedef unsigned short __kernel_old_dev_t;
+
+
+typedef long long __kernel_loff_t;
+
+
+typedef struct {
+ int val[2];
+} __kernel_fsid_t;
+# 3 "/usr/include/asm/posix_types.h" 2 3 4
+# 48 "/usr/include/linux/posix_types.h" 2 3 4
+# 9 "/usr/include/linux/types.h" 2 3 4
+# 27 "/usr/include/linux/types.h" 3 4
+typedef __u16 __le16;
+typedef __u16 __be16;
+typedef __u32 __le32;
+typedef __u32 __be32;
+typedef __u64 __le64;
+typedef __u64 __be64;
+
+typedef __u16 __sum16;
+typedef __u32 __wsum;
+# 6 "/usr/include/asm/sigcontext.h" 2 3 4
+# 23 "/usr/include/asm/sigcontext.h" 3 4
+struct _fpx_sw_bytes {
+ __u32 magic1;
+ __u32 extended_size;
+
+
+ __u64 xstate_bv;
+
+
+
+
+ __u32 xstate_size;
+
+
+
+
+ __u32 padding[7];
+};
+# 56 "/usr/include/asm/sigcontext.h" 3 4
+struct _fpreg {
+ unsigned short significand[4];
+ unsigned short exponent;
+};
+
+struct _fpxreg {
+ unsigned short significand[4];
+ unsigned short exponent;
+ unsigned short padding[3];
+};
+
+struct _xmmreg {
+ unsigned long element[4];
+};
+
+struct _fpstate {
+
+ unsigned long cw;
+ unsigned long sw;
+ unsigned long tag;
+ unsigned long ipoff;
+ unsigned long cssel;
+ unsigned long dataoff;
+ unsigned long datasel;
+ struct _fpreg _st[8];
+ unsigned short status;
+ unsigned short magic;
+
+
+ unsigned long _fxsr_env[6];
+ unsigned long mxcsr;
+ unsigned long reserved;
+ struct _fpxreg _fxsr_st[8];
+ struct _xmmreg _xmm[8];
+ unsigned long padding1[44];
+
+ union {
+  unsigned long padding2[12];
+  struct _fpx_sw_bytes sw_reserved;
+
+ };
+};
+
+
+
+
+
+
+struct sigcontext {
+ unsigned short gs, __gsh;
+ unsigned short fs, __fsh;
+ unsigned short es, __esh;
+ unsigned short ds, __dsh;
+ unsigned long edi;
+ unsigned long esi;
+ unsigned long ebp;
+ unsigned long esp;
+ unsigned long ebx;
+ unsigned long edx;
+ unsigned long ecx;
+ unsigned long eax;
+ unsigned long trapno;
+ unsigned long err;
+ unsigned long eip;
+ unsigned short cs, __csh;
+ unsigned long eflags;
+ unsigned long esp_at_signal;
+ unsigned short ss, __ssh;
+ struct _fpstate *fpstate;
+ unsigned long oldmask;
+ unsigned long cr2;
+};
+# 190 "/usr/include/asm/sigcontext.h" 3 4
+struct _xsave_hdr {
+ __u64 xstate_bv;
+ __u64 reserved1[2];
+ __u64 reserved2[5];
+};
+
+struct _ymmh_state {
+
+ __u32 ymmh_space[64];
+};
+
+
+
+
+
+
+
+struct _xstate {
+ struct _fpstate fpstate;
+ struct _xsave_hdr xstate_hdr;
+ struct _ymmh_state ymmh;
+
+};
+# 29 "/usr/include/bits/sigcontext.h" 2 3 4
+# 340 "/usr/include/signal.h" 2 3 4
+
+
+extern int sigreturn (struct sigcontext *__scp) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 350 "/usr/include/signal.h" 2 3 4
+
+
+
+
+extern int siginterrupt (int __sig, int __interrupt) __attribute__ ((__nothrow__));
+
+# 1 "/usr/include/bits/sigstack.h" 1 3 4
+# 26 "/usr/include/bits/sigstack.h" 3 4
+struct sigstack
+  {
+    void *ss_sp;
+    int ss_onstack;
+  };
+
+
+
+enum
+{
+  SS_ONSTACK = 1,
+
+  SS_DISABLE
+
+};
+# 50 "/usr/include/bits/sigstack.h" 3 4
+typedef struct sigaltstack
+  {
+    void *ss_sp;
+    int ss_flags;
+    size_t ss_size;
+  } stack_t;
+# 357 "/usr/include/signal.h" 2 3 4
+
+
+# 1 "/usr/include/sys/ucontext.h" 1 3 4
+# 23 "/usr/include/sys/ucontext.h" 3 4
+# 1 "/usr/include/signal.h" 1 3 4
+# 24 "/usr/include/sys/ucontext.h" 2 3 4
+
+
+
+# 1 "/usr/include/bits/sigcontext.h" 1 3 4
+# 28 "/usr/include/sys/ucontext.h" 2 3 4
+
+
+
+typedef int greg_t;
+
+
+
+
+
+typedef greg_t gregset_t[19];
+# 85 "/usr/include/sys/ucontext.h" 3 4
+struct _libc_fpreg
+{
+  unsigned short int significand[4];
+  unsigned short int exponent;
+};
+
+struct _libc_fpstate
+{
+  unsigned long int cw;
+  unsigned long int sw;
+  unsigned long int tag;
+  unsigned long int ipoff;
+  unsigned long int cssel;
+  unsigned long int dataoff;
+  unsigned long int datasel;
+  struct _libc_fpreg _st[8];
+  unsigned long int status;
+};
+
+
+typedef struct _libc_fpstate *fpregset_t;
+
+
+typedef struct
+  {
+    gregset_t gregs;
+
+
+    fpregset_t fpregs;
+    unsigned long int oldmask;
+    unsigned long int cr2;
+  } mcontext_t;
+
+
+typedef struct ucontext
+  {
+    unsigned long int uc_flags;
+    struct ucontext *uc_link;
+    stack_t uc_stack;
+    mcontext_t uc_mcontext;
+    __sigset_t uc_sigmask;
+    struct _libc_fpstate __fpregs_mem;
+  } ucontext_t;
+# 360 "/usr/include/signal.h" 2 3 4
+
+
+
+
+
+extern int sigstack (struct sigstack *__ss, struct sigstack *__oss)
+     __attribute__ ((__nothrow__)) __attribute__ ((__deprecated__));
+
+
+
+extern int sigaltstack (__const struct sigaltstack *__restrict __ss,
+   struct sigaltstack *__restrict __oss) __attribute__ ((__nothrow__));
+# 394 "/usr/include/signal.h" 3 4
+# 1 "/usr/include/bits/pthreadtypes.h" 1 3 4
+# 36 "/usr/include/bits/pthreadtypes.h" 3 4
+typedef unsigned long int pthread_t;
+
+
+typedef union
+{
+  char __size[36];
+  long int __align;
+} pthread_attr_t;
+
+
+typedef struct __pthread_internal_slist
+{
+  struct __pthread_internal_slist *__next;
+} __pthread_slist_t;
+
+
+
+
+typedef union
+{
+  struct __pthread_mutex_s
+  {
+    int __lock;
+    unsigned int __count;
+    int __owner;
+
+
+    int __kind;
+    unsigned int __nusers;
+    __extension__ union
+    {
+      int __spins;
+      __pthread_slist_t __list;
+    };
+  } __data;
+  char __size[24];
+  long int __align;
+} pthread_mutex_t;
+
+typedef union
+{
+  char __size[4];
+  long int __align;
+} pthread_mutexattr_t;
+
+
+
+
+typedef union
+{
+  struct
+  {
+    int __lock;
+    unsigned int __futex;
+    __extension__ unsigned long long int __total_seq;
+    __extension__ unsigned long long int __wakeup_seq;
+    __extension__ unsigned long long int __woken_seq;
+    void *__mutex;
+    unsigned int __nwaiters;
+    unsigned int __broadcast_seq;
+  } __data;
+  char __size[48];
+  __extension__ long long int __align;
+} pthread_cond_t;
+
+typedef union
+{
+  char __size[4];
+  long int __align;
+} pthread_condattr_t;
+
+
+
+typedef unsigned int pthread_key_t;
+
+
+
+typedef int pthread_once_t;
+
+
+
+
+
+typedef union
+{
+  struct
+  {
+    int __lock;
+    unsigned int __nr_readers;
+    unsigned int __readers_wakeup;
+    unsigned int __writer_wakeup;
+    unsigned int __nr_readers_queued;
+    unsigned int __nr_writers_queued;
+
+
+    unsigned char __flags;
+    unsigned char __shared;
+    unsigned char __pad1;
+    unsigned char __pad2;
+    int __writer;
+  } __data;
+  char __size[32];
+  long int __align;
+} pthread_rwlock_t;
+
+typedef union
+{
+  char __size[8];
+  long int __align;
+} pthread_rwlockattr_t;
+
+
+
+
+
+typedef volatile int pthread_spinlock_t;
+
+
+
+
+typedef union
+{
+  char __size[20];
+  long int __align;
+} pthread_barrier_t;
+
+typedef union
+{
+  char __size[4];
+  int __align;
+} pthread_barrierattr_t;
+# 395 "/usr/include/signal.h" 2 3 4
+# 1 "/usr/include/bits/sigthread.h" 1 3 4
+# 31 "/usr/include/bits/sigthread.h" 3 4
+extern int pthread_sigmask (int __how,
+       __const __sigset_t *__restrict __newmask,
+       __sigset_t *__restrict __oldmask)__attribute__ ((__nothrow__));
+
+
+extern int pthread_kill (pthread_t __threadid, int __signo) __attribute__ ((__nothrow__));
+# 396 "/usr/include/signal.h" 2 3 4
+
+
+
+
+
+
+extern int __libc_current_sigrtmin (void) __attribute__ ((__nothrow__));
+
+extern int __libc_current_sigrtmax (void) __attribute__ ((__nothrow__));
+
+
+
+
+# 7 "rdtsc.h" 2
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stdint.h" 1 3 4
+
+
+# 1 "/usr/include/stdint.h" 1 3 4
+# 27 "/usr/include/stdint.h" 3 4
+# 1 "/usr/include/bits/wchar.h" 1 3 4
+# 28 "/usr/include/stdint.h" 2 3 4
+# 1 "/usr/include/bits/wordsize.h" 1 3 4
+# 29 "/usr/include/stdint.h" 2 3 4
+# 37 "/usr/include/stdint.h" 3 4
+typedef signed char int8_t;
+typedef short int int16_t;
+typedef int int32_t;
+
+
+
+__extension__
+typedef long long int int64_t;
+
+
+
+
+typedef unsigned char uint8_t;
+typedef unsigned short int uint16_t;
+
+typedef unsigned int uint32_t;
+
+
+
+
+
+__extension__
+typedef unsigned long long int uint64_t;
+
+
+
+
+
+
+typedef signed char int_least8_t;
+typedef short int int_least16_t;
+typedef int int_least32_t;
+
+
+
+__extension__
+typedef long long int int_least64_t;
+
+
+
+typedef unsigned char uint_least8_t;
+typedef unsigned short int uint_least16_t;
+typedef unsigned int uint_least32_t;
+
+
+
+__extension__
+typedef unsigned long long int uint_least64_t;
+
+
+
+
+
+
+typedef signed char int_fast8_t;
+
+
+
+
+
+typedef int int_fast16_t;
+typedef int int_fast32_t;
+__extension__
+typedef long long int int_fast64_t;
+
+
+
+typedef unsigned char uint_fast8_t;
+
+
+
+
+
+typedef unsigned int uint_fast16_t;
+typedef unsigned int uint_fast32_t;
+__extension__
+typedef unsigned long long int uint_fast64_t;
+# 126 "/usr/include/stdint.h" 3 4
+typedef int intptr_t;
+
+
+typedef unsigned int uintptr_t;
+# 138 "/usr/include/stdint.h" 3 4
+__extension__
+typedef long long int intmax_t;
+__extension__
+typedef unsigned long long int uintmax_t;
+# 4 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stdint.h" 2 3 4
+# 8 "rdtsc.h" 2
+
+# 1 "/usr/include/stdlib.h" 1 3 4
+# 33 "/usr/include/stdlib.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 323 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 3 4
+typedef long int wchar_t;
+# 34 "/usr/include/stdlib.h" 2 3 4
+
+
+
+
+
+
+
+
+# 1 "/usr/include/bits/waitflags.h" 1 3 4
+# 43 "/usr/include/stdlib.h" 2 3 4
+# 1 "/usr/include/bits/waitstatus.h" 1 3 4
+# 65 "/usr/include/bits/waitstatus.h" 3 4
+# 1 "/usr/include/endian.h" 1 3 4
+# 37 "/usr/include/endian.h" 3 4
+# 1 "/usr/include/bits/endian.h" 1 3 4
+# 38 "/usr/include/endian.h" 2 3 4
+# 61 "/usr/include/endian.h" 3 4
+# 1 "/usr/include/bits/byteswap.h" 1 3 4
+# 62 "/usr/include/endian.h" 2 3 4
+# 66 "/usr/include/bits/waitstatus.h" 2 3 4
+
+union wait
+  {
+    int w_status;
+    struct
+      {
+
+ unsigned int __w_termsig:7;
+ unsigned int __w_coredump:1;
+ unsigned int __w_retcode:8;
+ unsigned int:16;
+
+
+
+
+
+
+
+      } __wait_terminated;
+    struct
+      {
+
+ unsigned int __w_stopval:8;
+ unsigned int __w_stopsig:8;
+ unsigned int:16;
+
+
+
+
+
+
+      } __wait_stopped;
+  };
+# 44 "/usr/include/stdlib.h" 2 3 4
+# 68 "/usr/include/stdlib.h" 3 4
+typedef union
+  {
+    union wait *__uptr;
+    int *__iptr;
+  } __WAIT_STATUS __attribute__ ((__transparent_union__));
+# 96 "/usr/include/stdlib.h" 3 4
+
+
+typedef struct
+  {
+    int quot;
+    int rem;
+  } div_t;
+
+
+
+typedef struct
+  {
+    long int quot;
+    long int rem;
+  } ldiv_t;
+
+
+
+
+
+
+
+__extension__ typedef struct
+  {
+    long long int quot;
+    long long int rem;
+  } lldiv_t;
+
+
+# 140 "/usr/include/stdlib.h" 3 4
+extern size_t __ctype_get_mb_cur_max (void) __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern double atof (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
+
+extern int atoi (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
+
+extern long int atol (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+__extension__ extern long long int atoll (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+extern double strtod (__const char *__restrict __nptr,
+        char **__restrict __endptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+extern float strtof (__const char *__restrict __nptr,
+       char **__restrict __endptr) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+extern long double strtold (__const char *__restrict __nptr,
+       char **__restrict __endptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+extern long int strtol (__const char *__restrict __nptr,
+   char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+extern unsigned long int strtoul (__const char *__restrict __nptr,
+      char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+__extension__
+extern long long int strtoq (__const char *__restrict __nptr,
+        char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+__extension__
+extern unsigned long long int strtouq (__const char *__restrict __nptr,
+           char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+__extension__
+extern long long int strtoll (__const char *__restrict __nptr,
+         char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+__extension__
+extern unsigned long long int strtoull (__const char *__restrict __nptr,
+     char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+# 311 "/usr/include/stdlib.h" 3 4
+extern char *l64a (long int __n) __attribute__ ((__nothrow__)) ;
+
+
+extern long int a64l (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+# 1 "/usr/include/sys/types.h" 1 3 4
+# 28 "/usr/include/sys/types.h" 3 4
+
+
+
+
+
+
+typedef __u_char u_char;
+typedef __u_short u_short;
+typedef __u_int u_int;
+typedef __u_long u_long;
+typedef __quad_t quad_t;
+typedef __u_quad_t u_quad_t;
+typedef __fsid_t fsid_t;
+
+
+
+
+typedef __loff_t loff_t;
+
+
+
+typedef __ino_t ino_t;
+# 61 "/usr/include/sys/types.h" 3 4
+typedef __dev_t dev_t;
+
+
+
+
+typedef __gid_t gid_t;
+
+
+
+
+typedef __mode_t mode_t;
+
+
+
+
+typedef __nlink_t nlink_t;
+# 105 "/usr/include/sys/types.h" 3 4
+typedef __id_t id_t;
+# 116 "/usr/include/sys/types.h" 3 4
+typedef __daddr_t daddr_t;
+typedef __caddr_t caddr_t;
+
+
+
+
+
+typedef __key_t key_t;
+# 133 "/usr/include/sys/types.h" 3 4
+# 1 "/usr/include/time.h" 1 3 4
+# 58 "/usr/include/time.h" 3 4
+
+
+typedef __clock_t clock_t;
+
+
+
+# 92 "/usr/include/time.h" 3 4
+typedef __clockid_t clockid_t;
+# 104 "/usr/include/time.h" 3 4
+typedef __timer_t timer_t;
+# 134 "/usr/include/sys/types.h" 2 3 4
+# 147 "/usr/include/sys/types.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 148 "/usr/include/sys/types.h" 2 3 4
+
+
+
+typedef unsigned long int ulong;
+typedef unsigned short int ushort;
+typedef unsigned int uint;
+# 201 "/usr/include/sys/types.h" 3 4
+typedef unsigned int u_int8_t __attribute__ ((__mode__ (__QI__)));
+typedef unsigned int u_int16_t __attribute__ ((__mode__ (__HI__)));
+typedef unsigned int u_int32_t __attribute__ ((__mode__ (__SI__)));
+typedef unsigned int u_int64_t __attribute__ ((__mode__ (__DI__)));
+
+typedef int register_t __attribute__ ((__mode__ (__word__)));
+# 223 "/usr/include/sys/types.h" 3 4
+# 1 "/usr/include/sys/sysmacros.h" 1 3 4
+# 30 "/usr/include/sys/sysmacros.h" 3 4
+__extension__
+extern unsigned int gnu_dev_major (unsigned long long int __dev)
+     __attribute__ ((__nothrow__));
+__extension__
+extern unsigned int gnu_dev_minor (unsigned long long int __dev)
+     __attribute__ ((__nothrow__));
+__extension__
+extern unsigned long long int gnu_dev_makedev (unsigned int __major,
+            unsigned int __minor)
+     __attribute__ ((__nothrow__));
+# 224 "/usr/include/sys/types.h" 2 3 4
+
+
+
+
+
+typedef __blksize_t blksize_t;
+
+
+
+
+
+
+typedef __blkcnt_t blkcnt_t;
+
+
+
+typedef __fsblkcnt_t fsblkcnt_t;
+
+
+
+typedef __fsfilcnt_t fsfilcnt_t;
+# 274 "/usr/include/sys/types.h" 3 4
+
+# 321 "/usr/include/stdlib.h" 2 3 4
+
+
+
+
+
+
+extern long int random (void) __attribute__ ((__nothrow__));
+
+
+extern void srandom (unsigned int __seed) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern char *initstate (unsigned int __seed, char *__statebuf,
+   size_t __statelen) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+
+extern char *setstate (char *__statebuf) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+
+struct random_data
+  {
+    int32_t *fptr;
+    int32_t *rptr;
+    int32_t *state;
+    int rand_type;
+    int rand_deg;
+    int rand_sep;
+    int32_t *end_ptr;
+  };
+
+extern int random_r (struct random_data *__restrict __buf,
+       int32_t *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern int srandom_r (unsigned int __seed, struct random_data *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+extern int initstate_r (unsigned int __seed, char *__restrict __statebuf,
+   size_t __statelen,
+   struct random_data *__restrict __buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 4)));
+
+extern int setstate_r (char *__restrict __statebuf,
+         struct random_data *__restrict __buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+
+
+extern int rand (void) __attribute__ ((__nothrow__));
+
+extern void srand (unsigned int __seed) __attribute__ ((__nothrow__));
+
+
+
+
+extern int rand_r (unsigned int *__seed) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+extern double drand48 (void) __attribute__ ((__nothrow__));
+extern double erand48 (unsigned short int __xsubi[3]) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern long int lrand48 (void) __attribute__ ((__nothrow__));
+extern long int nrand48 (unsigned short int __xsubi[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern long int mrand48 (void) __attribute__ ((__nothrow__));
+extern long int jrand48 (unsigned short int __xsubi[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern void srand48 (long int __seedval) __attribute__ ((__nothrow__));
+extern unsigned short int *seed48 (unsigned short int __seed16v[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void lcong48 (unsigned short int __param[7]) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+struct drand48_data
+  {
+    unsigned short int __x[3];
+    unsigned short int __old_x[3];
+    unsigned short int __c;
+    unsigned short int __init;
+    unsigned long long int __a;
+  };
+
+
+extern int drand48_r (struct drand48_data *__restrict __buffer,
+        double *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int erand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        double *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int lrand48_r (struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int nrand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int mrand48_r (struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int jrand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+extern int srand48_r (long int __seedval, struct drand48_data *__buffer)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+extern int seed48_r (unsigned short int __seed16v[3],
+       struct drand48_data *__buffer) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+extern int lcong48_r (unsigned short int __param[7],
+        struct drand48_data *__buffer)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+
+
+
+
+
+extern void *malloc (size_t __size) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) ;
+
+extern void *calloc (size_t __nmemb, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) ;
+
+
+
+
+
+
+
+
+
+
+extern void *realloc (void *__ptr, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+
+extern void free (void *__ptr) __attribute__ ((__nothrow__));
+
+
+
+
+extern void cfree (void *__ptr) __attribute__ ((__nothrow__));
+
+
+
+# 1 "/usr/include/alloca.h" 1 3 4
+# 25 "/usr/include/alloca.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 26 "/usr/include/alloca.h" 2 3 4
+
+
+
+
+
+
+
+extern void *alloca (size_t __size) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+# 498 "/usr/include/stdlib.h" 2 3 4
+
+
+
+
+
+extern void *valloc (size_t __size) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) ;
+
+
+
+
+extern int posix_memalign (void **__memptr, size_t __alignment, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+extern void abort (void) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+
+
+
+extern int atexit (void (*__func) (void)) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+# 531 "/usr/include/stdlib.h" 3 4
+
+
+
+
+
+extern int on_exit (void (*__func) (int __status, void *__arg), void *__arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern void exit (int __status) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+# 554 "/usr/include/stdlib.h" 3 4
+
+
+
+
+
+
+extern void _Exit (int __status) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+
+
+
+
+
+
+extern char *getenv (__const char *__name) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+extern char *__secure_getenv (__const char *__name)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+extern int putenv (char *__string) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+extern int setenv (__const char *__name, __const char *__value, int __replace)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+extern int unsetenv (__const char *__name) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern int clearenv (void) __attribute__ ((__nothrow__));
+# 606 "/usr/include/stdlib.h" 3 4
+extern char *mktemp (char *__template) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+# 620 "/usr/include/stdlib.h" 3 4
+extern int mkstemp (char *__template) __attribute__ ((__nonnull__ (1))) ;
+# 642 "/usr/include/stdlib.h" 3 4
+extern int mkstemps (char *__template, int __suffixlen) __attribute__ ((__nonnull__ (1))) ;
+# 663 "/usr/include/stdlib.h" 3 4
+extern char *mkdtemp (char *__template) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+# 712 "/usr/include/stdlib.h" 3 4
+
+
+
+
+
+extern int system (__const char *__command) ;
+
+# 734 "/usr/include/stdlib.h" 3 4
+extern char *realpath (__const char *__restrict __name,
+         char *__restrict __resolved) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+
+typedef int (*__compar_fn_t) (__const void *, __const void *);
+# 752 "/usr/include/stdlib.h" 3 4
+
+
+
+extern void *bsearch (__const void *__key, __const void *__base,
+        size_t __nmemb, size_t __size, __compar_fn_t __compar)
+     __attribute__ ((__nonnull__ (1, 2, 5))) ;
+
+
+
+extern void qsort (void *__base, size_t __nmemb, size_t __size,
+     __compar_fn_t __compar) __attribute__ ((__nonnull__ (1, 4)));
+# 771 "/usr/include/stdlib.h" 3 4
+extern int abs (int __x) __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+extern long int labs (long int __x) __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+
+
+
+__extension__ extern long long int llabs (long long int __x)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+
+
+
+
+
+
+
+extern div_t div (int __numer, int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+extern ldiv_t ldiv (long int __numer, long int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+
+
+
+
+__extension__ extern lldiv_t lldiv (long long int __numer,
+        long long int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) ;
+
+# 808 "/usr/include/stdlib.h" 3 4
+extern char *ecvt (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) ;
+
+
+
+
+extern char *fcvt (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) ;
+
+
+
+
+extern char *gcvt (double __value, int __ndigit, char *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3))) ;
+
+
+
+
+extern char *qecvt (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) ;
+extern char *qfcvt (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) ;
+extern char *qgcvt (long double __value, int __ndigit, char *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3))) ;
+
+
+
+
+extern int ecvt_r (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign, char *__restrict __buf,
+     size_t __len) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int fcvt_r (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign, char *__restrict __buf,
+     size_t __len) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+
+extern int qecvt_r (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign,
+      char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int qfcvt_r (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign,
+      char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+
+
+
+
+
+
+
+extern int mblen (__const char *__s, size_t __n) __attribute__ ((__nothrow__)) ;
+
+
+extern int mbtowc (wchar_t *__restrict __pwc,
+     __const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__)) ;
+
+
+extern int wctomb (char *__s, wchar_t __wchar) __attribute__ ((__nothrow__)) ;
+
+
+
+extern size_t mbstowcs (wchar_t *__restrict __pwcs,
+   __const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__));
+
+extern size_t wcstombs (char *__restrict __s,
+   __const wchar_t *__restrict __pwcs, size_t __n)
+     __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+
+extern int rpmatch (__const char *__response) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+# 896 "/usr/include/stdlib.h" 3 4
+extern int getsubopt (char **__restrict __optionp,
+        char *__const *__restrict __tokens,
+        char **__restrict __valuep)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2, 3))) ;
+# 948 "/usr/include/stdlib.h" 3 4
+extern int getloadavg (double __loadavg[], int __nelem)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+# 964 "/usr/include/stdlib.h" 3 4
+
+# 10 "rdtsc.h" 2
+
+# 1 "/usr/include/unistd.h" 1 3 4
+# 28 "/usr/include/unistd.h" 3 4
+
+# 203 "/usr/include/unistd.h" 3 4
+# 1 "/usr/include/bits/posix_opt.h" 1 3 4
+# 204 "/usr/include/unistd.h" 2 3 4
+
+
+
+# 1 "/usr/include/bits/environments.h" 1 3 4
+# 208 "/usr/include/unistd.h" 2 3 4
+# 227 "/usr/include/unistd.h" 3 4
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 228 "/usr/include/unistd.h" 2 3 4
+# 256 "/usr/include/unistd.h" 3 4
+typedef __useconds_t useconds_t;
+# 275 "/usr/include/unistd.h" 3 4
+typedef __socklen_t socklen_t;
+# 288 "/usr/include/unistd.h" 3 4
+extern int access (__const char *__name, int __type) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+# 305 "/usr/include/unistd.h" 3 4
+extern int faccessat (int __fd, __const char *__file, int __type, int __flag)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2))) ;
+# 331 "/usr/include/unistd.h" 3 4
+extern __off_t lseek (int __fd, __off_t __offset, int __whence) __attribute__ ((__nothrow__));
+# 350 "/usr/include/unistd.h" 3 4
+extern int close (int __fd);
+
+
+
+
+
+
+extern ssize_t read (int __fd, void *__buf, size_t __nbytes) ;
+
+
+
+
+
+extern ssize_t write (int __fd, __const void *__buf, size_t __n) ;
+# 373 "/usr/include/unistd.h" 3 4
+extern ssize_t pread (int __fd, void *__buf, size_t __nbytes,
+        __off_t __offset) ;
+
+
+
+
+
+
+extern ssize_t pwrite (int __fd, __const void *__buf, size_t __n,
+         __off_t __offset) ;
+# 414 "/usr/include/unistd.h" 3 4
+extern int pipe (int __pipedes[2]) __attribute__ ((__nothrow__)) ;
+# 429 "/usr/include/unistd.h" 3 4
+extern unsigned int alarm (unsigned int __seconds) __attribute__ ((__nothrow__));
+# 441 "/usr/include/unistd.h" 3 4
+extern unsigned int sleep (unsigned int __seconds);
+
+
+
+
+
+
+
+extern __useconds_t ualarm (__useconds_t __value, __useconds_t __interval)
+     __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int usleep (__useconds_t __useconds);
+# 466 "/usr/include/unistd.h" 3 4
+extern int pause (void);
+
+
+
+extern int chown (__const char *__file, __uid_t __owner, __gid_t __group)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+extern int fchown (int __fd, __uid_t __owner, __gid_t __group) __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern int lchown (__const char *__file, __uid_t __owner, __gid_t __group)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+
+extern int fchownat (int __fd, __const char *__file, __uid_t __owner,
+       __gid_t __group, int __flag)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2))) ;
+
+
+
+extern int chdir (__const char *__path) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+extern int fchdir (int __fd) __attribute__ ((__nothrow__)) ;
+# 508 "/usr/include/unistd.h" 3 4
+extern char *getcwd (char *__buf, size_t __size) __attribute__ ((__nothrow__)) ;
+# 522 "/usr/include/unistd.h" 3 4
+extern char *getwd (char *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__deprecated__)) ;
+
+
+
+
+extern int dup (int __fd) __attribute__ ((__nothrow__)) ;
+
+
+extern int dup2 (int __fd, int __fd2) __attribute__ ((__nothrow__));
+# 540 "/usr/include/unistd.h" 3 4
+extern char **__environ;
+
+
+
+
+
+
+
+extern int execve (__const char *__path, char *__const __argv[],
+     char *__const __envp[]) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+extern int fexecve (int __fd, char *__const __argv[], char *__const __envp[])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+
+
+extern int execv (__const char *__path, char *__const __argv[])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+extern int execle (__const char *__path, __const char *__arg, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+extern int execl (__const char *__path, __const char *__arg, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+extern int execvp (__const char *__file, char *__const __argv[])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+
+
+
+
+extern int execlp (__const char *__file, __const char *__arg, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+# 595 "/usr/include/unistd.h" 3 4
+extern int nice (int __inc) __attribute__ ((__nothrow__)) ;
+
+
+
+
+extern void _exit (int __status) __attribute__ ((__noreturn__));
+
+
+
+
+
+# 1 "/usr/include/bits/confname.h" 1 3 4
+# 26 "/usr/include/bits/confname.h" 3 4
+enum
+  {
+    _PC_LINK_MAX,
+
+    _PC_MAX_CANON,
+
+    _PC_MAX_INPUT,
+
+    _PC_NAME_MAX,
+
+    _PC_PATH_MAX,
+
+    _PC_PIPE_BUF,
+
+    _PC_CHOWN_RESTRICTED,
+
+    _PC_NO_TRUNC,
+
+    _PC_VDISABLE,
+
+    _PC_SYNC_IO,
+
+    _PC_ASYNC_IO,
+
+    _PC_PRIO_IO,
+
+    _PC_SOCK_MAXBUF,
+
+    _PC_FILESIZEBITS,
+
+    _PC_REC_INCR_XFER_SIZE,
+
+    _PC_REC_MAX_XFER_SIZE,
+
+    _PC_REC_MIN_XFER_SIZE,
+
+    _PC_REC_XFER_ALIGN,
+
+    _PC_ALLOC_SIZE_MIN,
+
+    _PC_SYMLINK_MAX,
+
+    _PC_2_SYMLINKS
+
+  };
+
+
+enum
+  {
+    _SC_ARG_MAX,
+
+    _SC_CHILD_MAX,
+
+    _SC_CLK_TCK,
+
+    _SC_NGROUPS_MAX,
+
+    _SC_OPEN_MAX,
+
+    _SC_STREAM_MAX,
+
+    _SC_TZNAME_MAX,
+
+    _SC_JOB_CONTROL,
+
+    _SC_SAVED_IDS,
+
+    _SC_REALTIME_SIGNALS,
+
+    _SC_PRIORITY_SCHEDULING,
+
+    _SC_TIMERS,
+
+    _SC_ASYNCHRONOUS_IO,
+
+    _SC_PRIORITIZED_IO,
+
+    _SC_SYNCHRONIZED_IO,
+
+    _SC_FSYNC,
+
+    _SC_MAPPED_FILES,
+
+    _SC_MEMLOCK,
+
+    _SC_MEMLOCK_RANGE,
+
+    _SC_MEMORY_PROTECTION,
+
+    _SC_MESSAGE_PASSING,
+
+    _SC_SEMAPHORES,
+
+    _SC_SHARED_MEMORY_OBJECTS,
+
+    _SC_AIO_LISTIO_MAX,
+
+    _SC_AIO_MAX,
+
+    _SC_AIO_PRIO_DELTA_MAX,
+
+    _SC_DELAYTIMER_MAX,
+
+    _SC_MQ_OPEN_MAX,
+
+    _SC_MQ_PRIO_MAX,
+
+    _SC_VERSION,
+
+    _SC_PAGESIZE,
+
+
+    _SC_RTSIG_MAX,
+
+    _SC_SEM_NSEMS_MAX,
+
+    _SC_SEM_VALUE_MAX,
+
+    _SC_SIGQUEUE_MAX,
+
+    _SC_TIMER_MAX,
+
+
+
+
+    _SC_BC_BASE_MAX,
+
+    _SC_BC_DIM_MAX,
+
+    _SC_BC_SCALE_MAX,
+
+    _SC_BC_STRING_MAX,
+
+    _SC_COLL_WEIGHTS_MAX,
+
+    _SC_EQUIV_CLASS_MAX,
+
+    _SC_EXPR_NEST_MAX,
+
+    _SC_LINE_MAX,
+
+    _SC_RE_DUP_MAX,
+
+    _SC_CHARCLASS_NAME_MAX,
+
+
+    _SC_2_VERSION,
+
+    _SC_2_C_BIND,
+
+    _SC_2_C_DEV,
+
+    _SC_2_FORT_DEV,
+
+    _SC_2_FORT_RUN,
+
+    _SC_2_SW_DEV,
+
+    _SC_2_LOCALEDEF,
+
+
+    _SC_PII,
+
+    _SC_PII_XTI,
+
+    _SC_PII_SOCKET,
+
+    _SC_PII_INTERNET,
+
+    _SC_PII_OSI,
+
+    _SC_POLL,
+
+    _SC_SELECT,
+
+    _SC_UIO_MAXIOV,
+
+    _SC_IOV_MAX = _SC_UIO_MAXIOV,
+
+    _SC_PII_INTERNET_STREAM,
+
+    _SC_PII_INTERNET_DGRAM,
+
+    _SC_PII_OSI_COTS,
+
+    _SC_PII_OSI_CLTS,
+
+    _SC_PII_OSI_M,
+
+    _SC_T_IOV_MAX,
+
+
+
+    _SC_THREADS,
+
+    _SC_THREAD_SAFE_FUNCTIONS,
+
+    _SC_GETGR_R_SIZE_MAX,
+
+    _SC_GETPW_R_SIZE_MAX,
+
+    _SC_LOGIN_NAME_MAX,
+
+    _SC_TTY_NAME_MAX,
+
+    _SC_THREAD_DESTRUCTOR_ITERATIONS,
+
+    _SC_THREAD_KEYS_MAX,
+
+    _SC_THREAD_STACK_MIN,
+
+    _SC_THREAD_THREADS_MAX,
+
+    _SC_THREAD_ATTR_STACKADDR,
+
+    _SC_THREAD_ATTR_STACKSIZE,
+
+    _SC_THREAD_PRIORITY_SCHEDULING,
+
+    _SC_THREAD_PRIO_INHERIT,
+
+    _SC_THREAD_PRIO_PROTECT,
+
+    _SC_THREAD_PROCESS_SHARED,
+
+
+    _SC_NPROCESSORS_CONF,
+
+    _SC_NPROCESSORS_ONLN,
+
+    _SC_PHYS_PAGES,
+
+    _SC_AVPHYS_PAGES,
+
+    _SC_ATEXIT_MAX,
+
+    _SC_PASS_MAX,
+
+
+    _SC_XOPEN_VERSION,
+
+    _SC_XOPEN_XCU_VERSION,
+
+    _SC_XOPEN_UNIX,
+
+    _SC_XOPEN_CRYPT,
+
+    _SC_XOPEN_ENH_I18N,
+
+    _SC_XOPEN_SHM,
+
+
+    _SC_2_CHAR_TERM,
+
+    _SC_2_C_VERSION,
+
+    _SC_2_UPE,
+
+
+    _SC_XOPEN_XPG2,
+
+    _SC_XOPEN_XPG3,
+
+    _SC_XOPEN_XPG4,
+
+
+    _SC_CHAR_BIT,
+
+    _SC_CHAR_MAX,
+
+    _SC_CHAR_MIN,
+
+    _SC_INT_MAX,
+
+    _SC_INT_MIN,
+
+    _SC_LONG_BIT,
+
+    _SC_WORD_BIT,
+
+    _SC_MB_LEN_MAX,
+
+    _SC_NZERO,
+
+    _SC_SSIZE_MAX,
+
+    _SC_SCHAR_MAX,
+
+    _SC_SCHAR_MIN,
+
+    _SC_SHRT_MAX,
+
+    _SC_SHRT_MIN,
+
+    _SC_UCHAR_MAX,
+
+    _SC_UINT_MAX,
+
+    _SC_ULONG_MAX,
+
+    _SC_USHRT_MAX,
+
+
+    _SC_NL_ARGMAX,
+
+    _SC_NL_LANGMAX,
+
+    _SC_NL_MSGMAX,
+
+    _SC_NL_NMAX,
+
+    _SC_NL_SETMAX,
+
+    _SC_NL_TEXTMAX,
+
+
+    _SC_XBS5_ILP32_OFF32,
+
+    _SC_XBS5_ILP32_OFFBIG,
+
+    _SC_XBS5_LP64_OFF64,
+
+    _SC_XBS5_LPBIG_OFFBIG,
+
+
+    _SC_XOPEN_LEGACY,
+
+    _SC_XOPEN_REALTIME,
+
+    _SC_XOPEN_REALTIME_THREADS,
+
+
+    _SC_ADVISORY_INFO,
+
+    _SC_BARRIERS,
+
+    _SC_BASE,
+
+    _SC_C_LANG_SUPPORT,
+
+    _SC_C_LANG_SUPPORT_R,
+
+    _SC_CLOCK_SELECTION,
+
+    _SC_CPUTIME,
+
+    _SC_THREAD_CPUTIME,
+
+    _SC_DEVICE_IO,
+
+    _SC_DEVICE_SPECIFIC,
+
+    _SC_DEVICE_SPECIFIC_R,
+
+    _SC_FD_MGMT,
+
+    _SC_FIFO,
+
+    _SC_PIPE,
+
+    _SC_FILE_ATTRIBUTES,
+
+    _SC_FILE_LOCKING,
+
+    _SC_FILE_SYSTEM,
+
+    _SC_MONOTONIC_CLOCK,
+
+    _SC_MULTI_PROCESS,
+
+    _SC_SINGLE_PROCESS,
+
+    _SC_NETWORKING,
+
+    _SC_READER_WRITER_LOCKS,
+
+    _SC_SPIN_LOCKS,
+
+    _SC_REGEXP,
+
+    _SC_REGEX_VERSION,
+
+    _SC_SHELL,
+
+    _SC_SIGNALS,
+
+    _SC_SPAWN,
+
+    _SC_SPORADIC_SERVER,
+
+    _SC_THREAD_SPORADIC_SERVER,
+
+    _SC_SYSTEM_DATABASE,
+
+    _SC_SYSTEM_DATABASE_R,
+
+    _SC_TIMEOUTS,
+
+    _SC_TYPED_MEMORY_OBJECTS,
+
+    _SC_USER_GROUPS,
+
+    _SC_USER_GROUPS_R,
+
+    _SC_2_PBS,
+
+    _SC_2_PBS_ACCOUNTING,
+
+    _SC_2_PBS_LOCATE,
+
+    _SC_2_PBS_MESSAGE,
+
+    _SC_2_PBS_TRACK,
+
+    _SC_SYMLOOP_MAX,
+
+    _SC_STREAMS,
+
+    _SC_2_PBS_CHECKPOINT,
+
+
+    _SC_V6_ILP32_OFF32,
+
+    _SC_V6_ILP32_OFFBIG,
+
+    _SC_V6_LP64_OFF64,
+
+    _SC_V6_LPBIG_OFFBIG,
+
+
+    _SC_HOST_NAME_MAX,
+
+    _SC_TRACE,
+
+    _SC_TRACE_EVENT_FILTER,
+
+    _SC_TRACE_INHERIT,
+
+    _SC_TRACE_LOG,
+
+
+    _SC_LEVEL1_ICACHE_SIZE,
+
+    _SC_LEVEL1_ICACHE_ASSOC,
+
+    _SC_LEVEL1_ICACHE_LINESIZE,
+
+    _SC_LEVEL1_DCACHE_SIZE,
+
+    _SC_LEVEL1_DCACHE_ASSOC,
+
+    _SC_LEVEL1_DCACHE_LINESIZE,
+
+    _SC_LEVEL2_CACHE_SIZE,
+
+    _SC_LEVEL2_CACHE_ASSOC,
+
+    _SC_LEVEL2_CACHE_LINESIZE,
+
+    _SC_LEVEL3_CACHE_SIZE,
+
+    _SC_LEVEL3_CACHE_ASSOC,
+
+    _SC_LEVEL3_CACHE_LINESIZE,
+
+    _SC_LEVEL4_CACHE_SIZE,
+
+    _SC_LEVEL4_CACHE_ASSOC,
+
+    _SC_LEVEL4_CACHE_LINESIZE,
+
+
+
+    _SC_IPV6 = _SC_LEVEL1_ICACHE_SIZE + 50,
+
+    _SC_RAW_SOCKETS,
+
+
+    _SC_V7_ILP32_OFF32,
+
+    _SC_V7_ILP32_OFFBIG,
+
+    _SC_V7_LP64_OFF64,
+
+    _SC_V7_LPBIG_OFFBIG,
+
+
+    _SC_SS_REPL_MAX,
+
+
+    _SC_TRACE_EVENT_NAME_MAX,
+
+    _SC_TRACE_NAME_MAX,
+
+    _SC_TRACE_SYS_MAX,
+
+    _SC_TRACE_USER_EVENT_MAX,
+
+
+    _SC_XOPEN_STREAMS,
+
+
+    _SC_THREAD_ROBUST_PRIO_INHERIT,
+
+    _SC_THREAD_ROBUST_PRIO_PROTECT
+
+  };
+
+
+enum
+  {
+    _CS_PATH,
+
+
+    _CS_V6_WIDTH_RESTRICTED_ENVS,
+
+
+
+    _CS_GNU_LIBC_VERSION,
+
+    _CS_GNU_LIBPTHREAD_VERSION,
+
+
+    _CS_V5_WIDTH_RESTRICTED_ENVS,
+
+
+
+    _CS_V7_WIDTH_RESTRICTED_ENVS,
+
+
+
+    _CS_LFS_CFLAGS = 1000,
+
+    _CS_LFS_LDFLAGS,
+
+    _CS_LFS_LIBS,
+
+    _CS_LFS_LINTFLAGS,
+
+    _CS_LFS64_CFLAGS,
+
+    _CS_LFS64_LDFLAGS,
+
+    _CS_LFS64_LIBS,
+
+    _CS_LFS64_LINTFLAGS,
+
+
+    _CS_XBS5_ILP32_OFF32_CFLAGS = 1100,
+
+    _CS_XBS5_ILP32_OFF32_LDFLAGS,
+
+    _CS_XBS5_ILP32_OFF32_LIBS,
+
+    _CS_XBS5_ILP32_OFF32_LINTFLAGS,
+
+    _CS_XBS5_ILP32_OFFBIG_CFLAGS,
+
+    _CS_XBS5_ILP32_OFFBIG_LDFLAGS,
+
+    _CS_XBS5_ILP32_OFFBIG_LIBS,
+
+    _CS_XBS5_ILP32_OFFBIG_LINTFLAGS,
+
+    _CS_XBS5_LP64_OFF64_CFLAGS,
+
+    _CS_XBS5_LP64_OFF64_LDFLAGS,
+
+    _CS_XBS5_LP64_OFF64_LIBS,
+
+    _CS_XBS5_LP64_OFF64_LINTFLAGS,
+
+    _CS_XBS5_LPBIG_OFFBIG_CFLAGS,
+
+    _CS_XBS5_LPBIG_OFFBIG_LDFLAGS,
+
+    _CS_XBS5_LPBIG_OFFBIG_LIBS,
+
+    _CS_XBS5_LPBIG_OFFBIG_LINTFLAGS,
+
+
+    _CS_POSIX_V6_ILP32_OFF32_CFLAGS,
+
+    _CS_POSIX_V6_ILP32_OFF32_LDFLAGS,
+
+    _CS_POSIX_V6_ILP32_OFF32_LIBS,
+
+    _CS_POSIX_V6_ILP32_OFF32_LINTFLAGS,
+
+    _CS_POSIX_V6_ILP32_OFFBIG_CFLAGS,
+
+    _CS_POSIX_V6_ILP32_OFFBIG_LDFLAGS,
+
+    _CS_POSIX_V6_ILP32_OFFBIG_LIBS,
+
+    _CS_POSIX_V6_ILP32_OFFBIG_LINTFLAGS,
+
+    _CS_POSIX_V6_LP64_OFF64_CFLAGS,
+
+    _CS_POSIX_V6_LP64_OFF64_LDFLAGS,
+
+    _CS_POSIX_V6_LP64_OFF64_LIBS,
+
+    _CS_POSIX_V6_LP64_OFF64_LINTFLAGS,
+
+    _CS_POSIX_V6_LPBIG_OFFBIG_CFLAGS,
+
+    _CS_POSIX_V6_LPBIG_OFFBIG_LDFLAGS,
+
+    _CS_POSIX_V6_LPBIG_OFFBIG_LIBS,
+
+    _CS_POSIX_V6_LPBIG_OFFBIG_LINTFLAGS,
+
+
+    _CS_POSIX_V7_ILP32_OFF32_CFLAGS,
+
+    _CS_POSIX_V7_ILP32_OFF32_LDFLAGS,
+
+    _CS_POSIX_V7_ILP32_OFF32_LIBS,
+
+    _CS_POSIX_V7_ILP32_OFF32_LINTFLAGS,
+
+    _CS_POSIX_V7_ILP32_OFFBIG_CFLAGS,
+
+    _CS_POSIX_V7_ILP32_OFFBIG_LDFLAGS,
+
+    _CS_POSIX_V7_ILP32_OFFBIG_LIBS,
+
+    _CS_POSIX_V7_ILP32_OFFBIG_LINTFLAGS,
+
+    _CS_POSIX_V7_LP64_OFF64_CFLAGS,
+
+    _CS_POSIX_V7_LP64_OFF64_LDFLAGS,
+
+    _CS_POSIX_V7_LP64_OFF64_LIBS,
+
+    _CS_POSIX_V7_LP64_OFF64_LINTFLAGS,
+
+    _CS_POSIX_V7_LPBIG_OFFBIG_CFLAGS,
+
+    _CS_POSIX_V7_LPBIG_OFFBIG_LDFLAGS,
+
+    _CS_POSIX_V7_LPBIG_OFFBIG_LIBS,
+
+    _CS_POSIX_V7_LPBIG_OFFBIG_LINTFLAGS,
+
+
+    _CS_V6_ENV,
+
+    _CS_V7_ENV
+
+  };
+# 607 "/usr/include/unistd.h" 2 3 4
+
+
+extern long int pathconf (__const char *__path, int __name)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+extern long int fpathconf (int __fd, int __name) __attribute__ ((__nothrow__));
+
+
+extern long int sysconf (int __name) __attribute__ ((__nothrow__));
+
+
+
+extern size_t confstr (int __name, char *__buf, size_t __len) __attribute__ ((__nothrow__));
+
+
+
+
+extern __pid_t getpid (void) __attribute__ ((__nothrow__));
+
+
+extern __pid_t getppid (void) __attribute__ ((__nothrow__));
+
+
+
+
+extern __pid_t getpgrp (void) __attribute__ ((__nothrow__));
+# 643 "/usr/include/unistd.h" 3 4
+extern __pid_t __getpgid (__pid_t __pid) __attribute__ ((__nothrow__));
+
+extern __pid_t getpgid (__pid_t __pid) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int setpgid (__pid_t __pid, __pid_t __pgid) __attribute__ ((__nothrow__));
+# 669 "/usr/include/unistd.h" 3 4
+extern int setpgrp (void) __attribute__ ((__nothrow__));
+# 686 "/usr/include/unistd.h" 3 4
+extern __pid_t setsid (void) __attribute__ ((__nothrow__));
+
+
+
+extern __pid_t getsid (__pid_t __pid) __attribute__ ((__nothrow__));
+
+
+
+extern __uid_t getuid (void) __attribute__ ((__nothrow__));
+
+
+extern __uid_t geteuid (void) __attribute__ ((__nothrow__));
+
+
+extern __gid_t getgid (void) __attribute__ ((__nothrow__));
+
+
+extern __gid_t getegid (void) __attribute__ ((__nothrow__));
+
+
+
+
+extern int getgroups (int __size, __gid_t __list[]) __attribute__ ((__nothrow__)) ;
+# 719 "/usr/include/unistd.h" 3 4
+extern int setuid (__uid_t __uid) __attribute__ ((__nothrow__));
+
+
+
+
+extern int setreuid (__uid_t __ruid, __uid_t __euid) __attribute__ ((__nothrow__));
+
+
+
+
+extern int seteuid (__uid_t __uid) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int setgid (__gid_t __gid) __attribute__ ((__nothrow__));
+
+
+
+
+extern int setregid (__gid_t __rgid, __gid_t __egid) __attribute__ ((__nothrow__));
+
+
+
+
+extern int setegid (__gid_t __gid) __attribute__ ((__nothrow__));
+# 775 "/usr/include/unistd.h" 3 4
+extern __pid_t fork (void) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+extern __pid_t vfork (void) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern char *ttyname (int __fd) __attribute__ ((__nothrow__));
+
+
+
+extern int ttyname_r (int __fd, char *__buf, size_t __buflen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2))) ;
+
+
+
+extern int isatty (int __fd) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern int ttyslot (void) __attribute__ ((__nothrow__));
+
+
+
+
+extern int link (__const char *__from, __const char *__to)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2))) ;
+
+
+
+
+extern int linkat (int __fromfd, __const char *__from, int __tofd,
+     __const char *__to, int __flags)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 4))) ;
+
+
+
+
+extern int symlink (__const char *__from, __const char *__to)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2))) ;
+
+
+
+
+extern ssize_t readlink (__const char *__restrict __path,
+    char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2))) ;
+
+
+
+
+extern int symlinkat (__const char *__from, int __tofd,
+        __const char *__to) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3))) ;
+
+
+extern ssize_t readlinkat (int __fd, __const char *__restrict __path,
+      char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3))) ;
+
+
+
+extern int unlink (__const char *__name) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+extern int unlinkat (int __fd, __const char *__name, int __flag)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+
+
+
+extern int rmdir (__const char *__path) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+extern __pid_t tcgetpgrp (int __fd) __attribute__ ((__nothrow__));
+
+
+extern int tcsetpgrp (int __fd, __pid_t __pgrp_id) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern char *getlogin (void);
+
+
+
+
+
+
+
+extern int getlogin_r (char *__name, size_t __name_len) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+extern int setlogin (__const char *__name) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+# 890 "/usr/include/unistd.h" 3 4
+# 1 "/usr/include/getopt.h" 1 3 4
+# 59 "/usr/include/getopt.h" 3 4
+extern char *optarg;
+# 73 "/usr/include/getopt.h" 3 4
+extern int optind;
+
+
+
+
+extern int opterr;
+
+
+
+extern int optopt;
+# 152 "/usr/include/getopt.h" 3 4
+extern int getopt (int ___argc, char *const *___argv, const char *__shortopts)
+       __attribute__ ((__nothrow__));
+# 891 "/usr/include/unistd.h" 2 3 4
+
+
+
+
+
+
+
+extern int gethostname (char *__name, size_t __len) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+
+extern int sethostname (__const char *__name, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+extern int sethostid (long int __id) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+extern int getdomainname (char *__name, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+extern int setdomainname (__const char *__name, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+extern int vhangup (void) __attribute__ ((__nothrow__));
+
+
+extern int revoke (__const char *__file) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+
+
+
+
+extern int profil (unsigned short int *__sample_buffer, size_t __size,
+     size_t __offset, unsigned int __scale)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+
+
+
+
+
+extern int acct (__const char *__name) __attribute__ ((__nothrow__));
+
+
+
+extern char *getusershell (void) __attribute__ ((__nothrow__));
+extern void endusershell (void) __attribute__ ((__nothrow__));
+extern void setusershell (void) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern int daemon (int __nochdir, int __noclose) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+
+extern int chroot (__const char *__path) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+
+
+
+extern char *getpass (__const char *__prompt) __attribute__ ((__nonnull__ (1)));
+# 976 "/usr/include/unistd.h" 3 4
+extern int fsync (int __fd);
+
+
+
+
+
+
+extern long int gethostid (void);
+
+
+extern void sync (void) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern int getpagesize (void) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+
+
+
+
+extern int getdtablesize (void) __attribute__ ((__nothrow__));
+# 1007 "/usr/include/unistd.h" 3 4
+extern int truncate (__const char *__file, __off_t __length)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) ;
+# 1029 "/usr/include/unistd.h" 3 4
+extern int ftruncate (int __fd, __off_t __length) __attribute__ ((__nothrow__)) ;
+# 1050 "/usr/include/unistd.h" 3 4
+extern int brk (void *__addr) __attribute__ ((__nothrow__)) ;
+
+
+
+
+
+extern void *sbrk (intptr_t __delta) __attribute__ ((__nothrow__));
+# 1071 "/usr/include/unistd.h" 3 4
+extern long int syscall (long int __sysno, ...) __attribute__ ((__nothrow__));
+# 1094 "/usr/include/unistd.h" 3 4
+extern int lockf (int __fd, int __cmd, __off_t __len) ;
+# 1125 "/usr/include/unistd.h" 3 4
+extern int fdatasync (int __fildes);
+# 1154 "/usr/include/unistd.h" 3 4
+extern char *ctermid (char *__s) __attribute__ ((__nothrow__));
+# 1163 "/usr/include/unistd.h" 3 4
+
+# 12 "rdtsc.h" 2
+# 1 "/usr/include/time.h" 1 3 4
+# 30 "/usr/include/time.h" 3 4
+
+
+
+
+
+
+
+
+# 1 "/usr/lib/gcc/i486-slackware-linux/4.5.2/include/stddef.h" 1 3 4
+# 39 "/usr/include/time.h" 2 3 4
+
+
+
+# 1 "/usr/include/bits/time.h" 1 3 4
+# 43 "/usr/include/time.h" 2 3 4
+# 131 "/usr/include/time.h" 3 4
+
+
+struct tm
+{
+  int tm_sec;
+  int tm_min;
+  int tm_hour;
+  int tm_mday;
+  int tm_mon;
+  int tm_year;
+  int tm_wday;
+  int tm_yday;
+  int tm_isdst;
+
+
+  long int tm_gmtoff;
+  __const char *tm_zone;
+
+
+
+
+};
+
+
+
+
+
+
+
+
+struct itimerspec
+  {
+    struct timespec it_interval;
+    struct timespec it_value;
+  };
+
+
+struct sigevent;
+# 180 "/usr/include/time.h" 3 4
+
+
+
+extern clock_t clock (void) __attribute__ ((__nothrow__));
+
+
+extern time_t time (time_t *__timer) __attribute__ ((__nothrow__));
+
+
+extern double difftime (time_t __time1, time_t __time0)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+
+
+extern time_t mktime (struct tm *__tp) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern size_t strftime (char *__restrict __s, size_t __maxsize,
+   __const char *__restrict __format,
+   __const struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+
+# 217 "/usr/include/time.h" 3 4
+extern size_t strftime_l (char *__restrict __s, size_t __maxsize,
+     __const char *__restrict __format,
+     __const struct tm *__restrict __tp,
+     __locale_t __loc) __attribute__ ((__nothrow__));
+# 230 "/usr/include/time.h" 3 4
+
+
+
+extern struct tm *gmtime (__const time_t *__timer) __attribute__ ((__nothrow__));
+
+
+
+extern struct tm *localtime (__const time_t *__timer) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern struct tm *gmtime_r (__const time_t *__restrict __timer,
+       struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+
+
+
+extern struct tm *localtime_r (__const time_t *__restrict __timer,
+          struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+
+
+
+
+
+extern char *asctime (__const struct tm *__tp) __attribute__ ((__nothrow__));
+
+
+extern char *ctime (__const time_t *__timer) __attribute__ ((__nothrow__));
+
+
+
+
+
+
+
+extern char *asctime_r (__const struct tm *__restrict __tp,
+   char *__restrict __buf) __attribute__ ((__nothrow__));
+
+
+extern char *ctime_r (__const time_t *__restrict __timer,
+        char *__restrict __buf) __attribute__ ((__nothrow__));
+
+
+
+
+extern char *__tzname[2];
+extern int __daylight;
+extern long int __timezone;
+
+
+
+
+extern char *tzname[2];
+
+
+
+extern void tzset (void) __attribute__ ((__nothrow__));
+
+
+
+extern int daylight;
+extern long int timezone;
+
+
+
+
+
+extern int stime (__const time_t *__when) __attribute__ ((__nothrow__));
+# 313 "/usr/include/time.h" 3 4
+extern time_t timegm (struct tm *__tp) __attribute__ ((__nothrow__));
+
+
+extern time_t timelocal (struct tm *__tp) __attribute__ ((__nothrow__));
+
+
+extern int dysize (int __year) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+# 328 "/usr/include/time.h" 3 4
+extern int nanosleep (__const struct timespec *__requested_time,
+        struct timespec *__remaining);
+
+
+
+extern int clock_getres (clockid_t __clock_id, struct timespec *__res) __attribute__ ((__nothrow__));
+
+
+extern int clock_gettime (clockid_t __clock_id, struct timespec *__tp) __attribute__ ((__nothrow__));
+
+
+extern int clock_settime (clockid_t __clock_id, __const struct timespec *__tp)
+     __attribute__ ((__nothrow__));
+
+
+
+
+
+
+extern int clock_nanosleep (clockid_t __clock_id, int __flags,
+       __const struct timespec *__req,
+       struct timespec *__rem);
+
+
+extern int clock_getcpuclockid (pid_t __pid, clockid_t *__clock_id) __attribute__ ((__nothrow__));
+
+
+
+
+extern int timer_create (clockid_t __clock_id,
+    struct sigevent *__restrict __evp,
+    timer_t *__restrict __timerid) __attribute__ ((__nothrow__));
+
+
+extern int timer_delete (timer_t __timerid) __attribute__ ((__nothrow__));
+
+
+extern int timer_settime (timer_t __timerid, int __flags,
+     __const struct itimerspec *__restrict __value,
+     struct itimerspec *__restrict __ovalue) __attribute__ ((__nothrow__));
+
+
+extern int timer_gettime (timer_t __timerid, struct itimerspec *__value)
+     __attribute__ ((__nothrow__));
+
+
+extern int timer_getoverrun (timer_t __timerid) __attribute__ ((__nothrow__));
+# 417 "/usr/include/time.h" 3 4
+
+# 13 "rdtsc.h" 2
+# 32 "rdtsc.h"
+static inline unsigned long long RDTSC()
+{
+ unsigned long long val;
+
+ asm volatile( "mfence\n"
+   "rdtsc" : "=A" (val));
+
+ return (val);
+}
+
+
+static inline unsigned long long GTD()
+{
+ struct timeval time;
+
+ gettimeofday(&time, ((void *)0));
+
+ return (((unsigned long long)time.tv_sec * 1000000) + time.tv_usec);
+}
+
+
+static inline unsigned long long CGT()
+{
+ struct timespec time;
+
+ clock_gettime(0, &time);
+
+ return (((unsigned long long)time.tv_sec * 1000000000) + time.tv_nsec);
+}
+# 36 "count.c" 2
+# 70 "count.c"
+typedef struct barrier {
+ pthread_cond_t complete;
+ pthread_mutex_t mutex;
+ int count;
+ int crossing;
+} barrier_t;
+
+void barrier_init(barrier_t *b, int n) {
+ pthread_cond_init(&b->complete, ((void *)0));
+ pthread_mutex_init(&b->mutex, ((void *)0));
+ b->count = n;
+ b->crossing = 0;
+}
+
+void barrier_cross(barrier_t *b) {
+ pthread_mutex_lock(&b->mutex);
+
+ b->crossing++;
+
+ if (b->crossing < b->count) {
+  pthread_cond_wait(&b->complete, &b->mutex);
+ } else {
+  pthread_cond_broadcast(&b->complete);
+
+  b->crossing = 0;
+ }
+ pthread_mutex_unlock(&b->mutex);
+}
+
+
+
+
+
+typedef struct _data_variables{
+ int data;
+
+
+
+} data_variables_t;
+
+
+ static data_variables_t data_variables[64];
+
+ static data_variables_t data_variable;
+
+
+
+
+typedef struct _spinlock {
+ int lock;
+} spinlock_t;
+
+
+
+ static int spinlock_variable;
+
+static inline void init_spinlock() {
+
+ spinlock_variable = 0;
+}
+
+static inline void test_spinlock(long arg) {
+
+ while ( ({ __typeof(*(((&(spinlock_variable))))) __x = ((1)); switch (sizeof(*(&(spinlock_variable)))) { case 1: asm volatile("xchgb %b0,%1" : "=q" (__x) : "m" (*__xg(((&(spinlock_variable))))), "0" (__x) : "memory"); break; case 2: asm volatile("xchgw %w0,%1" : "=r" (__x) : "m" (*__xg(((&(spinlock_variable))))), "0" (__x) : "memory"); break; case 4: asm volatile("xchgl %0,%1" : "=r" (__x) : "m" (*__xg(((&(spinlock_variable))))), "0" (__x) : "memory"); break; case 8: asm volatile("xchgq %0,%1" : "=r" (__x) : "m" (*__xg(((&(spinlock_variable))))), "0" (__x) : "memory"); break; default: assert(!sizeof(*(&(spinlock_variable)))); } __x; }) )
+  ;
+
+
+
+
+ spinlock_variable = 0;
+}
+
+
+
+
+ static int vspinlock_variable;
+
+
+static inline void init_vspinlock() {
+ spinlock_variable = 0;
+}
+
+static inline void test_vspinlock(long arg) {
+ while (cmpxchg(&spinlock_variable, 1) != 1234)
+  ;
+
+
+
+
+ spinlock_variable = 1234;
+}
+
+
+
+
+
+ static int ticket_variable;
+
+static inline void init_ticket() {
+ ticket_variable = 0;
+}
+
+static inline void test_ticket(long arg) {
+
+}
+
+
+
+
+static inline void init_arraylock() {
+
+}
+
+static inline void test_arraylock(long arg) {
+
+}
+
+
+
+
+
+int test_mcs() {
+
+}
+
+int test_cachemcs( data) {
+
+}
+
+int test_message (data) {
+
+}
+# 215 "count.c"
+typedef sample_t unsigned long;
+
+typedef struct private {
+ int index;
+ int cpu;
+ int count;
+ int pad;
+ sample_t samples[];
+} private_t;
+
+int stop = 0;
+
+void *test(void *arg)
+{
+ private_t * data = (private_t *) arg;
+ cpu_set_t cpuset;
+   int src, dst, id;
+   int iter, max_iter;
+   unsigned long long timestamp1, timestamp2;
+
+   src = get_cpu(); dst = data->cpu; id = data->id;
+ CPU_ZERO(&cpuset);
+ CPU_SET(dst, &cpuset);
+    if (sched_setaffinity(0, sizeof (cpu_set_t), &cpuset)) {
+  perror("sched_getaffinity MAJOR ERROR");
+  exit( 1 );
+ }
+
+    dst = get_cpu();
+    printf ("thread id %d src %d dst %d (requested %d)\n",
+      data->id, src, dst, data->cpu);
+
+    iter=0; max_iter=data->count;
+
+    init_spinlock();
+
+
+
+
+
+  while ((iter < max_iter) && (!stop)) {
+  (timestamp1 = RDTSC());
+
+  test_spinlock(id);
+
+  timestamp2 = (RDTSC() - b);
+
+  data->sample[i] = (sample_t) timestamp2;
+  i++;
+  }
+
+  printf("thread id: %d iterations %d\n", iter)
+  pdata->count = iter;
+
+
+  return 0;
+}
+
+
+
+
+
+static inline int get_cpu() {
+ int cpu
+
+
+
+
+
+
+  cpu = sched_getcpu();
+
+  return cpu;
+}
+
+
+
+
+
+int main(int argc, char* argv[]) {
+
+
+
+ pthread_attr_t attr;
+ pthread_t * threads;
+ private_t * data, pdata;
+ struct timeval real_start, start, end;
+ struct timespec timeout;
+ unsigned long offset;
+ int threads_num, cpus_num;
+ int duration = 1000, iterations = 8192;
+ int _ret, i, l;
+ struct option long_options[] = {
+
+     {"duration", required_argument, ((void *)0), 'd'},
+     {"iterations", required_argument, ((void *)0), 'i'},
+     {"threads", required_argument, ((void *)0), 'n'},
+     {"test", required_argument, ((void *)0), 't'},
+     {((void *)0), 0, ((void *)0), 0}
+ };
+
+   while(1) {
+     i = 0;
+     c = getopt_long(argc, argv, "d:n:t:", long_options, &i);
+
+     if(c == -1)
+       break;
+
+     if(c == 0 && long_options[i].flag == 0)
+       c = long_options[i].val;
+
+     switch(c) {
+      case 0:
+
+        break;
+      case 'd':
+        duration = atoi(optarg);
+        break;
+      case 'i':
+        iterations = atoi(optarg);
+        break;
+      case 'n':
+        threads_num = atoi(optarg);
+        break;
+      case 't':
+       printf("case t is not implemented right now %s \n", optarg);
+
+       test = thread_spinlock;
+
+      break;
+      default:
+        exit(1);
+     }
+   }
+
+   assert (threads_num >=1);
+   assert (iterations >=1);
+   assert (duration >0);
+   assert (test != 0);
+
+
+   int offset = (sizeof(private_t) + (sizeof(sample_t)* iterations);
+    if ((data = (private_t *) malloc(threads_num * offset)) == ((void *)0)) {
+  perror("malloc %d * %d", threads_num, offset);
+  exit(1);
+ }
+ if ((threads = (pthread_t *) malloc(threads_num * sizeof(pthread_t)))
+   == ((void *)0)) {
+  perror("malloc");
+  exit(1);
+ }
+
+ cpus_num = sysconf(_SC_NPROCESSORS_ONLN);
+ main_cpu = get_cpu();
+ printf("creating %d threads on %d cpus from cpu %d\n",
+   threads_num, cpus_num, main_cpu);
+# 385 "count.c"
+ pthread_attr_init(&attr);
+ pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+ pdata = data;
+ l = 0;
+ for (i = 0; i < threads_num; i++) {
+  pdata->count = iterations;
+  pdata->index = i;
+
+
+
+  pdata->cpu = i;
+
+  pdata->cpu %= cpus_num;
+
+
+  printf("Creating thread %d cpu %d\n", i, pdata->cpu);
+  if (pthread_create(&threads[i], &attr, test, (void *) (pdata))
+    != 0) {
+   fprintf(stderr, "Error creating thread\n");
+   exit(1);
+  }
+  pdata = (private_t *)((void* pdata) + offset);
+ }
+ pthread_attr_destroy(&attr);
+# 419 "count.c"
+ gettimeofday(&real_start, ((void *)0));
+ barrier_cross(&barrier);
+ gettimeofday(&start, ((void *)0));
+ printf("STARTING...\n");
+ if (duration > 0) {
+  nanosleep(&timeout, ((void *)0));
+ } else {
+
+
+
+
+ }
+
+
+ stop = 1;
+ gettimeofday(&end, ((void *)0));
+ printf("STOPPING...\n");
+
+ for (i = 0; i < threads_num; i++) {
+  if (pthread_join(threads[i], ((void *)0)) != 0) {
+   fprintf(stderr, "Error waiting for thread completion\n");
+   exit(1);
+  }
+ }
+
+
+ for (i = 0; i< iterations; i++ ) {
+  pdata = data;
+  for (l = 0; l< threads_num; l++) {
+   if (pdata->iterations =< i)
+    printf("%ld ", pdata->samples[i]);
+   else
+    printf("%ld ", 0);
+   pdata = (private_t*)((void*)pdata + offset);
+  }
+  printf("\n");
+ }
+
+
+ free (data);
+ return 0;
+}
diff --git a/ipc/test/matrix_comm.c b/ipc/test/matrix_comm.c
new file mode 100644
index 0000000..333f417
--- /dev/null
+++ b/ipc/test/matrix_comm.c
@@ -0,0 +1,367 @@
+
+// Copyright Antonio Barbalace Virginia Tech 2012
+// Project Popcorn
+
+/*
+ * matrix / 2D communication for mklinux
+ * support to cache coherency
+ * support to NUMA architectures
+ */
+
+
+//#define UNIT_TEST_MACOMM
+//#define USE_MBUFFER
+
+//#include "types.h"
+typedef unsigned short u16;
+typedef unsigned int u32;
+
+#ifndef CACHE_ALIGNED
+ #define CACHE_ALIGNED
+#endif
+
+#include "buffer.h"
+#ifdef USE_MBUFFER
+ #include "mbuffer.h"
+#endif /* USE_MBUFFER */
+
+#include "matrix_comm.h"
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <assert.h>
+
+#include "alloc.h"
+
+// TODO NUMA placement, i.e. each thread must be affine
+// TODO cache efficiency
+// TODO how to handle resizing ?!?! STATIC ALLOCATION for now
+
+// the kernel extension will work with IPI (comparing with MSI can be an option)
+// interrupts and other stuff handled at another layer
+
+/*
+For each core allocate the followings locally on the node
+	a. n buffers of size BBUFFER_SIZEOF(padded_space) +
+	b. recv bitmap array
+	c. recv buffer pointer array
+	d. send buffer pointer array
+
+	1. global descriptor is max_elemnents
+	2. an array of pointers to the different local buffers
+	3. current number of subscribers
+	4. a global lock to access child data structures
+*/
+// input: number of cpu (to create the matrix)
+//return a global descriptor allocated for max elements
+// size is size of each singular receive buffer
+//local_vector_t **
+global_vector_t matrix_init_global(int size, int cpus )
+{
+	int i, l;
+
+
+	if ((cpus < 1) || (cpus > MAX_CPUS) || !(size))
+		return 0;
+
+	/* this code will not use bbuffer_init */
+	int bbuf_pad_size = size;
+#ifdef CACHE_ALIGNED
+	bbuf_pad_size = BBUFFER_SPACE(size);
+#endif /* CACHE_ALIGNED */
+	BBUFFER_CHECK(bbuf_pad_size);
+
+	/* for each cpu there is a vector of recveirs buffers */
+	int bbuf_size = BBUFFER_SIZEOF(bbuf_pad_size);
+	int vector_memory = sizeof(local_vector_t) +
+			(bbuf_size * cpus);
+
+	/* actual matrix, can be wherever accessed only at init during matrix_init_local */
+	global_vector_t matrix = alloc_global(cpus * sizeof(local_vector_t*));
+
+	/* allocate and init local data structures */
+	for (i=0; i<cpus; i++) {
+		int node = get_node_from_cpu(i);
+		matrix[i] = (local_vector_t*)alloc_on_node(vector_memory, node);
+		if (!(matrix[i]))
+			return 0; // bad error
+
+		/* check the alignment*/
+		bbuffer_t * pbbuf = (bbuffer_t*)&(matrix[i][1]);
+		CHECK_CACHE_ALIGNED(matrix[i]);
+		CHECK_CACHE_ALIGNED(pbbuf); //must be by design
+		/* init local data structures */
+		for (l=0; l<cpus; l++) {
+			BBUFFER_INIT(pbbuf, bbuf_pad_size);
+			matrix[i]->recv[l] = pbbuf;
+			pbbuf = (bbuffer_t*)((void*)pbbuf + bbuf_size);
+		}
+
+		matrix[i]->cpus = cpus;
+		matrix[i]->me = i;
+	}
+
+	/* link the different local data structures send pointers*/
+	for (i=0; i<cpus; i++)
+		for (l=0; l<cpus; l++) {
+			matrix[i]->send[l] = matrix[l]->recv[i];
+			matrix[i]->send_pbmp[l] = matrix[l]->recv_bmp;
+		}
+
+	return matrix;
+
+	// handle errors
+}
+
+//TODO future version
+//matrix_update_local() { }
+
+// there are different strategies for the allocation (because I do not know if we can allocate remotely)
+// one idea (easyest is to allocate the matrix in the global function and then
+local_vector_t * matrix_init_local(global_vector_t global, int cpu) {
+	/*
+	required to use numa move page
+	or deallocate and reallocate locally
+*/
+	/*properties are:
+	 * 1. how many elements
+	 * 2. my personal index (increment and get on the global desc
+	 */
+/*
+	-locally we have the receiving buffers (ptrs and the actual buffers where to read)
+	-locally we have the array of remotely recv buffer where to write
+
+	...each recv buffer is a circular buffer...
+	*/
+	//return the right local_vector pointer
+	return global[cpu];
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// finalization functions
+/*
+matrix_finalize_local() {}
+*/
+void matrix_finalize_global(global_vector_t matrix)
+{
+	int i, l, c;
+	c = matrix[0]->cpus;
+
+	/* unlink send buffers*/
+	for (i=0; i<c; i++)
+		for (l=0; l<c; l++) {
+			matrix[i]->send[l] = 0;
+			matrix[i]->send_pbmp[l]= 0;
+		}
+
+	/* we reset each bitmap and recv buffer */
+	for (i=0; i<c; i++)
+		memset(matrix[i]->recv_bmp, 0, sizeof(matrix[i]->recv_bmp));
+	/* two for cycles in order to a receiver to get out */
+	for (i=0; i<c; i++)
+		for (l=0; l<c; l++)
+			matrix[i]->recv[l] = 0;
+
+	/* we assume that here no one will still be reading on linked memory,
+	  delete each local container */
+	for (i=0; i<c; i++)
+		free_on_node(matrix[i]);
+
+	free_on_node(matrix);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// point to point send functions
+
+// point to point send
+int matrix_send_to(local_vector_t * vector, int dest, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!vector)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(dest < vector->cpus))
+		return 0;
+	/* check if the destination recv buffer is registered */
+	if (!(bb = vector->send[dest]))
+		return 0;
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_put(bb, buff, count);
+#else
+	a = bbuffer_put(bb, buff, count);
+#endif
+
+	if (a > 0)
+		set_bit_bitmap(vector->send_pbmp[dest], vector->me);
+	return a;
+}
+
+int matrix_send_self(local_vector_t * vector, char* buff, int count)
+{
+	return matrix_send_to(vector, vector->me, buff, count);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// multicast send functions
+
+//TODO future version
+//matrix_send_many() { }
+
+//TODO future version
+//NOTE send_all is sub of send_many
+//matrix_send_all() { }
+
+
+///////////////////////////////////////////////////////////////////////////////
+// point to point recv functions
+
+int matrix_recv_from(local_vector_t* vector, int src, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!vector)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(src < vector->cpus))
+		return 0;
+	/* check if our recv buffer is registered */
+	if (!(bb = vector->recv[src]))
+		return 0;
+
+	// we choose to do not use the bitmap here but only as a best
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_get(bb, buff, count);
+#else
+	a = bbuffer_get(bb, buff, count);
+#endif
+
+	if (a > 0)
+		if (!bbuffer_count(bb))
+			clear_bit_bitmap(vector->recv_bmp, src);
+	return a;
+}
+
+int matrix_recv_self(local_vector_t* vector, char* buff, int count)
+{
+	return matrix_recv_from(vector, vector->me, buff, count);
+}
+
+//peak one message round-robin on different queques (or on the bitmap)11
+//(a one message technique can be implemented)
+int matrix_recv(local_vector_t* vector, char* buff, int count)
+{
+	//DIFFERENT POLITICS FOR CHOOSING THE NEXT
+	register int source = ffs_bit_bitmap(&(vector->recv_bmp[0]));
+	return matrix_recv_from(vector, source, buff, count);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// group recv functions
+/*
+matrix_recv_many() {
+	// I think this and all are more for synchronization purposes
+}
+matrix_recv_all() {
+	// I think this and all are more for synchronization purposes
+}
+*/
+
+#ifdef UNIT_TEST_MACOMM
+
+#include <pthread.h>
+
+#define CPU_NUM   4
+#define BUFF_SIZE   65
+
+typedef struct _ldata {
+	global_vector_t glob;
+	local_vector_t * loc;
+	int id;
+} ldata;
+
+void* local_thread(void* arg)
+{
+	ldata * data= (ldata *) arg;
+	local_vector_t * vector = data->loc;
+	int node = data->id;
+	int  i, ret, count;
+	char buff[BUFF_SIZE]; memset(buff, 0, BUFF_SIZE);
+	//printf("c1 %d/%d vector:%p\n", node, CPU_NUM, vector);
+
+	// content - we are sending strings
+	sprintf(buff, "local_thread%d", node);
+	count = strlen(buff);
+	//printf("%d:'%s'\n", count, buff);
+
+	for (i=0; i< CPU_NUM; i++) {
+		// try to send point to point
+		while ((ret = matrix_send_to(vector, i, buff, count)) != count) ;
+	}
+
+	//printf("c2 %d/%d vector:%p\n", node, CPU_NUM, vector);
+	count = BUFF_SIZE;
+	for (i=0; i< CPU_NUM; i++) {
+		// receive from every one
+		memset(buff, 0, BUFF_SIZE);
+		while ((ret = matrix_recv_from(vector, i, buff, count)) <= 0)
+			//printf("%d error %d, %p, %d, %p, %d\n", node, ret, vector, i, buff, count);
+			;
+		printf("%d:%d: %s [%d] %d\n", node, i, buff, strlen(buff), ret);
+	}
+}
+
+int main (int argc, char argv[]) {
+	global_vector_t macomm = matrix_init_global(BUFF_SIZE, CPU_NUM);
+	if (macomm == 0) {
+		printf("matrix init global error\n");
+		return 0;
+	}
+#ifdef USE_MBUFFER
+	printf("message oriented\n");
+#endif
+	printf("created a matrix of %d cpus buffer size %d\n", CPU_NUM, BUFF_SIZE);
+
+	// create one thread per core
+	int i;
+	pthread_attr_t attr;
+	pthread_t threads[CPU_NUM];
+	pthread_attr_init(&attr);
+	pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+	for (i=0; i< CPU_NUM; i++) {
+		ldata * ld = (ldata*) malloc(sizeof(ldata)*CPU_NUM);
+		ld->glob = macomm;
+		ld->loc = matrix_init_local(macomm, i);
+		ld->id = i;
+		if (pthread_create(&threads[i], &attr, local_thread, (void *) (ld))
+			!= 0) {
+			printf("Error creating thread\n");
+			exit(1);
+		}
+	}
+	pthread_attr_destroy(&attr);
+
+	// pin each thread to each core
+
+	// join threads
+	for (i = 0; i < CPU_NUM; i++) {
+		if (pthread_join(threads[i], NULL) != 0) {
+			printf("Error waiting for thread completion\n");
+			exit(1);
+		}
+	}
+
+	// delete data and exit
+	matrix_finalize_global(macomm);
+
+	return 0;
+}
+
+#endif /* UNIT_TEST_MACOMM */
diff --git a/ipc/test/matrix_comm.h b/ipc/test/matrix_comm.h
new file mode 100644
index 0000000..9e8f348
--- /dev/null
+++ b/ipc/test/matrix_comm.h
@@ -0,0 +1,46 @@
+
+// Author: Antonio Barbalace, Virginia Tech 2012
+#define MAX_CPUS 64
+#define MAX_ARRAY MAX_CPUS
+#define MAX_BITMAP 4
+
+#if (WORLD_BYTES == 4)
+ #define BIT_PER_BITMASK 32
+#else
+ #warning "code to be completed not currently correct for 64bit"
+#endif
+
+#include "bitmask.h"
+
+// todo we can pack the structure in order to have simple way to pad
+
+// local vector buffer
+#define __public
+#define __private
+typedef struct local_vector {
+	//local copy of the pointers must be held here
+	__public bitmask_t recv_bmp[MAX_BITMAP]; //this first because must be cache aligned
+
+	__private bitmask_t* send_pbmp[MAX_ARRAY]; //remote bitmap pointer
+
+	//TODO send_pbmp and send must be paired per access (i.e. they must be on the same cache line)
+	// in this way we eliminate cache problems
+
+	__public bbuffer_t* recv[MAX_ARRAY]; // allocated local
+	__private bbuffer_t* send[MAX_ARRAY]; // pointers to remote recv buffers
+	__public int cpus, me; //information must be replicated on each local copy
+	char pad[(CACHE_LINE -
+			( (sizeof(bbuffer_t *) * 2 * MAX_ARRAY) +
+			(sizeof(bitmask_t)* MAX_BITMAP) +
+			(2 * sizeof(int)) ) %
+			CACHE_LINE)];
+} local_vector_t;
+
+// global_vector holds the pointers to each local vector
+typedef local_vector_t** global_vector_t;
+
+
+//for each element a local copy must be held
+//previous prototype
+//struct matrix_entry  * vector [MAX_ARRAY];
+//static matrix_entry * matrix[MAX_ARRAY][MAX_ARRAY];
diff --git a/ipc/test/matrix_shm_comm.c b/ipc/test/matrix_shm_comm.c
new file mode 100644
index 0000000..63c795f
--- /dev/null
+++ b/ipc/test/matrix_shm_comm.c
@@ -0,0 +1,537 @@
+
+// matrix shm communicator (using shm sysv)
+// Copyright Antonio Barbalace, Virginia Tech 2012
+
+/* TODO completely rewrite and define a dynamic infrastructure
+ * matrix / 2D communication for mklinux
+ * support to cache coherency
+ * support to NUMA architectures
+ */
+
+
+//#define UNIT_TEST_MACOMM
+//#define USE_MBUFFER
+
+typedef unsigned short u16;
+typedef unsigned int u32;
+
+#ifndef CACHE_ALIGNED
+ #define CACHE_ALIGNED
+#endif
+
+#include "buffer.h"
+#ifdef USE_MBUFFER
+ #include "mbuffer.h"
+#endif /* USE_MBUFFER */
+
+#include "matrix_comm.h"
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <assert.h>
+
+#include "alloc.h"
+
+
+#include "matrix_shm_comm.h"
+
+
+static int matrix_init_matrix (matrix_comm ** pmatrix, int elements)
+{
+	char matrix_magic[]= MAGIC_CHARS_MATR;
+	int need_init =0;
+
+	// actual matrix that takes care about the mapping
+	//matrix_comm * matrix = (matrix_comm *)alloc_global(sizeof(matrix_comm));
+	matrix_comm * matrix = (matrix_comm *)alloc_global(sizeof(matrix_comm));
+	if (!matrix) {
+		fprintf(stderr, "matrix_init_matrix: error allocating matrix_comm\n");
+ 		return -1;
+	}
+
+	// check if the area was allocated before
+	if ( memcmp(matrix, matrix_magic, 4) == 0) {
+		// it was initialized before, sanity checks
+		if (matrix->elements != elements) {
+			fprintf(stderr, "matrix_init_matrix: matrix elements not correspond %d %d\n",
+					matrix->elements, elements);
+			return -1;
+		}
+	}
+	else {
+		// it was never initialized before,
+		need_init =1;
+
+		//Initialize the main matrix descriptor
+		memcpy(matrix, matrix_magic, 4);
+		matrix->elements = elements;
+		matrix->lock = 0;
+		memset (&(matrix->present), 0, sizeof(bitmask_t));
+		memset (&(matrix->desc[0]), 0, sizeof(void*) * elements);
+	}
+
+	if (pmatrix)
+		*pmatrix = matrix;
+
+	return need_init;
+}
+
+static int matrix_init_row (row_comm ** prow, matrix_comm * matrix,
+		int size, int need_init, int id, int elements)
+{
+	char row_magic[]= MAGIC_CHARS_ROW;
+	int l;
+	int need_init_cell =0;
+
+	/* this code will not use bbuffer_init */
+	int bbuf_pad_size = size;
+#ifdef CACHE_ALIGNED
+	bbuf_pad_size = BBUFFER_SPACE(size);
+#endif /* CACHE_ALIGNED */
+	BBUFFER_CHECK(bbuf_pad_size);
+
+	/* for each cpu there is a vector of recveirs buffers */
+	int bbuf_size = BBUFFER_SIZEOF(bbuf_pad_size);
+	int row_memory =
+			sizeof(row_comm) + (bbuf_size * elements);
+
+
+	// we need to pass the cpuid in order to get the right shm area
+	// is the alloc function that has to figure out the correct mem zone
+	row_comm * row = (row_comm * ) alloc_on_node(row_memory, id);
+	if ( !(row) ) {
+		fprintf(stderr, "matrix_init_row: error allocating row_comm\n");
+		return 0;
+	}
+	CHECK_CACHE_ALIGNED(row);
+	matrix->desc[id] = row; // TODO
+
+	// if init is not required check if the area was allocated before
+	if ( !need_init && (memcmp(row, row_magic, 4) == 0)) {
+		need_init_cell=0;
+
+		// it was initialized before, sanity checks
+		if (row->elements != elements) {
+			fprintf(stderr, "matrix_init_row: row elements not correspond %d %d\n",
+					row->elements, elements);
+			return 0;
+		}
+		if (row->csize != bbuf_size) {
+			fprintf(stderr, "matrix_init_row: size not correspond %d %d\n",
+					row->csize, bbuf_size);
+			return 0;
+		}
+	}
+	else {
+		// it was never initialized before
+		need_init_cell =1;
+
+		memcpy(row, row_magic, 4);
+		row->elements = elements;
+		row->id = id;
+		row->lock = 0;
+
+		memset(&(row->status), 0, sizeof(bitmask_t) * MAX_BITMAP);
+		memset(&(row->active), 0, sizeof(bitmask_t) * MAX_BITMAP);
+		memset(&(row->offset), 0, sizeof(unsigned long) * MAX_ELEMENTS);
+
+		row->csize = bbuf_size;
+		row->cnumber = 0;
+	}
+
+	// check the alignment
+	CHECK_CACHE_ALIGNED( (&(row->status)) );
+
+	bbuffer_t * pbbuf = (bbuffer_t*)&(row[1]);
+	CHECK_CACHE_ALIGNED( pbbuf );
+
+	// init local data structures if required
+	if (need_init_cell)
+		for (l=0; l<elements; l++) {
+			BBUFFER_INIT(pbbuf, bbuf_pad_size);
+
+			row->offset[l] =
+					(unsigned long)pbbuf - (unsigned long)((bbuffer_t*)&(row[1]));
+			pbbuf = (bbuffer_t*)((void*)pbbuf + bbuf_size);
+
+			set_bit_bitmap(&(row->active[0]), l);
+		}
+
+	if (prow)
+		*prow = row;
+
+	return need_init_cell;
+}
+
+/*
+ * size is the size of a single message cell buffer
+ * elements is the maximum number of rows or columns
+ *
+ * The returned value refer to a private local comm_mapping struct
+ * such data structure saves the mappings of the different memory areas
+ */
+comm_mapping * matrix_init_mapping (int size, int elements )
+{
+	int i, l;
+	int need_init =0, need_init_cell =0;
+
+	char matrix_magic[]= MAGIC_CHARS_MATR;
+	char row_magic[]= MAGIC_CHARS_ROW;
+
+	matrix_comm * matrix;
+
+	/* arguments checks */
+	if ((elements < 1) || (elements > MAX_CPUS) || !(size))
+		return 0;
+
+	alloc_init();
+
+	need_init = matrix_init_matrix( &matrix, elements);
+	if (need_init == -1)
+		return 0;
+
+	// create a comm_mapping descriptor
+	comm_mapping * map = (comm_mapping*)
+			alloc_private(sizeof(comm_mapping), -1);
+	if (!map) {
+		fprintf(stderr, "matrix_init_mapping: error allocating comm_mapping id %d\n", -1);
+		return 0;
+	}
+	memset (map, 0, sizeof(comm_mapping));
+	map->matrix = matrix;
+
+
+	// allocate and init local data structures
+	for (i=0; i<elements; i++) {
+
+		row_comm * row;
+		int need_init_cell = matrix_init_row (&row, matrix,
+						size, need_init, i, elements);
+		if ( need_init_cell == -1 )
+			return 0;
+
+		// save the private mapping
+		map->row[i] = row;
+		map->bmp[i] = &(row->status[0]);
+		map->buf[i] = (bbuffer_t *) &(row[1]);
+
+		// set the global descriptor
+		set_bit_bitmap(&(matrix->present[0]), i); // TODO move this to next function?
+	}
+
+	return map;
+}
+
+/*
+ * This function assumes that a previous call to matrix_init_mapping was issued
+ * and the shared data areas are mapped to memory (shared data areas corrensponds to
+ * MPICH segments
+ */
+comm_buffers * matrix_init_buffers(comm_mapping * map, int id)
+{
+	int i;
+	int elements =0, bbuf_size =0;
+
+
+	/* arguments checks */
+	if ( !(map) || (id < 0) || (id >= MAX_CPUS) )
+		return 0;
+	if ( !(map->matrix) || !(map->row[id]) )
+		return 0;
+
+
+	/* reload the arguments */
+	elements = map->matrix->elements;
+	bbuf_size = map->row[id]->csize;
+
+	/* create a comm_buffers descriptor */
+	comm_buffers * buffs = (comm_buffers*)
+			alloc_private(sizeof(comm_buffers), id);
+	if (!buffs) {
+		fprintf(stderr, "matrix_init_buffers: error allocating comm_buffers id %d\n", id);
+		return 0;
+	}
+	memset(buffs, 0, sizeof(comm_buffers));
+
+	/* init the private data structure */
+	buffs->id = id;
+	buffs->elements = elements;
+	buffs->recv_bmp = map->bmp[id];
+
+	/* cells of this row */
+	for (i=0; i<elements; i++)
+		buffs->recv_buf[i] = (void*) map->buf[id] + (bbuf_size * i);
+
+	/* cross references */
+	for (i=0; i<elements; i++) {
+		buffs->send[i].bmp = map->bmp[i];
+		buffs->send[i].buf = (void*) map->buf[i] + (bbuf_size * id);
+	}
+
+	return buffs;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// finalization functions
+
+void matrix_finalize_buffers (comm_mapping * map)
+{}
+
+void matrix_finalize_mapping (comm_mapping * map)
+{
+	// TODO
+
+/*	int i, l, c;
+	c = matrix[0]->cpus;
+
+	// unlink send buffers
+	for (i=0; i<c; i++)
+		for (l=0; l<c; l++) {
+			matrix[i]->send[l] = 0;
+			matrix[i]->send_pbmp[l]= 0;
+		}
+
+	// we reset each bitmap and recv buffer
+	for (i=0; i<c; i++)
+		memset(matrix[i]->recv_bmp, 0, sizeof(matrix[i]->recv_bmp));
+	// two for cycles in order to a receiver to get out
+	for (i=0; i<c; i++)
+		for (l=0; l<c; l++)
+			matrix[i]->recv[l] = 0;
+
+	// we assume that here no one will still be reading on linked memory,
+	  delete each local container
+	for (i=0; i<c; i++)
+		free_on_node(matrix[i]);
+
+	free_on_node(matrix);
+	*/
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// point to point send functions
+
+// point to point send
+int matrix_send_to(comm_buffers * buffs, int dest, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!buffs)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(dest < buffs->elements))
+		return 0;
+	/* check if the destination recv buffer is registered */
+	if (!(bb = buffs->send[dest].buf))
+		return 0;
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_put(bb, buff, count);
+#else
+	a = bbuffer_put(bb, buff, count);
+#endif
+
+	if (a > 0)
+		set_bit_bitmap(buffs->send[dest].bmp, buffs->id);
+	return a;
+}
+
+int matrix_send_self(comm_buffers * buffs, char* buff, int count)
+{
+	if ( !buffs )
+		return 0;
+
+	return matrix_send_to(buffs, buffs->id, buff, count);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// multicast send functions
+
+//TODO future version
+//matrix_send_many() { }
+
+//TODO future version
+//NOTE send_all is sub of send_many
+//matrix_send_all() { }
+
+
+///////////////////////////////////////////////////////////////////////////////
+// point to point recv functions
+
+int matrix_recv_from(comm_buffers* buffs, int src, char* buff, int count)
+{
+	register bbuffer_t * bb;
+
+	/* check if the vector is valid */
+	if (!buffs)
+		return 0;
+	/* check if the cpu is in range */
+	if (!(src < buffs->elements))
+		return 0;
+	/* check if our recv buffer is registered */
+	if (!(bb = buffs->recv_buf[src]))
+		return 0;
+
+	// we choose to do not use the bitmap here but only as a best
+
+	register int a;
+#ifdef USE_MBUFFER
+	a = mbuffer_get(bb, buff, count);
+#else
+	a = bbuffer_get(bb, buff, count);
+#endif
+
+	if (a > 0)
+		if (!bbuffer_count(bb))
+			clear_bit_bitmap(buffs->recv_bmp, src);
+	return a;
+}
+
+int matrix_recv_self(comm_buffers* buffs, char* buff, int count)
+{
+	return matrix_recv_from(buffs, buffs->id, buff, count);
+}
+
+//peak one message round-robin on different queques (or on the bitmap)11
+//(a one message technique can be implemented)
+int matrix_recv(comm_buffers* buffs, char* buff, int count)
+{
+	//DIFFERENT POLITICS FOR CHOOSING THE NEXT
+	register int source = ffs_bit_bitmap(&(buffs->recv_bmp[0]));
+	return matrix_recv_from(buffs, source, buff, count);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// group recv functions
+/*
+matrix_recv_many() {
+	// I think this and all are more for synchronization purposes
+}
+matrix_recv_all() {
+	// I think this and all are more for synchronization purposes
+}
+*/
+
+#ifdef UNIT_TEST_MACOMM
+
+#include <sys/types.h>
+#include <sys/ipc.h>
+#include <sys/shm.h>
+#include <unistd.h>
+#include <pthread.h>
+
+#define CPU_NUM   4
+#define BUFF_SIZE   65
+/*
+typedef struct _ldata {
+	global_vector_t glob;
+	local_vector_t * loc;
+	int id;
+} ldata;
+
+void* local_thread(void* arg)
+{
+	ldata * data= (ldata *) arg;
+	matrix_vector_t * vector = data->loc;
+	int node = data->id;
+	int  i, ret, count;
+	char buff[BUFF_SIZE]; memset(buff, 0, BUFF_SIZE);
+	//printf("c1 %d/%d vector:%p\n", node, CPU_NUM, vector);
+
+	// content - we are sending strings
+	sprintf(buff, "local_thread%d", node);
+	count = strlen(buff);
+	//printf("%d:'%s'\n", count, buff);
+
+	for (i=0; i< CPU_NUM; i++) {
+		// try to send point to point
+		while ((ret = matrix_send_to(vector, i, buff, count)) != count) ;
+	}
+
+	//printf("c2 %d/%d vector:%p\n", node, CPU_NUM, vector);
+	count = BUFF_SIZE;
+	for (i=0; i< CPU_NUM; i++) {
+		// receive from every one
+		memset(buff, 0, BUFF_SIZE);
+		while ((ret = matrix_recv_from(vector, i, buff, count)) <= 0)
+			//printf("%d error %d, %p, %d, %p, %d\n", node, ret, vector, i, buff, count);
+			;
+		printf("%d:%d: %s [%d] %d\n", node, i, buff, strlen(buff), ret);
+	}
+}
+*/
+int main (int argc, char argv[]) {
+	// TODO
+	// only parent create the infrastructure, we have to improve this point
+
+	// create different processes
+	pid_t child= fork();
+	if (child == -1) {
+		perror("forking");
+		return 0;
+	}
+	if (!child) {
+		child = 1;
+		printf("child id %d\n", child);
+		sleep (1);
+	}
+	else {
+		child = 0;
+		printf("parent id %d\n", child);
+	}
+
+	// the infrastructure is different:
+	// everyone have to create the mapping of the base area
+	// only one will creates the data infrastructure
+		comm_mapping * macomm = matrix_init_mapping(BUFF_SIZE, CPU_NUM);
+		if (macomm == 0) {
+			printf("matrix init global error\n");
+			return 0;
+		}
+		printf("SHM MACOMM %p created a matrix of %d cpus buffer size %d\n",
+				macomm,CPU_NUM, BUFF_SIZE);
+
+	// everyone map the infrastructure on itself *local* in the same way
+		comm_buffers * mavec = matrix_init_buffers(macomm, child);
+
+if (!child) //this stupid trick is to avoid using a barrier in this version
+	sleep(2);
+else
+	sleep(3);
+		// DATA test
+
+int count, ret, i;
+char buff[BUFF_SIZE]; memset(buff, 0, BUFF_SIZE);
+	sprintf(buff, "local_thread%d", child);
+	count = strlen(buff);
+	printf("%d:'%s' mavec:%p\n", count, buff, mavec);
+
+	for (i=0; i< 2; i++) {
+		// try to send point to point
+		while ((ret = matrix_send_to(mavec, i, buff, count)) != count) ;
+	}
+
+	printf("c2 %d/%d vector:%p\n", child, CPU_NUM, mavec);
+	count = BUFF_SIZE;
+	for (i=0; i< 2; i++) {
+		// receive from every one
+		memset(buff, 0, BUFF_SIZE);
+		while ((ret = matrix_recv_from(mavec, i, buff, count)) <= 0)
+		//printf("%d error %d, %p, %d, %p, %d\n", node, ret, vector, i, buff, count);
+		;
+		printf("%d:%d: %s [%d] %d\n", child, i, buff, strlen(buff), ret);
+	}
+
+printf("gonna to go out %d \n", child);
+
+	// delete data and exit
+//	if (child == 0) // only parent finalize
+//		matrix_finalize_global(macomm);
+
+	return 0;
+}
+
+#endif /* UNIT_TEST_MACOMM */
diff --git a/ipc/test/matrix_shm_comm.h b/ipc/test/matrix_shm_comm.h
new file mode 100644
index 0000000..2e1dc49
--- /dev/null
+++ b/ipc/test/matrix_shm_comm.h
@@ -0,0 +1,142 @@
+// for shm / kernel version the buffer needs some sort of global acknowledgment
+// the main shmkey is always fixed (i.e. the main address is passed at kernel init or in some BIOS descriptor
+// in such an area there are different things (an header is taking care about them):
+// 1. magic value
+// 2. max statically allocable array references
+// 3. a bitmap of currently allocated buffer
+// 4. a spinlock (can be used as an initialization barrier)
+
+// NOTE on the model
+// -Interrupt must be used to synchronize the data structure along different kernels
+// -Point 3 can relaxed to a static assignment to all the buffer (i.e. the first kernel will set up all the areas)
+
+/*
+ * We define a bi-dimensional matrix for the Point to Point communications.
+ * This means that the broadcast/multicast communications require another
+ * infrastructure.
+ *
+ * The bi-dimensional matrix is organized in row. Every row is local to one
+ * communicator, this will exploit locality if the communicator is pinned to
+ * core local to the row's memory.
+ * Every cell of the row is a receiver buffer (one reader one writer),
+ * lockfree.
+ */
+
+#define MAX_ELEMENTS MAX_ARRAY
+#define USE_CACHE_ALIGN
+
+#define MAGIC_CHARS_ROW {'R','O','W',' '}
+
+typedef struct _row_comm {
+	char magic[4];		// magic
+	int elements;		// number of cpus
+	int id;				// cpu identifier
+	unsigned long lock;	// lock
+
+#ifdef USE_CACHE_ALIGN
+	char pad0[(CACHE_LINE -
+			( (sizeof(char) *4) +
+			(sizeof(int) *2) +
+			(sizeof(unsigned long) *1) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+
+	bitmask_t 	  status[MAX_BITMAP];   // receivers (cells) status
+	bitmask_t 	  active[MAX_BITMAP];	// currently allocated buffers or initialized
+	unsigned long offset[MAX_ARRAY];	// offset of the buffer from the beginning of the map
+	int 	 	  csize;				// allocated space per buffer
+	int 		  cnumber;				// number of buffers currently present
+
+#ifdef USE_CACHE_ALIGN
+	char pad1[(CACHE_LINE -
+			( (sizeof(bitmask_t) *2 *MAX_BITMAP) +
+			(sizeof(int) *2) +
+			(sizeof(unsigned long) *MAX_ARRAY) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+} row_comm;
+
+//NOTA ricordati la differenza tra massimo numero di elementi e quelli correntemente allocati
+
+// this is dependent by the type of memory allocator we are using
+// see what we learn from the MPICH/Nemesis guys so define it
+// simply void*
+typedef struct _shm_desc {
+	size_t	size;
+	key_t	key;
+	row_comm * addr; // used by the setup process
+} shm_desc;
+// TODO move in the allocator
+
+
+#define MAGIC_CHARS_MATR {'M','A','T','R'}
+//general communicator header
+typedef struct _matrix_comm {
+	char			magic[4];
+	unsigned long	lock; // we have to spinlock so must maybe be cache aligned (the problem is this does not to be critical)
+
+	int				elements; // the maximum number of elements, or the currently allocated elements
+	bitmask_t 		present[MAX_BITMAP]; // which elements are currently really allocated
+	void*			desc[MAX_ELEMENTS]; // available descriptors per element
+
+} matrix_comm;
+
+
+// NOTA the following two can be merged in one!!!
+// they are both allocated locally/privately
+// so no one cares
+// what will be readed concurrently and is in the same cache line?
+// does something like this exists? and if yes what?
+
+//structure CACHE_ALIGNED !!!
+typedef struct _comm_buffers {
+
+	// THIS IS MY BITMAP: the copy is inshared memory
+	bitmask_t * recv_bmp; //this first because must be cache aligned
+	// THIS ARE THE ptr to MY BUFFERS hopefully they will fit the same cache line of the pointer before
+	bbuffer_t * recv_buf[MAX_ARRAY];
+
+#ifdef USE_CACHE_ALIGN
+	char pad0[(CACHE_LINE -
+			( (sizeof(bitmask_t *) *1) +
+			(sizeof(bbuffer_t *) *MAX_ARRAY) ) %
+			CACHE_LINE)];
+#endif	/* USE_CACHE_ALIGN */
+
+	// the following data is packed per item  because it will be accessed together
+	struct {
+		// remote bitmap pointer
+		bitmask_t * bmp;
+		// remote recv buffer pointer
+		bbuffer_t * buf;
+	} send[MAX_ARRAY];
+
+	// the following is not aligned
+	int elements, id; //information must be replicated on each local copy
+
+} comm_buffers;
+
+// this is the private/local summary of each area
+typedef struct _comm_mapping {
+	matrix_comm * matrix;
+	row_comm    * row[MAX_ARRAY];
+
+	// remove the followings?!?!
+	// the following can be reconstructed from base
+	bitmask_t* bmp[MAX_ARRAY];
+	bbuffer_t* buf[MAX_ARRAY];
+} comm_mapping;
+
+// PROTOTYPES DECLARATION
+
+comm_mapping * matrix_init_mapping (int size, int elements);
+comm_buffers * matrix_init_buffers (comm_mapping * map, int id);
+
+void matrix_finalize_buffers(comm_mapping * map);
+void matrix_finalize_mapping(comm_mapping * map);
+
+int matrix_send_to(comm_buffers * buffs, int dest, char* buff, int count);
+int matrix_send_self(comm_buffers * buffs, char *buff, int count);
+
+int matrix_recv_from(comm_buffers* buffs, int src, char* buff, int count);
+int matrix_recv_self(comm_buffers* buffs, char* buff, int count);
diff --git a/ipc/test/mbuffer.c b/ipc/test/mbuffer.c
new file mode 100644
index 0000000..5599eaa
--- /dev/null
+++ b/ipc/test/mbuffer.c
@@ -0,0 +1,284 @@
+// mbufer.c
+// Author: Antonio Barbalace, Virginia Tech 2012
+// messagge buffer (based on byte buffer)
+
+
+#include <stdint.h>
+
+//#include "types.h"
+typedef unsigned short u16;
+typedef unsigned int u32;
+
+#ifndef CACHE_ALIGNED
+ #define CACHE_ALIGNED
+#endif
+//#define UNIT_TEST_BBUFFER
+
+#include "buffer.h"
+#include "mbuffer.h"
+
+
+
+//and maybe one cache line before and after the buffer must be a watermark
+// header and buffer must be allocate together in the same private/local area
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <assert.h>
+
+
+
+
+typedef struct hheader {
+	union {
+		__indexes_t head_head;
+		struct _raw_heads {
+			__index_t part, total;
+		} header;
+	};
+} hheader_t;
+
+//#define MALIGNMENT CACHE_LINE
+#define MALIGNMENT sizeof(hheader_t)
+
+int mbuffer_put (bbuffer_t* buf, char* src, int count)
+{
+	register struct _raw_indexes ht;
+	struct _raw_heads hh;
+	register int acount, size, avail_elements; // used_elements,
+
+	ht = buf->indexes;
+	size = buf->size;
+
+	acount = sizeof(hheader_t) + count;
+	acount += MALIGNMENT - (acount % MALIGNMENT);
+
+	//used_elements = ((size + ht.head) - ht.tail) % size;
+    avail_elements = size - ((size + ht.head) - ht.tail) % size; //used_elements;
+
+    /* if the elements does not fit in the buffer return error */
+    if (acount > (avail_elements -1))
+    	return -1;
+
+    hh.part = count;
+    hh.total = acount;
+
+    /* head will cross the buffer */
+    if ((ht.head + sizeof(hheader_t)) >= size) {
+    	// copy the header
+    	memcpy(&(buf->buffer[ht.head]),
+    			&hh, (size - ht.head) );
+    	memcpy(&(buf->buffer[0]),
+    	    			(&hh + (size - ht.head)), (ht.head + sizeof(hheader_t)) % size);
+    	// copy the data
+    	memcpy(&(buf->buffer[((ht.head + sizeof(hheader_t)) % size)]),
+    	    			src, count);
+    	// mem set aligned data
+    	memset(&(buf->buffer[((ht.head + sizeof(hheader_t)) % size) + count]),
+    			-1, (acount - count - sizeof(hheader_t)) );
+    	// new head value
+    	ht.head = (ht.head + acount) % size;
+    }
+    /* data will cross the buffer */
+    else if ((ht.head + sizeof(hheader_t) + count) >= size) {
+    	// copy the header
+    	memcpy(&(buf->buffer[ht.head]),
+    			&hh, sizeof(hheader_t));
+    	// copy the data
+    	memcpy(&(buf->buffer[ht.head]) + sizeof(hheader_t),
+    			src, (size - sizeof(hheader_t) - ht.head));
+    	memcpy(&(buf->buffer[0]),
+    			(src + (size - sizeof(hheader_t) - ht.head)), (ht.head + sizeof(hheader_t) + count) % size);
+    	// memset aligned data
+    	memset(&(buf->buffer[((ht.head + sizeof(hheader_t) + count) % size)]),
+    			-1, (acount - count));
+    	// new head value
+    	ht.head = (ht.head + acount) % size;
+	}
+    /* aligned data will cross the buffer */
+    else if ((ht.head + acount) >= size) {
+		// copy the header
+		memcpy(&(buf->buffer[ht.head]), &hh, sizeof(hheader_t));
+		// copy the data
+		memcpy(&(buf->buffer[(ht.head + sizeof(hheader_t))]), src, count);
+		// memset the alignment
+		memset(&(buf->buffer[(ht.head + sizeof(hheader_t) + count)]),
+				-1, (size -ht.head -sizeof(hheader_t) -count));
+		memset(&(buf->buffer[0]),
+				-1, ((ht.head + acount) % size));
+		// new head value
+    	ht.head = (ht.head + acount) % size;
+    }
+    /* no data crossing */
+	else {
+		// copy the header
+		memcpy(&(buf->buffer[ht.head]), &hh, sizeof(hheader_t));
+		// copy the data
+		memcpy(&(buf->buffer[(ht.head + sizeof(hheader_t))]), src, count);
+		// memset the alignment
+		memset(&(buf->buffer[(ht.head + sizeof(hheader_t) + count)]), -1, (acount -count));
+		// new head value
+		ht.head = (ht.head + acount);
+	}
+
+    buf->indexes.head = ht.head;
+    return count;
+}
+
+int mbuffer_get (bbuffer_t * buf, char * dst, int count)
+{
+	register struct _raw_indexes ht;
+	struct _raw_heads hh;
+	register int size;
+	register int used_elements; // avail_elements;
+
+	ht = buf->indexes;
+	size = buf->size;
+
+	used_elements = (((size + ht.head) - ht.tail) % size);
+ 	//avail_elements = size - used_elements;
+
+ 	/* nothing present in the buffer */
+	if (used_elements == 0 ) // tail == head
+		return -1;
+
+	/* read the header, can cross the buffer */
+	if (ht.tail + sizeof(hheader_t) >= size) {
+		memcpy(&hh, &(buf->buffer[ht.tail]), size -ht.tail);
+		memcpy(&hh, &(buf->buffer[0]), (ht.tail + sizeof(hheader_t) % size) );
+	}
+	else {
+		memcpy(&hh, &(buf->buffer[ht.tail]), sizeof(hheader_t));
+	}
+	ht.tail = (ht.tail + sizeof(hheader_t) % size);
+
+	/* amount to copy */
+	if (count >= hh.part )
+		count = hh.part;
+	else
+		// exit if there is no enough space
+		return -1;
+
+	/* when tail is greater then head content is written across the end */
+	if (ht.tail + count >= size) {
+		memcpy(dst, &(buf->buffer[ht.tail]),
+				(size - ht.tail));
+		memcpy((dst + (size - ht.tail)), &(buf->buffer[0]),
+				(ht.tail + count) % size);
+	}
+	else {
+		memcpy(dst, &(buf->buffer[ht.tail]), count);
+	}
+	ht.tail = (ht.tail + count) % size;
+
+	/* check for the align space */
+	register acount = hh.total - hh.part - sizeof(hheader_t);
+	if ( acount )
+		ht.tail = (ht.tail + acount) % size;
+
+	buf->indexes.tail = ht.tail;
+	return count;
+}
+
+
+static void mbuffer_dump(bbuffer_t * bb)
+{
+  printf("mbuffer_dump: head %d tail %d size %d count %d\n",
+		  bb->indexes.head, bb->indexes.tail, bb->size,
+		  (((bb->size + bb->indexes.head) - bb->indexes.tail) % bb->size));
+}
+
+
+//#define UNIT_TEST_MBUFFER
+#ifdef UNIT_TEST_MBUFFER
+int main (int argc, char * argv[])
+{
+  bbuffer_t* bbuf;
+  int _ret;
+  char src[196] = "Il viaggio ultraterreno di Dante richiede l'appoggio di "
+		  "una guida, in quanto il protagonista rappresenta l'uomo smarrito in "
+		  "conseguenza del peccato e pertanto incapace di recuperare da solo "
+		  "la retta via. Per l'intero cammino che si svolge attraverso il "
+		  "baratro dell'Inferno e su per la montagna del Purgatorio la guida "
+		  "prescelta  Virgilio, l'antico poeta latino autore dell'Eneide.";
+  char dest[196];
+
+  bbuf = mbuffer_init ((64 +15), 0);
+
+  _ret = mbuffer_put(bbuf, &(src[0]), 5);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[5]), 5);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[10]), 28);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[38]), 33);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 15);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 64);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[71]), 33);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[104]), 31);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[104]), 30);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  _ret = mbuffer_put(bbuf, &(src[104]), 3);
+  printf("put ret %d\n", _ret);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 32);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 64);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 64);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 64);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  // GET
+  memset(dest, 0, 128);
+  _ret = mbuffer_get(bbuf, dest, 64);
+  printf("get ret %d '%s'\n", _ret, dest);
+  mbuffer_dump(bbuf);
+
+  return 0;
+}
+#endif /* UNIT_TEST_MBUFFER */
diff --git a/ipc/test/mbuffer.h b/ipc/test/mbuffer.h
new file mode 100644
index 0000000..991176e
--- /dev/null
+++ b/ipc/test/mbuffer.h
@@ -0,0 +1,31 @@
+// bbuffer.h
+// Author: Antonio Barbalace, Virginia Tech 2012
+
+/*
+ *
+ */
+static inline bbuffer_t* mbuffer_init (int size, int node)
+{
+	return bbuffer_init(size, node);
+}
+
+/*
+ *
+ */
+static inline void mbuffer_finalize (bbuffer_t* bb)
+{
+	return bbuffer_finalize(bb);
+}
+/*
+ *
+ */
+int mbuffer_put (bbuffer_t* bb, char* src, int count);
+/*
+ *
+ */
+int mbuffer_get (bbuffer_t* bb, char* dst, int count);
+
+static inline int mbuffer_count (bbuffer_t * buf)
+{
+	return bbuffer_count(buf);
+}
diff --git a/ipc/test/rdtsc.h b/ipc/test/rdtsc.h
new file mode 100644
index 0000000..d52c4b0
--- /dev/null
+++ b/ipc/test/rdtsc.h
@@ -0,0 +1,63 @@
+/*
+ * time stamp counter services
+ */
+
+#include <string.h>
+#include <signal.h>
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <sys/types.h>
+
+#define BILLION		1000000000
+#define MILLION		1000000
+#define THOUSAND	1000
+
+/* Read the timestamp counter. Throw mfence to prevent reordering */
+#ifdef __i386__
+#define DECLARE_ARGS(val, low, high)    unsigned long long val
+#define EAX_EDX_VAL(val, low, high)     (val)
+#define EAX_EDX_RET(val, low, high)     "=A" (val)
+#else
+#define DECLARE_ARGS(val, low, high)    unsigned low, high
+#define EAX_EDX_VAL(val, low, high)     ((low) | ((uint64_t)(high) << 32))
+#define EAX_EDX_RET(val, low, high)     "=a" (low), "=d" (high)
+#endif
+
+
+static inline unsigned long long RDTSC()
+{
+	DECLARE_ARGS(val, low, high);
+
+	asm volatile(	"mfence\n"
+			"rdtsc" : EAX_EDX_RET(val, low, high));
+
+	return EAX_EDX_VAL(val, low, high);
+}
+
+/* when rdtsc is not supported --- usec resolution */
+static inline unsigned long long GTD()
+{
+	struct timeval time;
+
+	gettimeofday(&time, NULL);
+
+	return (((unsigned long long)time.tv_sec * 1000000) + time.tv_usec);
+}
+
+/* when rdtsc is not supported --- nsec resolution */
+static inline unsigned long long CGT()
+{
+	struct timespec time;
+
+	clock_gettime(CLOCK_REALTIME, &time);
+
+	return (((unsigned long long)time.tv_sec * 1000000000) + time.tv_nsec);
+}
+
+#define start_measure(a) (a = RDTSC())
+#define end_measure(a) (RDTSC() - a)
diff --git a/ipc/test/script/plotCommand.sh b/ipc/test/script/plotCommand.sh
new file mode 100644
index 0000000..16c33fd
--- /dev/null
+++ b/ipc/test/script/plotCommand.sh
@@ -0,0 +1,7 @@
+#!/bin/sh
+
+#arguments
+#test name (spinlockXX.log)
+#core num (XX)
+
+plot
\ No newline at end of file
diff --git a/ipc/test/script/runExperiments.sh b/ipc/test/script/runExperiments.sh
new file mode 100644
index 0000000..e69de29
diff --git a/kcp32.sh b/kcp32.sh
new file mode 100755
index 0000000..e13c2ea
--- /dev/null
+++ b/kcp32.sh
@@ -0,0 +1,16 @@
+#!/bin/bash
+# This script simply creates from vmlinux the file vmlinux.elf (a stripped version)
+# then it will copy it to the selected file system (that will first be mounted)
+
+MOUNT_IMG=/root/Downloads/kexec_img/kexec128.img
+MOUNT_POINT=/root/Downloads/kexec_fs/
+
+mount -o loop $MOUNT_IMG $MOUNT_POINT
+
+objcopy -R .note -R .comment -S vmlinux vmlinux.elf
+cp arch/x86/boot/compressed/vmlinux.relocs $MOUNT_POINT/boot/vmlinux.relocs 
+cp vmlinux.elf $MOUNT_POINT/boot/vmlinux.elf 
+
+umount $MOUNT_POINT
+
+echo "done"
diff --git a/kernel/kexec.c b/kernel/kexec.c
index dc7bc08..5448e59 100644
--- a/kernel/kexec.c
+++ b/kernel/kexec.c
@@ -116,7 +116,8 @@ static int kimage_is_destination_range(struct kimage *image,
 static struct page *kimage_alloc_page(struct kimage *image,
 				       gfp_t gfp_mask,
 				       unsigned long dest);
-
+// allocates the struct kimage copying the segment descriptor from user space
+// it checks each segment descriptor for physical dimension and physical overlapping
 static int do_kimage_alloc(struct kimage **rimage, unsigned long entry,
 	                    unsigned long nr_segments,
                             struct kexec_segment __user *segments)
@@ -151,6 +152,7 @@ static int do_kimage_alloc(struct kimage **rimage, unsigned long entry,
 	/* Read in the segments */
 	image->nr_segments = nr_segments;
 	segment_bytes = nr_segments * sizeof(*segments);
+	//TODO check segments < KEXEC_SEGMENT_MAX
 	result = copy_from_user(image->segment, segments, segment_bytes);
 	if (result) {
 		result = -EFAULT;
@@ -226,6 +228,8 @@ out:
 
 }
 
+// calls do_kimage_alloc
+// allocates control_code_page and swap_page
 static int kimage_normal_alloc(struct kimage **rimage, unsigned long entry,
 				unsigned long nr_segments,
 				struct kexec_segment __user *segments)
@@ -953,14 +957,21 @@ SYSCALL_DEFINE4(kexec_load, unsigned long, entry, unsigned long, nr_segments,
 	 * Verify we have a legal set of flags
 	 * This leaves us room for future extensions.
 	 */
-	if ((flags & KEXEC_FLAGS) != (flags & ~KEXEC_ARCH_MASK))
+	if ((flags & KEXEC_FLAGS) != (flags & ~KEXEC_ARCH_MASK)) {
+		printk ("flags = 0x%08lx [0x%08x 0x%08x] if (0x%08lx != 0x%08lx)\n",
+				flags, KEXEC_FLAGS, ~KEXEC_ARCH_MASK,
+				(flags & KEXEC_FLAGS), (flags & ~KEXEC_ARCH_MASK));
 		return -EINVAL;
+	}
 
 	/* Verify we are on the appropriate architecture */
 	if (((flags & KEXEC_ARCH_MASK) != KEXEC_ARCH) &&
-		((flags & KEXEC_ARCH_MASK) != KEXEC_ARCH_DEFAULT))
+		((flags & KEXEC_ARCH_MASK) != KEXEC_ARCH_DEFAULT)) {
+		printk ("flags = 0x%08lx [0x%08x 0x%08x 0x%08x] if (0x%08lx != 0x%08x) && ( . != 0x%08x)\n",
+				flags, KEXEC_ARCH_MASK, KEXEC_ARCH, KEXEC_ARCH_DEFAULT,
+				(flags & KEXEC_ARCH_MASK), KEXEC_ARCH, KEXEC_ARCH_DEFAULT);
 		return -EINVAL;
-
+	}
 	/* Put an artificial cap on the number
 	 * of segments passed to kexec_load.
 	 */
@@ -970,8 +981,8 @@ SYSCALL_DEFINE4(kexec_load, unsigned long, entry, unsigned long, nr_segments,
 	image = NULL;
 	result = 0;
 
-	/* Because we write directly to the reserved memory
-	 * region when loading crash kernels we need a mutex here to
+	/* Because we write directly to the RESERVED MEMORY
+	 * REGION when loading crash kernels we need a mutex here to
 	 * prevent multiple crash  kernels from attempting to load
 	 * simultaneously, and to prevent a crash kernel from loading
 	 * over the top of a in use crash kernel.
@@ -982,8 +993,12 @@ SYSCALL_DEFINE4(kexec_load, unsigned long, entry, unsigned long, nr_segments,
 		return -EBUSY;
 
 	dest_image = &kexec_image;
-	if (flags & KEXEC_ON_CRASH)
+	if (flags & KEXEC_ON_CRASH) {
 		dest_image = &kexec_crash_image;
+		printk(KERN_DEBUG "syscall_kexec_load CRASH MODE\n");
+	} else
+		printk(KERN_DEBUG "syscall_kexec_load NORMAL MODE\n");
+
 	if (nr_segments > 0) {
 		unsigned long i;
 
diff --git a/kernel/smp.c b/kernel/smp.c
index db197d6..da9d1c6 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -671,6 +671,13 @@ void __init smp_init(void)
 
 	/* FIXME: This should be done in userspace --RR */
 	for_each_present_cpu(cpu) {
+/*
+	ok ... how defined present and where?
+			what we need is a maskof present cpus (that is different from possible)
+	idea is somewhere define the present cpus differently from possible
+	using a mask and we are done
+			result is: trying to boot up an 8 cores enabling only cores 1, 3 ,5 7
+*/
 		if (num_online_cpus() >= setup_max_cpus)
 			break;
 		if (!cpu_online(cpu))
diff --git a/kernel/sys.c b/kernel/sys.c
index 481611f..1660a69 100644
--- a/kernel/sys.c
+++ b/kernel/sys.c
@@ -489,7 +489,12 @@ SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd,
 		ret = kernel_kexec();
 		break;
 #endif
+	case LINUX_REBOOT_CMD_MKBSP: {
+		int cpu = (int) arg; // TODO rewrite this part for compatibility
+		int apicid = apic->cpu_present_to_apicid(cpu);
 
+		ret = mkbsp_boot_cpu( apicid, cpu);
+		break; }
 #ifdef CONFIG_HIBERNATION
 	case LINUX_REBOOT_CMD_SW_SUSPEND:
 		ret = hibernate();
diff --git a/mm/percpu.c b/mm/percpu.c
index 716eb4a..e4a95d4 100644
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@ -1129,12 +1129,12 @@ static void pcpu_dump_alloc_info(const char *lvl,
 				printk("\n");
 				printk("%spcpu-alloc: ", lvl);
 			}
-			printk("[%0*d] ", group_width, group);
+			printk("[%0*d] ", group_width, group); // print group id
 
 			for (unit_end += upa; unit < unit_end; unit++)
 				if (gi->cpu_map[unit] != NR_CPUS)
 					printk("%0*d ", cpu_width,
-					       gi->cpu_map[unit]);
+					       gi->cpu_map[unit]); // print cpuid of each element in the group
 				else
 					printk("%s ", empty_str);
 		}
diff --git a/script32.gdb b/script32.gdb
new file mode 100644
index 0000000..f0dfb5c
--- /dev/null
+++ b/script32.gdb
@@ -0,0 +1,321 @@
+#
+# http://www.opensource.apple.com/source/xnu/xnu-792.13.8/kgmacros?txt
+# http://www.ibm.com/developerworks/aix/library/au-gdb.html
+#
+
+define dump_memblock
+printf "limit: 0x%x size: %d\n", memblock.current_limit, memblock.memory_size
+set $_i=0
+set $_tot=0
+set $_mem_cnt=memblock.memory.cnt
+printf "memory (%d)\n", $_mem_cnt
+while ($_i < $_mem_cnt)
+  printf " %2d:0x%08x-0x%08x (%d B)\n", $_i, memblock.memory.regions[$_i].base, memblock.memory.regions[$_i].base + memblock.memory.regions[$_i].size, memblock.memory.regions[$_i].size
+  set $_tot = $_tot + memblock.memory.regions[$_i].size
+  set $_i = $_i +1
+end
+printf " total memory: %d B\n", $_tot
+set $_i=0
+set $_tot=0
+set $_res_cnt=memblock.reserved.cnt
+printf "reserved (%d)\n", $_res_cnt
+while ($_i < $_res_cnt)
+  printf " %2d:0x%08x-0x%08x (%d B)\n", $_i, memblock.reserved.regions[$_i].base, memblock.reserved.regions[$_i].base + memblock.reserved.regions[$_i].size, memblock.reserved.regions[$_i].size
+  set $_tot = $_tot + memblock.reserved.regions[$_i].size   
+  set $_i = $_i +1
+end
+printf " total reserved: %d B\n", $_tot
+end
+document dump_memblock
+memblock is a Linux global variable that collects non reserved and reserved memory blocks
+end
+
+define dump_e820
+set $_i=0
+set $_tot=0
+set $_count=e820.nr_map
+printf "e820 (%d)\n", $_count
+while ($_i < $_count)
+  printf " %2d:0x%08x-0x%08x (%d B) ", $_i, e820.map[$_i].addr, e820.map[$_i].addr + e820.map[$_i].size, e820.map[$_i].size
+  set $_tot = $_tot + e820.map[$_i].size
+  set $_type = e820.map[$_i].type 
+  if ($_type == 1)
+    printf "E820_RAM\n"
+  else
+    if ($_type == 2)
+      printf "E820_RESERVED\n"
+    else
+      if ($_type == 3)
+        printf "E820_ACPI\n"
+      else
+        if ($_type == 4)
+          printf "E820_NVS\n"
+        else
+          if ($_type == 5)
+            printf "E820_UNUSABLE\n"
+          else
+            if ($_type == 128)
+              printf "E820_RESERVED_KERN\n"
+            else
+              printf "UKNONWN (%d)\n", $_type
+            end
+          end
+        end
+      end
+    end
+  end
+  set $_i = $_i +1
+end
+printf " total e820: %d B\n", $_tot
+end
+document dump_e820
+e820 is a BIOS call that lists all the memory regions present in the machine
+end
+
+define dump_pd_bit
+  set $_current = $arg0
+  if (($_current & 0x0002) != 0)
+    printf "RW "
+  else
+    printf " R "
+  end
+  if (($_current & 0x0004) != 0)
+    printf "USR "
+  else
+    printf "KRN "
+  end
+  if (($_current & 0x0008) != 0)
+    printf "WT "
+  else
+    printf "WB "
+  end
+  if (($_current & 0x0010) != 0)
+    printf "CD"
+  else
+    printf "CE"
+  end
+end
+document dump_pd_bit
+function used together with dump_pd and dump_pt
+WT means Write Through, WB means Write Back, CD is Cache Disable, CE Cache Enable
+end 
+
+#dump_pt page_table_address, base_address
+define dump_pt
+set $_i=0
+set $_count=1024
+set $_base=(void*)$arg1
+set $_addr=(void*)$arg0
+set $_size=4
+if ($_base != 0) 
+  printf "page table at 0x%08x\n", $_addr
+end
+while ( $_count > 0)
+  set $_current = *(long*)$_addr
+  if (($_current & 0x0001) != 0)
+    printf "   %2d:0x%08x->0x%08x [", $_i, \
+      $_base + ((($_addr - (void*)$arg0)/$_size) << 12), ($_current & 0xFFFFF000)
+      dump_pd_bit $_current
+      printf "] (4kB)\n"
+    set $_i = $_i + 1
+  end
+  set $_addr = $_addr + $_size
+  set $_count = $_count - 1
+end
+if ($_base != 0)
+  printf "total: %d\n", $_i
+end
+end
+
+#dump_pd page_directory_address
+define dump_pd
+set $_i=0
+set $_count=1024
+set $_addr=(void*)$arg0
+set $_size=4
+printf "page directory at 0x%08x\n", $_addr
+while ( $_count > 0)
+  set $_current = *(long*)$_addr
+  if (($_current & 0x0001) != 0)
+    if (($_current & 0x0080) !=0)
+      printf " %2d:0x%08x->0x%08x [", $_i, \
+        (($_addr - (void*)$arg0)/$_size) << 22, ($_current & 0xFFC00000)
+      dump_pd_bit $_current 
+      printf "] (4MB)\n"
+    else
+      printf " %2d:0x%08x-@0x%08x [", $_i, \
+        (($_addr - (void*)$arg0)/$_size) << 22, ($_current & 0xFFFFF000)
+      dump_pd_bit $_current
+      printf "] (page table)\n"
+    end
+    set $_i = $_i + 1
+  end
+  set $_addr = $_addr + $_size
+  set $_count = $_count - 1
+end
+printf "total: %d\n", $_i
+end
+document dump_pd
+dump the page directory entries, it expected the page directory virtul address as an input;
+the page directory address can be read from cr3 (physical) or from swapper_pg_dir (virtual)
+after setup_arch() or initial_page_table (virtual) before setup_arch();
+the number of page table entries is 1024, each entry can address 4kB (requires a pte), 2MB(PAE) or 4MB.
+have a look at arch/x86/kernel/dump_pagetables.c
+end
+
+TODO for 32bit multikernel development must be offsetted correctly TODO TODO TODO
+define dump_cpu_masks 
+  printf "maxcpus=%d (setup_max_cpus) nr_cpus=%d (nr_cpu_ids)\n", \
+    setup_max_cpus, nr_cpu_ids
+  printf "possible_cpus=%d (setup_possible_cpus)\n", \
+    setup_possible_cpus
+  printf "num_processors=%d [acpi_boot_init()] disabled_cpus=%d [generic_processor_info()]\n", \
+    num_processors, disabled_cpus
+  printf "possible %08x(%p) present %08x(%p)\nonline   %08x(%p) active  %08x(%p)\n", \
+    *(long*)cpu_possible_mask, cpu_possible_mask, \
+    *(long*)cpu_present_mask, cpu_present_mask, \
+    *(long*)cpu_online_mask, cpu_online_mask, \
+    *(long*)cpu_active_mask, cpu_active_mask 
+  info threads
+end
+
+define dmesg
+  set $__log_buf = (char*)$arg0
+  set $log_start = *(unsigned int*)$arg1
+  set $log_end = *(unsigned int*)$arg2
+  set $x = $log_start
+  printf "%p %d %d %d\n", $__log_buf, $log_start, $log_end, $x 
+  while ($x < $log_end)
+    set $c = (char)(($__log_buf)[$x++])
+    printf "%c" , $c
+  end
+  printf "\n"
+end
+document dmesg
+dmesg __log_buf log_start log_end
+Print the content of the kernel message buffer
+from elinux.org
+end
+
+define dump_resource
+18 struct resource {
+ 19         resource_size_t start;
+ 20         resource_size_t end;
+ 21         const char *name;
+ 22         unsigned long flags;
+ 23         struct resource *parent, *sibling, *child;
+ 24 };
+    
+define dump_iomem
+  dump_resource iomem_resource
+end
+
+define dump_ioport
+  dump_resource ioport_resource
+end
+
+define task_struct_show
+   # task_struct addr and PID
+   set $st=(struct task_struct *)$arg0
+   printf "0x%08X %5d ", $st, $st->pid
+
+   # State
+   if ($st->state == 0)
+     printf "Running   "
+   else
+     if ($st->state == 1)
+       printf "Sleeping  "
+     else
+       if ($st->state == 2)
+         printf "Disksleep "
+       else
+         if ($st->state == 4)
+           printf "Zombie    "
+         else
+           if ($st->state == 8)
+             printf "sTopped   "
+           else
+             if ($st->state == 16)
+               printf "Wpaging   "
+             else
+               printf "%2d        ", $st->state
+             end
+           end
+         end
+       end
+     end
+   end
+
+   # User NIP
+   printf "0x%08X ", $st->thread.ip
+   
+   # Display the kernel stack pointer
+   printf "0x%08X ", $st->thread.sp
+   
+   # Display the processor id
+   printf "%d ", ((struct thread_info *)($st)->stack)->cpu
+
+   # comm
+  printf "%s\n", $st->comm
+end
+
+define find_next_task
+  # Given a task address, find the next task in the linked list
+  set $t = (struct task_struct *)$arg0
+  set $off=( (char *)&($t->tasks) - (char *)$t)
+  set $t=(struct task_struct *)( (char *)$t->tasks.next - $off)
+end
+
+define ps
+  # first argument handle eventual relocation on 32bit
+  set $offset=$arg0
+  set $t=(char *)&init_task
+  set $t=$t + $offset
+  print/x $t
+  task_struct_show $t
+  find_next_task $t
+  # Walk the list
+  while ((char *)&init_task +$offset)!=$t
+    # Display useful info about each task
+    task_struct_show $t
+    find_next_task $t
+  end
+end
+document ps
+this version works only in kernel space, if the actual kernel is in user space this dumper does not work
+we will solve this issue in a further version
+this version support kernel relocation the only argument is the kernel relocation offset 
+end
+
+define dinitcall
+  # as ps first argument is relocation on 32bit
+  set $offset=$arg0
+  set $s=(char *)&__early_initcall_end
+  set $s=(initcall_t *)($s + $offset)
+  set $e=(char *)&__initcall_end
+  set $e=(initcall_t *)($e + $offset)
+  while $s!=$e
+    print *((initcall_t *)$s)
+	set $s=$s+1
+  end
+end
+
+define dearly
+  # as ps first argument is relocation on 32bit
+  set $offset=$arg0
+  set $s=(char *)&__initcall_start
+  set $s=(initcall_t *)($s + $offset)
+  set $e=(char *)&__early_initcall_end
+  set $e=(initcall_t *)($e + $offset)
+  while $s!=$e
+    print *((initcall_t *)$s)
+	set $s=$s+1
+  end
+end
+
+break handle_irq
+commands
+silent
+print irq
+continue
+end
diff --git a/tools/mk/latency_ipi.c b/tools/mk/latency_ipi.c
new file mode 100644
index 0000000..e69de29
diff --git a/tools/mk/latency_msi.c b/tools/mk/latency_msi.c
new file mode 100644
index 0000000..e69de29
diff --git a/tools/mk/latency_numa.c b/tools/mk/latency_numa.c
new file mode 100644
index 0000000..f4a25a9
--- /dev/null
+++ b/tools/mk/latency_numa.c
@@ -0,0 +1,124 @@
+#include <stdio.h>
+#include <numa.h>
+#include <pthread.h>
+#include <sched.h>
+
+void backend_set_numa(unsigned id)
+{
+    struct bitmask *bm = numa_allocate_cpumask();
+    numa_bitmask_setbit(bm, id);
+    numa_sched_setaffinity(0, bm);
+    numa_free_cpumask(bm);
+}
+
+void * backend_malloc(size_t size, unsigned id)
+{   return numa_alloc_onnode(size, id); }
+
+void backend_free(void* start, size_t size)
+{   numa_free(start, size); }
+
+void backend_run_func_on(int core_id, void* cfunc, void *arg)
+{
+    pthread_t pthread;
+    int r = pthread_create(&pthread, NULL, cfunc, arg);
+    if (r != 0) {
+        printf("pthread_create failed\n");
+    }
+}
+
+// for efficiency this must be keept locally to the processor in a ccNUMA system
+// we can avoid this choice by considering that this choice will introduce some more traffic in the application
+#define MAX 1024
+typedef struct _args {
+	int id; // cpuid on which to run the thread
+	int size; // number of element to be copied each time
+	int num; // number of delta recorded
+	long int timestamps[MAX]; // array of deltas
+} args;
+
+// page aligned
+long int global[SIZE] __cache__aligned; //must be cache aligned this must reside on the main node we can also think to allocate it dynamically
+// fully in one page
+
+void * cfunc (void* arg) {
+	args * a = (args *) arg;
+	int id = a->id;
+	int num = 0;
+	int size = a->size;
+	long int * t = a->timestamps;
+	long int start, end;
+	int cpuid;
+	long int * local;
+	long int check;
+	int i;
+
+	//move to the right processor
+	backend_set_numa(id);
+	//print the actual processor id
+	cpuid = sched_getcpu();
+	printf("id %d getcpu() %d\n", id, cpuid);
+	//change the scheduling policy
+	backend_set_policy(id);
+	//prepare pointers to save trend data
+	memset(t, 0, sizeof(long int)*MAX);
+	//allocate the local copy of the array here
+	local = backend_malloc (size, id);
+	printf("id %d malloc %p\n", id, local);
+
+	//barrier for synchronization
+	barrier();
+	//loop of MAX iterations to read
+	//every iteration to check that what we are reading is consistent we will check first number with last number
+	//(only when we are reading more then one word)
+for (i=0; i<MAX; i++) {
+	//
+	start = rdtsc();
+	// remote memory read (can also be an array)
+	memcpy(local, remote, sizeof(long int) * size);
+	end = rdtsc();
+
+	if (size == 1) {
+		no consistency check
+	}
+	else {
+		consistency check is needed
+	}
+
+	if the local copy is equal to the previous non salvare il tempo usa check per verificarlo
+	go back to start
+	otherwise cicletto sotto
+
+	save the time delta in the array at index i
+
+	fai qualche cosa tipo un cicletto for del minc 89hia e poi riprova a leggere i dati
+	for (l=0; l< (MAX/2); l++) {
+		backend_busy_wait();
+	}
+}
+
+}
+
+//one function per
+//test function: 1 -> 1 (different cache distances)
+//test function: 1 -> all (different dispalcements)
+
+int main (int argc, char* argv[]) {
+
+	//prepare data structures for saving data (all local to this processor: the producer)
+	//first version 1 producer, different consumers (next versions different data patterns)
+	//create threads
+
+
+	master thread must do the same registration but is the one that release the barrier
+
+	for (i=0; 1<MAX; i++)
+
+		for (l=0; l< (MAX/2); l++) {
+			backend_busy_wait();
+		}
+
+	//print out the whole data collected during the exection
+
+
+	return 0;
+}
